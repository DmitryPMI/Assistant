{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Ramas dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torchaudio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_Angry.csv',\n",
       " 'data_Disgusted.csv',\n",
       " 'data_Domination.csv',\n",
       " 'data_Happy.csv',\n",
       " 'data_Neutral.csv',\n",
       " 'data_Sad.csv',\n",
       " 'data_Scared.csv',\n",
       " 'data_Shame.csv',\n",
       " 'data_Submission.csv',\n",
       " 'data_Surprised.csv',\n",
       " 'data_Tiredness.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_files = os.listdir('Ramas(audio)/Annotations_by_emotions')\n",
    "category_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего 11 категорий, соответствующих различным эмоциям. Рассмотрим статистику по категориям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angry category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>File</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10dec_D11_1</td>\n",
       "      <td>123.801</td>\n",
       "      <td>143.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10dec_D11_1</td>\n",
       "      <td>210.220</td>\n",
       "      <td>257.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10dec_D31_1</td>\n",
       "      <td>20.981</td>\n",
       "      <td>29.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10dec_D41_1</td>\n",
       "      <td>21.083</td>\n",
       "      <td>24.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10dec_D41_1</td>\n",
       "      <td>26.379</td>\n",
       "      <td>31.611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         File    Start      End\n",
       "0   1  10dec_D11_1  123.801  143.728\n",
       "1   1  10dec_D11_1  210.220  257.280\n",
       "2   1  10dec_D31_1   20.981   29.468\n",
       "3   1  10dec_D41_1   21.083   24.517\n",
       "4   1  10dec_D41_1   26.379   31.611"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_angry = pd.read_csv('Ramas(audio)/Annotations_by_emotions/data_Angry.csv')\n",
    "data_angry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_angry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_angry = data_angry.End - data_angry.Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1561.000000\n",
       "mean       10.421540\n",
       "std        10.619133\n",
       "min         0.007000\n",
       "25%         3.340000\n",
       "50%         6.113000\n",
       "75%        12.954000\n",
       "max        60.090000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_angry.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Остальные категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Angry\n",
      "count    1561.000000\n",
      "mean       10.421540\n",
      "std        10.619133\n",
      "min         0.007000\n",
      "25%         3.340000\n",
      "50%         6.113000\n",
      "75%        12.954000\n",
      "max        60.090000\n",
      "dtype: float64\n",
      "\n",
      "Disgusted\n",
      "count    1152.000000\n",
      "mean       10.703730\n",
      "std        10.906867\n",
      "min         0.020000\n",
      "25%         3.288250\n",
      "50%         6.424000\n",
      "75%        14.727500\n",
      "max        62.457000\n",
      "dtype: float64\n",
      "\n",
      "Domination\n",
      "count    2400.000000\n",
      "mean       25.914166\n",
      "std        18.618666\n",
      "min         0.002000\n",
      "25%         7.212500\n",
      "50%        27.035000\n",
      "75%        39.740500\n",
      "max        91.960000\n",
      "dtype: float64\n",
      "\n",
      "Happy\n",
      "count    2618.000000\n",
      "mean        9.416040\n",
      "std        10.521548\n",
      "min         0.004000\n",
      "25%         2.910000\n",
      "50%         5.373000\n",
      "75%        11.004250\n",
      "max        76.147000\n",
      "dtype: float64\n",
      "\n",
      "Neutral\n",
      "count    1269.000000\n",
      "mean       24.581823\n",
      "std        32.358076\n",
      "min         0.002000\n",
      "25%         4.910000\n",
      "50%        13.060000\n",
      "75%        35.266000\n",
      "max       382.938000\n",
      "dtype: float64\n",
      "\n",
      "Sad\n",
      "count    1022.000000\n",
      "mean       13.179038\n",
      "std        13.854441\n",
      "min         0.001000\n",
      "25%         3.852500\n",
      "50%         7.161000\n",
      "75%        17.680750\n",
      "max        82.741000\n",
      "dtype: float64\n",
      "\n",
      "Scared\n",
      "count    1301.000000\n",
      "mean       15.113616\n",
      "std        13.626759\n",
      "min         0.010000\n",
      "25%         4.710000\n",
      "50%         9.316000\n",
      "75%        23.628000\n",
      "max        68.210000\n",
      "dtype: float64\n",
      "\n",
      "Shame\n",
      "count    317.000000\n",
      "mean      11.954423\n",
      "std       11.552749\n",
      "min        0.010000\n",
      "25%        4.390000\n",
      "50%        7.640000\n",
      "75%       14.890000\n",
      "max       58.357000\n",
      "dtype: float64\n",
      "\n",
      "Submission\n",
      "count    2145.000000\n",
      "mean       27.344736\n",
      "std        20.618267\n",
      "min         0.007000\n",
      "25%         8.425000\n",
      "50%        28.045000\n",
      "75%        41.409000\n",
      "max       219.012000\n",
      "dtype: float64\n",
      "\n",
      "Surprised\n",
      "count    1925.000000\n",
      "mean        7.323645\n",
      "std         8.613809\n",
      "min         0.003000\n",
      "25%         2.500000\n",
      "50%         4.170000\n",
      "75%         8.039000\n",
      "max        69.443000\n",
      "dtype: float64\n",
      "\n",
      "Tiredness\n",
      "count     58.000000\n",
      "mean      14.536552\n",
      "std       24.884877\n",
      "min        0.006000\n",
      "25%        2.251000\n",
      "50%        4.423500\n",
      "75%       18.539500\n",
      "max      155.584000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for cat in category_files:\n",
    "    data = pd.read_csv('Ramas(audio)/Annotations_by_emotions/' + cat)\n",
    "    stats_data = data.End - data.Start\n",
    "    print()\n",
    "    print(cat[5:-4])\n",
    "    print(stats_data.describe(), end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По некоторым категориям, вроде `Tiredness`, у нас достаточно мало объектов, однако по основным категориям больше 1000 объектов, этого уже достаточно для моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('RAMAS(audio)/Audio/10dec_D11_1_mic.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7946240,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('RAMAS(audio)/Audio/10dec_D42_1_mic.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(649472,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sample_rate = x, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=128)\n",
    "mfccsscaled = np.mean(mfccs.T,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccsscaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self, category_filenames, audio_path, table_prefix, sample_rate):\n",
    "        self.table_prefix = table_prefix\n",
    "        self.category_filenames = category_filenames\n",
    "        self.audio_path = audio_path\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def make_dataset(self):\n",
    "        train_test_data = []\n",
    "        c = 0\n",
    "        for category in self.category_filenames:\n",
    "            data = pd.read_csv(self.table_prefix + category)\n",
    "            values = data.values\n",
    "            for i in range(values.shape[0]):\n",
    "                ind, name, start, end = values[i]\n",
    "                try:\n",
    "                    file = AudioSegment.from_file(self.audio_path + name + \"_mic.wav\")\n",
    "                except:\n",
    "                    c += 1\n",
    "                    continue\n",
    "                try:\n",
    "                    audio = np.array(file[start * 1000 : end * 1000].get_array_of_samples()).astype('float')\n",
    "                    mfccs = librosa.feature.mfcc(y=audio, sr=self.sample_rate, n_mfcc=128)\n",
    "                    mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "                    train_test_data.append([category, mfccsscaled])\n",
    "                except:\n",
    "                    c += 1\n",
    "        print(f'Lost: {c}')\n",
    "        return train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(category_files, \"RAMAS(audio)/Audio/\", \"RAMAS(audio)/Annotations_by_emotions/\", 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost: 12064\n"
     ]
    }
   ],
   "source": [
    "ds = dl.make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.array(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3704, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_Happy.csv         638\n",
       "data_Domination.csv    561\n",
       "data_Neutral.csv       456\n",
       "data_Submission.csv    437\n",
       "data_Surprised.csv     390\n",
       "data_Angry.csv         352\n",
       "data_Disgusted.csv     292\n",
       "data_Scared.csv        292\n",
       "data_Sad.csv           221\n",
       "data_Shame.csv          47\n",
       "data_Tiredness.csv      18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ds[:, 0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы каким-то образом потеряли 75% выборки. Попробуем построить модель с тем, что есть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ds[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3704,), (3704, 11))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(np.array(list(map(lambda x: x.astype('float'), X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.columns = list(map(lambda x: 'y' + str(x), list(range(11))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y0  y1  y2  y3  y4  y5  y6  y7  y8  y9  y10\n",
       "0   1   0   0   0   0   0   0   0   0   0    0\n",
       "1   1   0   0   0   0   0   0   0   0   0    0\n",
       "2   1   0   0   0   0   0   0   0   0   0    0\n",
       "3   1   0   0   0   0   0   0   0   0   0    0\n",
       "4   1   0   0   0   0   0   0   0   0   0    0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>782.593805</td>\n",
       "      <td>125.750045</td>\n",
       "      <td>-7.096012</td>\n",
       "      <td>30.291876</td>\n",
       "      <td>-0.623040</td>\n",
       "      <td>18.035505</td>\n",
       "      <td>-6.152137</td>\n",
       "      <td>-1.018289</td>\n",
       "      <td>2.531784</td>\n",
       "      <td>-8.745806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>741.856962</td>\n",
       "      <td>108.594665</td>\n",
       "      <td>-1.118418</td>\n",
       "      <td>27.996197</td>\n",
       "      <td>11.538417</td>\n",
       "      <td>22.573374</td>\n",
       "      <td>-1.725687</td>\n",
       "      <td>0.121963</td>\n",
       "      <td>6.591717</td>\n",
       "      <td>-7.095285</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>634.575656</td>\n",
       "      <td>120.989468</td>\n",
       "      <td>46.548484</td>\n",
       "      <td>32.590693</td>\n",
       "      <td>0.425295</td>\n",
       "      <td>17.662792</td>\n",
       "      <td>-2.438896</td>\n",
       "      <td>8.921270</td>\n",
       "      <td>1.695513</td>\n",
       "      <td>-3.892302</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700.463525</td>\n",
       "      <td>113.865510</td>\n",
       "      <td>4.920722</td>\n",
       "      <td>14.854562</td>\n",
       "      <td>-3.228789</td>\n",
       "      <td>10.422334</td>\n",
       "      <td>-15.603181</td>\n",
       "      <td>3.501256</td>\n",
       "      <td>-3.101876</td>\n",
       "      <td>-3.035515</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>705.055377</td>\n",
       "      <td>117.656892</td>\n",
       "      <td>12.225516</td>\n",
       "      <td>11.308633</td>\n",
       "      <td>7.450487</td>\n",
       "      <td>16.785764</td>\n",
       "      <td>-13.225361</td>\n",
       "      <td>-0.508475</td>\n",
       "      <td>-0.539966</td>\n",
       "      <td>-8.581552</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4          5  \\\n",
       "0  782.593805  125.750045  -7.096012  30.291876  -0.623040  18.035505   \n",
       "1  741.856962  108.594665  -1.118418  27.996197  11.538417  22.573374   \n",
       "2  634.575656  120.989468  46.548484  32.590693   0.425295  17.662792   \n",
       "3  700.463525  113.865510   4.920722  14.854562  -3.228789  10.422334   \n",
       "4  705.055377  117.656892  12.225516  11.308633   7.450487  16.785764   \n",
       "\n",
       "           6         7         8         9  ...  y1  y2  y3  y4  y5  y6  y7  \\\n",
       "0  -6.152137 -1.018289  2.531784 -8.745806  ...   0   0   0   0   0   0   0   \n",
       "1  -1.725687  0.121963  6.591717 -7.095285  ...   0   0   0   0   0   0   0   \n",
       "2  -2.438896  8.921270  1.695513 -3.892302  ...   0   0   0   0   0   0   0   \n",
       "3 -15.603181  3.501256 -3.101876 -3.035515  ...   0   0   0   0   0   0   0   \n",
       "4 -13.225361 -0.508475 -0.539966 -8.581552  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "   y8  y9  y10  \n",
       "0   0   0    0  \n",
       "1   0   0    0  \n",
       "2   0   0    0  \n",
       "3   0   0    0  \n",
       "4   0   0    0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([X_df, y_df], axis=1, join=\"inner\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>384.129371</td>\n",
       "      <td>85.977938</td>\n",
       "      <td>40.818019</td>\n",
       "      <td>28.741837</td>\n",
       "      <td>7.832749</td>\n",
       "      <td>20.175130</td>\n",
       "      <td>10.109065</td>\n",
       "      <td>8.157295</td>\n",
       "      <td>3.525333</td>\n",
       "      <td>6.832565</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>550.057781</td>\n",
       "      <td>74.398509</td>\n",
       "      <td>37.835662</td>\n",
       "      <td>23.751557</td>\n",
       "      <td>2.801084</td>\n",
       "      <td>13.353396</td>\n",
       "      <td>4.986113</td>\n",
       "      <td>3.572924</td>\n",
       "      <td>6.381383</td>\n",
       "      <td>4.266097</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>686.089516</td>\n",
       "      <td>96.164423</td>\n",
       "      <td>16.735599</td>\n",
       "      <td>27.800913</td>\n",
       "      <td>-6.844259</td>\n",
       "      <td>12.922735</td>\n",
       "      <td>-5.041590</td>\n",
       "      <td>2.088965</td>\n",
       "      <td>-5.520138</td>\n",
       "      <td>-1.033384</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>562.667364</td>\n",
       "      <td>68.370049</td>\n",
       "      <td>12.705847</td>\n",
       "      <td>31.576763</td>\n",
       "      <td>12.842649</td>\n",
       "      <td>10.848686</td>\n",
       "      <td>0.078092</td>\n",
       "      <td>8.757463</td>\n",
       "      <td>2.445527</td>\n",
       "      <td>1.885409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>641.729316</td>\n",
       "      <td>98.827580</td>\n",
       "      <td>8.722678</td>\n",
       "      <td>43.513372</td>\n",
       "      <td>11.815128</td>\n",
       "      <td>32.351787</td>\n",
       "      <td>3.589162</td>\n",
       "      <td>8.736470</td>\n",
       "      <td>-0.765453</td>\n",
       "      <td>3.760414</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "591   384.129371  85.977938  40.818019  28.741837   7.832749  20.175130   \n",
       "2608  550.057781  74.398509  37.835662  23.751557   2.801084  13.353396   \n",
       "3577  686.089516  96.164423  16.735599  27.800913  -6.844259  12.922735   \n",
       "558   562.667364  68.370049  12.705847  31.576763  12.842649  10.848686   \n",
       "387   641.729316  98.827580   8.722678  43.513372  11.815128  32.351787   \n",
       "\n",
       "              6         7         8         9  ...  y1  y2  y3  y4  y5  y6  \\\n",
       "591   10.109065  8.157295  3.525333  6.832565  ...   1   0   0   0   0   0   \n",
       "2608   4.986113  3.572924  6.381383  4.266097  ...   0   0   0   0   0   1   \n",
       "3577  -5.041590  2.088965 -5.520138 -1.033384  ...   0   0   0   0   0   0   \n",
       "558    0.078092  8.757463  2.445527  1.885409  ...   1   0   0   0   0   0   \n",
       "387    3.589162  8.736470 -0.765453  3.760414  ...   1   0   0   0   0   0   \n",
       "\n",
       "      y7  y8  y9  y10  \n",
       "591    0   0   0    0  \n",
       "2608   0   0   0    0  \n",
       "3577   0   0   1    0  \n",
       "558    0   0   0    0  \n",
       "387    0   0   0    0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = data[:3200]\n",
    "Test_data = data[3200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 128), (504, 128))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = Train_data[list(range(128))]\n",
    "X_test = Test_data[list(range(128))]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 128, 1), (504, 128, 1))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(3200, 128, 1)\n",
    "X_test = X_test.values.reshape(504, 128, 1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Train_data[y_df.columns]\n",
    "y_test = Test_data[y_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(128,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(11))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 128, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 128, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                22539     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 516,235\n",
      "Trainable params: 516,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "200/200 [==============================] - 9s 37ms/step - loss: 2.4772 - accuracy: 0.1231 - val_loss: 2.2360 - val_accuracy: 0.1329\n",
      "Epoch 2/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.2749 - accuracy: 0.1506 - val_loss: 2.2248 - val_accuracy: 0.1627\n",
      "Epoch 3/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.2447 - accuracy: 0.1560 - val_loss: 2.2140 - val_accuracy: 0.1964\n",
      "Epoch 4/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.2346 - accuracy: 0.1633 - val_loss: 2.2125 - val_accuracy: 0.1726\n",
      "Epoch 5/700\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 2.2390 - accuracy: 0.1542 - val_loss: 2.1952 - val_accuracy: 0.1607\n",
      "Epoch 6/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.2093 - accuracy: 0.1610 - val_loss: 2.1850 - val_accuracy: 0.1925\n",
      "Epoch 7/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.1879 - accuracy: 0.1812 - val_loss: 2.1716 - val_accuracy: 0.2183\n",
      "Epoch 8/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.1852 - accuracy: 0.1952 - val_loss: 2.1612 - val_accuracy: 0.2302\n",
      "Epoch 9/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.1702 - accuracy: 0.2039 - val_loss: 2.1548 - val_accuracy: 0.2044\n",
      "Epoch 10/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.1510 - accuracy: 0.2073 - val_loss: 2.1434 - val_accuracy: 0.2421\n",
      "Epoch 11/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.1531 - accuracy: 0.2176 - val_loss: 2.1399 - val_accuracy: 0.2222\n",
      "Epoch 12/700\n",
      "200/200 [==============================] - 5s 28ms/step - loss: 2.1286 - accuracy: 0.2178 - val_loss: 2.1303 - val_accuracy: 0.2500\n",
      "Epoch 13/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.1076 - accuracy: 0.2352 - val_loss: 2.1288 - val_accuracy: 0.2083\n",
      "Epoch 14/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.1326 - accuracy: 0.2097 - val_loss: 2.1129 - val_accuracy: 0.2639\n",
      "Epoch 15/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.1132 - accuracy: 0.2204 - val_loss: 2.1075 - val_accuracy: 0.2480\n",
      "Epoch 16/700\n",
      "200/200 [==============================] - 5s 28ms/step - loss: 2.1024 - accuracy: 0.2289 - val_loss: 2.1021 - val_accuracy: 0.2480\n",
      "Epoch 17/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.1144 - accuracy: 0.2394 - val_loss: 2.0854 - val_accuracy: 0.2560\n",
      "Epoch 18/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.0820 - accuracy: 0.2334 - val_loss: 2.0817 - val_accuracy: 0.2560\n",
      "Epoch 19/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.0796 - accuracy: 0.2367 - val_loss: 2.0665 - val_accuracy: 0.2659\n",
      "Epoch 20/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.0750 - accuracy: 0.2376 - val_loss: 2.0640 - val_accuracy: 0.2817\n",
      "Epoch 21/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.0633 - accuracy: 0.2392 - val_loss: 2.0656 - val_accuracy: 0.2698\n",
      "Epoch 22/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.0384 - accuracy: 0.2733 - val_loss: 2.0659 - val_accuracy: 0.2540\n",
      "Epoch 23/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.0554 - accuracy: 0.2490 - val_loss: 2.0474 - val_accuracy: 0.2738\n",
      "Epoch 24/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.0466 - accuracy: 0.2441 - val_loss: 2.0444 - val_accuracy: 0.2679\n",
      "Epoch 25/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.0360 - accuracy: 0.2604 - val_loss: 2.0375 - val_accuracy: 0.2778\n",
      "Epoch 26/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.0158 - accuracy: 0.2495 - val_loss: 2.0454 - val_accuracy: 0.2540\n",
      "Epoch 27/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.0090 - accuracy: 0.2657 - val_loss: 2.0312 - val_accuracy: 0.2738\n",
      "Epoch 28/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 2.0034 - accuracy: 0.2663 - val_loss: 2.0213 - val_accuracy: 0.2877\n",
      "Epoch 29/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9680 - accuracy: 0.2787 - val_loss: 2.0301 - val_accuracy: 0.2837\n",
      "Epoch 30/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 2.0008 - accuracy: 0.2695 - val_loss: 2.0194 - val_accuracy: 0.2996\n",
      "Epoch 31/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.9901 - accuracy: 0.2842 - val_loss: 2.0232 - val_accuracy: 0.2778\n",
      "Epoch 32/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.9866 - accuracy: 0.2812 - val_loss: 2.0209 - val_accuracy: 0.2798\n",
      "Epoch 33/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.9885 - accuracy: 0.2869 - val_loss: 1.9980 - val_accuracy: 0.2996\n",
      "Epoch 34/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.9432 - accuracy: 0.2971 - val_loss: 1.9941 - val_accuracy: 0.2857\n",
      "Epoch 35/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9567 - accuracy: 0.2887 - val_loss: 2.0020 - val_accuracy: 0.3036\n",
      "Epoch 36/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.9596 - accuracy: 0.2955 - val_loss: 1.9929 - val_accuracy: 0.2837\n",
      "Epoch 37/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9757 - accuracy: 0.2931 - val_loss: 1.9839 - val_accuracy: 0.3274\n",
      "Epoch 38/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9469 - accuracy: 0.3006 - val_loss: 1.9793 - val_accuracy: 0.3175\n",
      "Epoch 39/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9365 - accuracy: 0.3184 - val_loss: 1.9857 - val_accuracy: 0.3056\n",
      "Epoch 40/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9464 - accuracy: 0.3211 - val_loss: 1.9630 - val_accuracy: 0.3194\n",
      "Epoch 41/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.9051 - accuracy: 0.3199 - val_loss: 1.9764 - val_accuracy: 0.3194\n",
      "Epoch 42/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9161 - accuracy: 0.3027 - val_loss: 1.9727 - val_accuracy: 0.3135\n",
      "Epoch 43/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.9293 - accuracy: 0.3075 - val_loss: 1.9638 - val_accuracy: 0.3095\n",
      "Epoch 44/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9325 - accuracy: 0.3102 - val_loss: 1.9610 - val_accuracy: 0.3353\n",
      "Epoch 45/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9123 - accuracy: 0.3235 - val_loss: 1.9539 - val_accuracy: 0.3274\n",
      "Epoch 46/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9114 - accuracy: 0.3344 - val_loss: 1.9514 - val_accuracy: 0.3353\n",
      "Epoch 47/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8634 - accuracy: 0.3400 - val_loss: 1.9502 - val_accuracy: 0.3413\n",
      "Epoch 48/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8885 - accuracy: 0.3427 - val_loss: 1.9301 - val_accuracy: 0.3512\n",
      "Epoch 49/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8795 - accuracy: 0.3324 - val_loss: 1.9419 - val_accuracy: 0.3393\n",
      "Epoch 50/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.9199 - accuracy: 0.3173 - val_loss: 1.9345 - val_accuracy: 0.3274\n",
      "Epoch 51/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8937 - accuracy: 0.3288 - val_loss: 1.9311 - val_accuracy: 0.3234\n",
      "Epoch 52/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8780 - accuracy: 0.3358 - val_loss: 1.9222 - val_accuracy: 0.3591\n",
      "Epoch 53/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.8607 - accuracy: 0.3541 - val_loss: 1.9150 - val_accuracy: 0.3433\n",
      "Epoch 54/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.8378 - accuracy: 0.3652 - val_loss: 1.9266 - val_accuracy: 0.3095\n",
      "Epoch 55/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.8655 - accuracy: 0.3386 - val_loss: 1.9229 - val_accuracy: 0.3730\n",
      "Epoch 56/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8217 - accuracy: 0.3686 - val_loss: 1.9088 - val_accuracy: 0.3611\n",
      "Epoch 57/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8535 - accuracy: 0.3485 - val_loss: 1.9001 - val_accuracy: 0.3512\n",
      "Epoch 58/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8337 - accuracy: 0.3477 - val_loss: 1.9147 - val_accuracy: 0.3254\n",
      "Epoch 59/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8317 - accuracy: 0.3734 - val_loss: 1.9008 - val_accuracy: 0.3651\n",
      "Epoch 60/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.8080 - accuracy: 0.3542 - val_loss: 1.8991 - val_accuracy: 0.3671\n",
      "Epoch 61/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.8052 - accuracy: 0.3793 - val_loss: 1.8881 - val_accuracy: 0.3571\n",
      "Epoch 62/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.8377 - accuracy: 0.3629 - val_loss: 1.8890 - val_accuracy: 0.3571\n",
      "Epoch 63/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.8065 - accuracy: 0.3650 - val_loss: 1.8799 - val_accuracy: 0.3611\n",
      "Epoch 64/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.8014 - accuracy: 0.3810 - val_loss: 1.8867 - val_accuracy: 0.3631\n",
      "Epoch 65/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.8106 - accuracy: 0.3642 - val_loss: 1.8882 - val_accuracy: 0.3472\n",
      "Epoch 66/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.8231 - accuracy: 0.3651 - val_loss: 1.8712 - val_accuracy: 0.3611\n",
      "Epoch 67/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7692 - accuracy: 0.3833 - val_loss: 1.8735 - val_accuracy: 0.3552\n",
      "Epoch 68/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7700 - accuracy: 0.3853 - val_loss: 1.8728 - val_accuracy: 0.3552\n",
      "Epoch 69/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.7629 - accuracy: 0.4013 - val_loss: 1.8790 - val_accuracy: 0.3433\n",
      "Epoch 70/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7664 - accuracy: 0.4005 - val_loss: 1.8697 - val_accuracy: 0.3690\n",
      "Epoch 71/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7825 - accuracy: 0.3773 - val_loss: 1.8618 - val_accuracy: 0.3512\n",
      "Epoch 72/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7563 - accuracy: 0.4095 - val_loss: 1.8532 - val_accuracy: 0.3611\n",
      "Epoch 73/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7642 - accuracy: 0.3905 - val_loss: 1.8670 - val_accuracy: 0.3492\n",
      "Epoch 74/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7593 - accuracy: 0.4052 - val_loss: 1.8492 - val_accuracy: 0.3393\n",
      "Epoch 75/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7435 - accuracy: 0.3995 - val_loss: 1.8527 - val_accuracy: 0.3690\n",
      "Epoch 76/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7794 - accuracy: 0.3790 - val_loss: 1.8571 - val_accuracy: 0.3552\n",
      "Epoch 77/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7383 - accuracy: 0.3991 - val_loss: 1.8460 - val_accuracy: 0.3710\n",
      "Epoch 78/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7245 - accuracy: 0.4034 - val_loss: 1.8499 - val_accuracy: 0.3671\n",
      "Epoch 79/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7264 - accuracy: 0.3954 - val_loss: 1.8485 - val_accuracy: 0.3651\n",
      "Epoch 80/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7552 - accuracy: 0.3917 - val_loss: 1.8582 - val_accuracy: 0.3552\n",
      "Epoch 81/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7193 - accuracy: 0.4166 - val_loss: 1.8347 - val_accuracy: 0.3591\n",
      "Epoch 82/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7179 - accuracy: 0.4143 - val_loss: 1.8337 - val_accuracy: 0.3651\n",
      "Epoch 83/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7325 - accuracy: 0.4118 - val_loss: 1.8508 - val_accuracy: 0.3393\n",
      "Epoch 84/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6836 - accuracy: 0.4325 - val_loss: 1.8315 - val_accuracy: 0.3611\n",
      "Epoch 85/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7044 - accuracy: 0.4025 - val_loss: 1.8460 - val_accuracy: 0.3651\n",
      "Epoch 86/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7083 - accuracy: 0.4047 - val_loss: 1.8303 - val_accuracy: 0.3690\n",
      "Epoch 87/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7078 - accuracy: 0.4122 - val_loss: 1.8265 - val_accuracy: 0.3730\n",
      "Epoch 88/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6914 - accuracy: 0.4193 - val_loss: 1.8186 - val_accuracy: 0.3730\n",
      "Epoch 89/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.7109 - accuracy: 0.3986 - val_loss: 1.8145 - val_accuracy: 0.3710\n",
      "Epoch 90/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6985 - accuracy: 0.4074 - val_loss: 1.8191 - val_accuracy: 0.3829\n",
      "Epoch 91/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6713 - accuracy: 0.4167 - val_loss: 1.8214 - val_accuracy: 0.3651\n",
      "Epoch 92/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6611 - accuracy: 0.4295 - val_loss: 1.8292 - val_accuracy: 0.3671\n",
      "Epoch 93/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6695 - accuracy: 0.4226 - val_loss: 1.8330 - val_accuracy: 0.3710\n",
      "Epoch 94/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6818 - accuracy: 0.4210 - val_loss: 1.8174 - val_accuracy: 0.3750\n",
      "Epoch 95/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6380 - accuracy: 0.4303 - val_loss: 1.7994 - val_accuracy: 0.3690\n",
      "Epoch 96/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6708 - accuracy: 0.4203 - val_loss: 1.8126 - val_accuracy: 0.3710\n",
      "Epoch 97/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6514 - accuracy: 0.4450 - val_loss: 1.8117 - val_accuracy: 0.3829\n",
      "Epoch 98/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6707 - accuracy: 0.4138 - val_loss: 1.8159 - val_accuracy: 0.3433\n",
      "Epoch 99/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6247 - accuracy: 0.4358 - val_loss: 1.7917 - val_accuracy: 0.3631\n",
      "Epoch 100/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6275 - accuracy: 0.4303 - val_loss: 1.8269 - val_accuracy: 0.3631\n",
      "Epoch 101/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6388 - accuracy: 0.4225 - val_loss: 1.7929 - val_accuracy: 0.3750\n",
      "Epoch 102/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6380 - accuracy: 0.4212 - val_loss: 1.8046 - val_accuracy: 0.3829\n",
      "Epoch 103/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6024 - accuracy: 0.4387 - val_loss: 1.7898 - val_accuracy: 0.3631\n",
      "Epoch 104/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6625 - accuracy: 0.4250 - val_loss: 1.7850 - val_accuracy: 0.3671\n",
      "Epoch 105/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6446 - accuracy: 0.4083 - val_loss: 1.8179 - val_accuracy: 0.3671\n",
      "Epoch 106/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6421 - accuracy: 0.4314 - val_loss: 1.7931 - val_accuracy: 0.3810\n",
      "Epoch 107/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6043 - accuracy: 0.4486 - val_loss: 1.7971 - val_accuracy: 0.3810\n",
      "Epoch 108/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6072 - accuracy: 0.4362 - val_loss: 1.7799 - val_accuracy: 0.3810\n",
      "Epoch 109/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6131 - accuracy: 0.4341 - val_loss: 1.7717 - val_accuracy: 0.3671\n",
      "Epoch 110/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.6273 - accuracy: 0.4384 - val_loss: 1.7731 - val_accuracy: 0.3671\n",
      "Epoch 111/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.5930 - accuracy: 0.4446 - val_loss: 1.7893 - val_accuracy: 0.3810\n",
      "Epoch 112/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.5983 - accuracy: 0.4288 - val_loss: 1.7796 - val_accuracy: 0.3889\n",
      "Epoch 113/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 5s 24ms/step - loss: 1.6037 - accuracy: 0.4328 - val_loss: 1.7765 - val_accuracy: 0.3730\n",
      "Epoch 114/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5733 - accuracy: 0.4665 - val_loss: 1.7677 - val_accuracy: 0.3750\n",
      "Epoch 115/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.6153 - accuracy: 0.4344 - val_loss: 1.8092 - val_accuracy: 0.3790\n",
      "Epoch 116/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5991 - accuracy: 0.4478 - val_loss: 1.8028 - val_accuracy: 0.3611\n",
      "Epoch 117/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5784 - accuracy: 0.4460 - val_loss: 1.7798 - val_accuracy: 0.3869\n",
      "Epoch 118/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5879 - accuracy: 0.4450 - val_loss: 1.7916 - val_accuracy: 0.3770\n",
      "Epoch 119/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5464 - accuracy: 0.4648 - val_loss: 1.8016 - val_accuracy: 0.3730\n",
      "Epoch 120/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5911 - accuracy: 0.4409 - val_loss: 1.7542 - val_accuracy: 0.3829\n",
      "Epoch 121/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5951 - accuracy: 0.4527 - val_loss: 1.7731 - val_accuracy: 0.3869\n",
      "Epoch 122/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5671 - accuracy: 0.4413 - val_loss: 1.7805 - val_accuracy: 0.3730\n",
      "Epoch 123/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5703 - accuracy: 0.4592 - val_loss: 1.7730 - val_accuracy: 0.3770\n",
      "Epoch 124/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5469 - accuracy: 0.4617 - val_loss: 1.7746 - val_accuracy: 0.3829\n",
      "Epoch 125/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5280 - accuracy: 0.4929 - val_loss: 1.7719 - val_accuracy: 0.3810\n",
      "Epoch 126/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5501 - accuracy: 0.4613 - val_loss: 1.7683 - val_accuracy: 0.3770\n",
      "Epoch 127/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5439 - accuracy: 0.4545 - val_loss: 1.7708 - val_accuracy: 0.3810\n",
      "Epoch 128/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5519 - accuracy: 0.4598 - val_loss: 1.7812 - val_accuracy: 0.3869\n",
      "Epoch 129/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5633 - accuracy: 0.4595 - val_loss: 1.7600 - val_accuracy: 0.3810\n",
      "Epoch 130/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5393 - accuracy: 0.4685 - val_loss: 1.7526 - val_accuracy: 0.3968\n",
      "Epoch 131/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5544 - accuracy: 0.4620 - val_loss: 1.7577 - val_accuracy: 0.3929\n",
      "Epoch 132/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5650 - accuracy: 0.4615 - val_loss: 1.7629 - val_accuracy: 0.3889\n",
      "Epoch 133/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5425 - accuracy: 0.4558 - val_loss: 1.7559 - val_accuracy: 0.3770\n",
      "Epoch 134/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5344 - accuracy: 0.4528 - val_loss: 1.7666 - val_accuracy: 0.3849\n",
      "Epoch 135/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5499 - accuracy: 0.4522 - val_loss: 1.7652 - val_accuracy: 0.3829\n",
      "Epoch 136/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5199 - accuracy: 0.4707 - val_loss: 1.7716 - val_accuracy: 0.3849\n",
      "Epoch 137/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5160 - accuracy: 0.4706 - val_loss: 1.7458 - val_accuracy: 0.3849\n",
      "Epoch 138/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5262 - accuracy: 0.4778 - val_loss: 1.7633 - val_accuracy: 0.3810\n",
      "Epoch 139/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5426 - accuracy: 0.4692 - val_loss: 1.7596 - val_accuracy: 0.3909\n",
      "Epoch 140/700\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.5389 - accuracy: 0.4650 - val_loss: 1.7599 - val_accuracy: 0.3869\n",
      "Epoch 141/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.5135 - accuracy: 0.4742 - val_loss: 1.7650 - val_accuracy: 0.3750\n",
      "Epoch 142/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4870 - accuracy: 0.4753 - val_loss: 1.7540 - val_accuracy: 0.3968\n",
      "Epoch 143/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4944 - accuracy: 0.4753 - val_loss: 1.7578 - val_accuracy: 0.3909\n",
      "Epoch 144/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4947 - accuracy: 0.4802 - val_loss: 1.7491 - val_accuracy: 0.3929\n",
      "Epoch 145/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.5097 - accuracy: 0.4656 - val_loss: 1.7731 - val_accuracy: 0.3929\n",
      "Epoch 146/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4661 - accuracy: 0.4970 - val_loss: 1.7563 - val_accuracy: 0.3869\n",
      "Epoch 147/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4747 - accuracy: 0.4997 - val_loss: 1.7462 - val_accuracy: 0.3988\n",
      "Epoch 148/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4950 - accuracy: 0.4690 - val_loss: 1.7404 - val_accuracy: 0.3869\n",
      "Epoch 149/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4824 - accuracy: 0.4823 - val_loss: 1.7585 - val_accuracy: 0.3750\n",
      "Epoch 150/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.5239 - accuracy: 0.4682 - val_loss: 1.7642 - val_accuracy: 0.3929\n",
      "Epoch 151/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4829 - accuracy: 0.4801 - val_loss: 1.7718 - val_accuracy: 0.3849\n",
      "Epoch 152/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4766 - accuracy: 0.4950 - val_loss: 1.7229 - val_accuracy: 0.3988\n",
      "Epoch 153/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4636 - accuracy: 0.4885 - val_loss: 1.7327 - val_accuracy: 0.3849\n",
      "Epoch 154/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4649 - accuracy: 0.5052 - val_loss: 1.7536 - val_accuracy: 0.3710\n",
      "Epoch 155/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4524 - accuracy: 0.5021 - val_loss: 1.7519 - val_accuracy: 0.3968\n",
      "Epoch 156/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4810 - accuracy: 0.4862 - val_loss: 1.7281 - val_accuracy: 0.4048\n",
      "Epoch 157/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4743 - accuracy: 0.4802 - val_loss: 1.7508 - val_accuracy: 0.4048\n",
      "Epoch 158/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4612 - accuracy: 0.4941 - val_loss: 1.7321 - val_accuracy: 0.4127\n",
      "Epoch 159/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4555 - accuracy: 0.5026 - val_loss: 1.7429 - val_accuracy: 0.3909\n",
      "Epoch 160/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4632 - accuracy: 0.4879 - val_loss: 1.7461 - val_accuracy: 0.4067\n",
      "Epoch 161/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4761 - accuracy: 0.4906 - val_loss: 1.7433 - val_accuracy: 0.4107\n",
      "Epoch 162/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4339 - accuracy: 0.4967 - val_loss: 1.7392 - val_accuracy: 0.4048\n",
      "Epoch 163/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4616 - accuracy: 0.4935 - val_loss: 1.7439 - val_accuracy: 0.3968\n",
      "Epoch 164/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4161 - accuracy: 0.4923 - val_loss: 1.7492 - val_accuracy: 0.4028\n",
      "Epoch 165/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4450 - accuracy: 0.4988 - val_loss: 1.7483 - val_accuracy: 0.3968\n",
      "Epoch 166/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4071 - accuracy: 0.5018 - val_loss: 1.7554 - val_accuracy: 0.4008\n",
      "Epoch 167/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4409 - accuracy: 0.5032 - val_loss: 1.7402 - val_accuracy: 0.4048\n",
      "Epoch 168/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.4472 - accuracy: 0.5064 - val_loss: 1.7424 - val_accuracy: 0.3889\n",
      "Epoch 169/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3799 - accuracy: 0.5275 - val_loss: 1.7569 - val_accuracy: 0.3810\n",
      "Epoch 170/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4241 - accuracy: 0.4906 - val_loss: 1.7360 - val_accuracy: 0.3988\n",
      "Epoch 171/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4118 - accuracy: 0.5099 - val_loss: 1.7292 - val_accuracy: 0.4048\n",
      "Epoch 172/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4071 - accuracy: 0.5008 - val_loss: 1.7296 - val_accuracy: 0.4028\n",
      "Epoch 173/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3930 - accuracy: 0.5203 - val_loss: 1.7313 - val_accuracy: 0.4107\n",
      "Epoch 174/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4331 - accuracy: 0.4875 - val_loss: 1.7349 - val_accuracy: 0.4087\n",
      "Epoch 175/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4036 - accuracy: 0.5302 - val_loss: 1.7228 - val_accuracy: 0.4127\n",
      "Epoch 176/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3698 - accuracy: 0.5235 - val_loss: 1.7716 - val_accuracy: 0.3790\n",
      "Epoch 177/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4001 - accuracy: 0.5055 - val_loss: 1.7269 - val_accuracy: 0.4167\n",
      "Epoch 178/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3762 - accuracy: 0.5355 - val_loss: 1.7616 - val_accuracy: 0.3869\n",
      "Epoch 179/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4178 - accuracy: 0.4907 - val_loss: 1.7190 - val_accuracy: 0.4048\n",
      "Epoch 180/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4149 - accuracy: 0.5117 - val_loss: 1.7403 - val_accuracy: 0.3988\n",
      "Epoch 181/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4201 - accuracy: 0.5071 - val_loss: 1.7378 - val_accuracy: 0.4167\n",
      "Epoch 182/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3921 - accuracy: 0.5077 - val_loss: 1.7288 - val_accuracy: 0.4067\n",
      "Epoch 183/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3823 - accuracy: 0.5159 - val_loss: 1.7397 - val_accuracy: 0.4048\n",
      "Epoch 184/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3761 - accuracy: 0.5061 - val_loss: 1.7053 - val_accuracy: 0.4028\n",
      "Epoch 185/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3664 - accuracy: 0.5127 - val_loss: 1.7287 - val_accuracy: 0.3968\n",
      "Epoch 186/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3666 - accuracy: 0.5105 - val_loss: 1.7217 - val_accuracy: 0.4087\n",
      "Epoch 187/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4089 - accuracy: 0.5092 - val_loss: 1.7190 - val_accuracy: 0.4107\n",
      "Epoch 188/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3837 - accuracy: 0.5283 - val_loss: 1.7366 - val_accuracy: 0.4127\n",
      "Epoch 189/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3425 - accuracy: 0.5327 - val_loss: 1.7239 - val_accuracy: 0.4127\n",
      "Epoch 190/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.3719 - accuracy: 0.5288 - val_loss: 1.7242 - val_accuracy: 0.4127\n",
      "Epoch 191/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.3715 - accuracy: 0.5019 - val_loss: 1.7354 - val_accuracy: 0.4167\n",
      "Epoch 192/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3594 - accuracy: 0.5245 - val_loss: 1.7216 - val_accuracy: 0.4226\n",
      "Epoch 193/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.3505 - accuracy: 0.5296 - val_loss: 1.7085 - val_accuracy: 0.4246\n",
      "Epoch 194/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.4087 - accuracy: 0.5072 - val_loss: 1.7218 - val_accuracy: 0.4107\n",
      "Epoch 195/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3426 - accuracy: 0.5352 - val_loss: 1.7137 - val_accuracy: 0.4226\n",
      "Epoch 196/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.3643 - accuracy: 0.5238 - val_loss: 1.7254 - val_accuracy: 0.4127\n",
      "Epoch 197/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3421 - accuracy: 0.5408 - val_loss: 1.7128 - val_accuracy: 0.4087\n",
      "Epoch 198/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3419 - accuracy: 0.5355 - val_loss: 1.7135 - val_accuracy: 0.4206\n",
      "Epoch 199/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3350 - accuracy: 0.5348 - val_loss: 1.7077 - val_accuracy: 0.4246\n",
      "Epoch 200/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2903 - accuracy: 0.5566 - val_loss: 1.7153 - val_accuracy: 0.4206\n",
      "Epoch 201/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3484 - accuracy: 0.5276 - val_loss: 1.7311 - val_accuracy: 0.3929\n",
      "Epoch 202/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3528 - accuracy: 0.5222 - val_loss: 1.7282 - val_accuracy: 0.4226\n",
      "Epoch 203/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3454 - accuracy: 0.5323 - val_loss: 1.7169 - val_accuracy: 0.4246\n",
      "Epoch 204/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3480 - accuracy: 0.5298 - val_loss: 1.7221 - val_accuracy: 0.4028\n",
      "Epoch 205/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3400 - accuracy: 0.5335 - val_loss: 1.7125 - val_accuracy: 0.4067\n",
      "Epoch 206/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3299 - accuracy: 0.5382 - val_loss: 1.7064 - val_accuracy: 0.4187\n",
      "Epoch 207/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3174 - accuracy: 0.5408 - val_loss: 1.7586 - val_accuracy: 0.4107\n",
      "Epoch 208/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3278 - accuracy: 0.5339 - val_loss: 1.7069 - val_accuracy: 0.4048\n",
      "Epoch 209/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3234 - accuracy: 0.5397 - val_loss: 1.7314 - val_accuracy: 0.4087\n",
      "Epoch 210/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3069 - accuracy: 0.5464 - val_loss: 1.7163 - val_accuracy: 0.4266\n",
      "Epoch 211/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3097 - accuracy: 0.5491 - val_loss: 1.7535 - val_accuracy: 0.4067\n",
      "Epoch 212/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3322 - accuracy: 0.5240 - val_loss: 1.7539 - val_accuracy: 0.3948\n",
      "Epoch 213/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3182 - accuracy: 0.5444 - val_loss: 1.7219 - val_accuracy: 0.4087\n",
      "Epoch 214/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3005 - accuracy: 0.5488 - val_loss: 1.7165 - val_accuracy: 0.4167\n",
      "Epoch 215/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2879 - accuracy: 0.5477 - val_loss: 1.6982 - val_accuracy: 0.4167\n",
      "Epoch 216/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3265 - accuracy: 0.5375 - val_loss: 1.7145 - val_accuracy: 0.4107\n",
      "Epoch 217/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2934 - accuracy: 0.5452 - val_loss: 1.7146 - val_accuracy: 0.4147\n",
      "Epoch 218/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2866 - accuracy: 0.5392 - val_loss: 1.7258 - val_accuracy: 0.4048\n",
      "Epoch 219/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2995 - accuracy: 0.5495 - val_loss: 1.7043 - val_accuracy: 0.4127\n",
      "Epoch 220/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3029 - accuracy: 0.5473 - val_loss: 1.7149 - val_accuracy: 0.4127\n",
      "Epoch 221/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2704 - accuracy: 0.5551 - val_loss: 1.7158 - val_accuracy: 0.4107\n",
      "Epoch 222/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2925 - accuracy: 0.5569 - val_loss: 1.7645 - val_accuracy: 0.3948\n",
      "Epoch 223/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2500 - accuracy: 0.5488 - val_loss: 1.7044 - val_accuracy: 0.4187\n",
      "Epoch 224/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2841 - accuracy: 0.5500 - val_loss: 1.7151 - val_accuracy: 0.3968\n",
      "Epoch 225/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2993 - accuracy: 0.5304 - val_loss: 1.7237 - val_accuracy: 0.4008\n",
      "Epoch 226/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2801 - accuracy: 0.5381 - val_loss: 1.6970 - val_accuracy: 0.4206\n",
      "Epoch 227/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2910 - accuracy: 0.5435 - val_loss: 1.6963 - val_accuracy: 0.4444\n",
      "Epoch 228/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2664 - accuracy: 0.5704 - val_loss: 1.7397 - val_accuracy: 0.4107\n",
      "Epoch 229/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2677 - accuracy: 0.5641 - val_loss: 1.7441 - val_accuracy: 0.4028\n",
      "Epoch 230/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2737 - accuracy: 0.5547 - val_loss: 1.7174 - val_accuracy: 0.4147\n",
      "Epoch 231/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2856 - accuracy: 0.5572 - val_loss: 1.7201 - val_accuracy: 0.4067\n",
      "Epoch 232/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2360 - accuracy: 0.5519 - val_loss: 1.7180 - val_accuracy: 0.4246\n",
      "Epoch 233/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2746 - accuracy: 0.5332 - val_loss: 1.7056 - val_accuracy: 0.4067\n",
      "Epoch 234/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.2367 - accuracy: 0.5609 - val_loss: 1.7039 - val_accuracy: 0.4206\n",
      "Epoch 235/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.2604 - accuracy: 0.5523 - val_loss: 1.7278 - val_accuracy: 0.4147\n",
      "Epoch 236/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2310 - accuracy: 0.5618 - val_loss: 1.7552 - val_accuracy: 0.4087\n",
      "Epoch 237/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2567 - accuracy: 0.5532 - val_loss: 1.7377 - val_accuracy: 0.3968\n",
      "Epoch 238/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2622 - accuracy: 0.5486 - val_loss: 1.7561 - val_accuracy: 0.4048\n",
      "Epoch 239/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2296 - accuracy: 0.5714 - val_loss: 1.7403 - val_accuracy: 0.4067\n",
      "Epoch 240/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2170 - accuracy: 0.5643 - val_loss: 1.7257 - val_accuracy: 0.4087\n",
      "Epoch 241/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2329 - accuracy: 0.5784 - val_loss: 1.7048 - val_accuracy: 0.4127\n",
      "Epoch 242/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2438 - accuracy: 0.5607 - val_loss: 1.7324 - val_accuracy: 0.4048\n",
      "Epoch 243/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2171 - accuracy: 0.5774 - val_loss: 1.7106 - val_accuracy: 0.4107\n",
      "Epoch 244/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2494 - accuracy: 0.5614 - val_loss: 1.7447 - val_accuracy: 0.4028\n",
      "Epoch 245/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2340 - accuracy: 0.5644 - val_loss: 1.7104 - val_accuracy: 0.4266\n",
      "Epoch 246/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.2681 - accuracy: 0.5649 - val_loss: 1.7149 - val_accuracy: 0.4206\n",
      "Epoch 247/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2445 - accuracy: 0.5686 - val_loss: 1.6871 - val_accuracy: 0.4147\n",
      "Epoch 248/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2059 - accuracy: 0.5774 - val_loss: 1.7104 - val_accuracy: 0.4067\n",
      "Epoch 249/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1939 - accuracy: 0.5950 - val_loss: 1.7345 - val_accuracy: 0.4067\n",
      "Epoch 250/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2243 - accuracy: 0.5843 - val_loss: 1.7044 - val_accuracy: 0.4187\n",
      "Epoch 251/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2138 - accuracy: 0.5771 - val_loss: 1.7164 - val_accuracy: 0.4167\n",
      "Epoch 252/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2117 - accuracy: 0.5768 - val_loss: 1.7271 - val_accuracy: 0.3988\n",
      "Epoch 253/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2054 - accuracy: 0.5868 - val_loss: 1.7095 - val_accuracy: 0.4127\n",
      "Epoch 254/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2013 - accuracy: 0.5741 - val_loss: 1.6985 - val_accuracy: 0.4266\n",
      "Epoch 255/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2330 - accuracy: 0.5694 - val_loss: 1.7059 - val_accuracy: 0.4127\n",
      "Epoch 256/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2106 - accuracy: 0.5858 - val_loss: 1.7193 - val_accuracy: 0.4246\n",
      "Epoch 257/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2264 - accuracy: 0.5775 - val_loss: 1.7163 - val_accuracy: 0.4226\n",
      "Epoch 258/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1988 - accuracy: 0.5791 - val_loss: 1.7937 - val_accuracy: 0.4028\n",
      "Epoch 259/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1949 - accuracy: 0.5915 - val_loss: 1.7299 - val_accuracy: 0.4127\n",
      "Epoch 260/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.2039 - accuracy: 0.5721 - val_loss: 1.7555 - val_accuracy: 0.4067\n",
      "Epoch 261/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1941 - accuracy: 0.5922 - val_loss: 1.7091 - val_accuracy: 0.4127\n",
      "Epoch 262/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1503 - accuracy: 0.6001 - val_loss: 1.7354 - val_accuracy: 0.4087\n",
      "Epoch 263/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1644 - accuracy: 0.5889 - val_loss: 1.7185 - val_accuracy: 0.4087\n",
      "Epoch 264/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1793 - accuracy: 0.5898 - val_loss: 1.7110 - val_accuracy: 0.4187\n",
      "Epoch 265/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1944 - accuracy: 0.5842 - val_loss: 1.7152 - val_accuracy: 0.4226\n",
      "Epoch 266/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1513 - accuracy: 0.5834 - val_loss: 1.7045 - val_accuracy: 0.4067\n",
      "Epoch 267/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1944 - accuracy: 0.5819 - val_loss: 1.7281 - val_accuracy: 0.4127\n",
      "Epoch 268/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1814 - accuracy: 0.5785 - val_loss: 1.7300 - val_accuracy: 0.4087\n",
      "Epoch 269/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.1677 - accuracy: 0.5894 - val_loss: 1.7464 - val_accuracy: 0.4048\n",
      "Epoch 270/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.1912 - accuracy: 0.5780 - val_loss: 1.7052 - val_accuracy: 0.4365\n",
      "Epoch 271/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1682 - accuracy: 0.5972 - val_loss: 1.7052 - val_accuracy: 0.4187\n",
      "Epoch 272/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1904 - accuracy: 0.5854 - val_loss: 1.7378 - val_accuracy: 0.4187\n",
      "Epoch 273/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1562 - accuracy: 0.5957 - val_loss: 1.7080 - val_accuracy: 0.4266\n",
      "Epoch 274/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1805 - accuracy: 0.5885 - val_loss: 1.7511 - val_accuracy: 0.4067\n",
      "Epoch 275/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1559 - accuracy: 0.5994 - val_loss: 1.7020 - val_accuracy: 0.4167\n",
      "Epoch 276/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1418 - accuracy: 0.6005 - val_loss: 1.7374 - val_accuracy: 0.4087\n",
      "Epoch 277/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1552 - accuracy: 0.6044 - val_loss: 1.7254 - val_accuracy: 0.4127\n",
      "Epoch 278/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1581 - accuracy: 0.5914 - val_loss: 1.7501 - val_accuracy: 0.4206\n",
      "Epoch 279/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1505 - accuracy: 0.5966 - val_loss: 1.7191 - val_accuracy: 0.4048\n",
      "Epoch 280/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.1846 - accuracy: 0.5731 - val_loss: 1.7075 - val_accuracy: 0.4266\n",
      "Epoch 281/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1551 - accuracy: 0.5962 - val_loss: 1.7333 - val_accuracy: 0.4087\n",
      "Epoch 282/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1531 - accuracy: 0.6037 - val_loss: 1.7360 - val_accuracy: 0.4286\n",
      "Epoch 283/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1549 - accuracy: 0.5845 - val_loss: 1.7393 - val_accuracy: 0.4187\n",
      "Epoch 284/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1575 - accuracy: 0.5955 - val_loss: 1.7074 - val_accuracy: 0.4306\n",
      "Epoch 285/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1519 - accuracy: 0.5978 - val_loss: 1.7515 - val_accuracy: 0.4087\n",
      "Epoch 286/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1322 - accuracy: 0.6104 - val_loss: 1.7349 - val_accuracy: 0.4008\n",
      "Epoch 287/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1684 - accuracy: 0.5890 - val_loss: 1.7352 - val_accuracy: 0.4048\n",
      "Epoch 288/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1565 - accuracy: 0.6010 - val_loss: 1.7292 - val_accuracy: 0.4107\n",
      "Epoch 289/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1574 - accuracy: 0.5792 - val_loss: 1.7272 - val_accuracy: 0.4147\n",
      "Epoch 290/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1276 - accuracy: 0.6049 - val_loss: 1.7475 - val_accuracy: 0.4127\n",
      "Epoch 291/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1332 - accuracy: 0.6043 - val_loss: 1.6975 - val_accuracy: 0.4226\n",
      "Epoch 292/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1584 - accuracy: 0.5980 - val_loss: 1.7224 - val_accuracy: 0.4127\n",
      "Epoch 293/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1337 - accuracy: 0.6026 - val_loss: 1.7330 - val_accuracy: 0.4008\n",
      "Epoch 294/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1263 - accuracy: 0.5987 - val_loss: 1.7151 - val_accuracy: 0.4087\n",
      "Epoch 295/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1118 - accuracy: 0.6061 - val_loss: 1.7223 - val_accuracy: 0.4028\n",
      "Epoch 296/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1161 - accuracy: 0.6042 - val_loss: 1.7212 - val_accuracy: 0.4226\n",
      "Epoch 297/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1044 - accuracy: 0.6239 - val_loss: 1.7664 - val_accuracy: 0.3869\n",
      "Epoch 298/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1313 - accuracy: 0.6114 - val_loss: 1.7566 - val_accuracy: 0.3988\n",
      "Epoch 299/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1079 - accuracy: 0.6060 - val_loss: 1.7574 - val_accuracy: 0.4008\n",
      "Epoch 300/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1190 - accuracy: 0.5931 - val_loss: 1.7548 - val_accuracy: 0.4246\n",
      "Epoch 301/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1281 - accuracy: 0.6003 - val_loss: 1.8034 - val_accuracy: 0.4048\n",
      "Epoch 302/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0970 - accuracy: 0.6028 - val_loss: 1.7537 - val_accuracy: 0.4167\n",
      "Epoch 303/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1119 - accuracy: 0.6001 - val_loss: 1.7577 - val_accuracy: 0.4087\n",
      "Epoch 304/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1122 - accuracy: 0.6046 - val_loss: 1.7270 - val_accuracy: 0.3988\n",
      "Epoch 305/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1101 - accuracy: 0.6185 - val_loss: 1.7330 - val_accuracy: 0.4167\n",
      "Epoch 306/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1415 - accuracy: 0.5933 - val_loss: 1.7255 - val_accuracy: 0.4246\n",
      "Epoch 307/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0641 - accuracy: 0.6289 - val_loss: 1.7705 - val_accuracy: 0.3829\n",
      "Epoch 308/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0546 - accuracy: 0.6247 - val_loss: 1.7089 - val_accuracy: 0.4206\n",
      "Epoch 309/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0999 - accuracy: 0.6098 - val_loss: 1.8351 - val_accuracy: 0.3829\n",
      "Epoch 310/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1043 - accuracy: 0.6005 - val_loss: 1.7478 - val_accuracy: 0.4226\n",
      "Epoch 311/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1211 - accuracy: 0.6043 - val_loss: 1.7164 - val_accuracy: 0.4246\n",
      "Epoch 312/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.1074 - accuracy: 0.6113 - val_loss: 1.7622 - val_accuracy: 0.3988\n",
      "Epoch 313/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0861 - accuracy: 0.6112 - val_loss: 1.7270 - val_accuracy: 0.4008\n",
      "Epoch 314/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0795 - accuracy: 0.6315 - val_loss: 1.7416 - val_accuracy: 0.3968\n",
      "Epoch 315/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0772 - accuracy: 0.6069 - val_loss: 1.7589 - val_accuracy: 0.3988\n",
      "Epoch 316/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0642 - accuracy: 0.6212 - val_loss: 1.7763 - val_accuracy: 0.3968\n",
      "Epoch 317/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0601 - accuracy: 0.6142 - val_loss: 1.8160 - val_accuracy: 0.3810\n",
      "Epoch 318/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0719 - accuracy: 0.6186 - val_loss: 1.7723 - val_accuracy: 0.3770\n",
      "Epoch 319/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0621 - accuracy: 0.6376 - val_loss: 1.7553 - val_accuracy: 0.4206\n",
      "Epoch 320/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0917 - accuracy: 0.5939 - val_loss: 1.7385 - val_accuracy: 0.4206\n",
      "Epoch 321/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0834 - accuracy: 0.6111 - val_loss: 1.7874 - val_accuracy: 0.4028\n",
      "Epoch 322/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0613 - accuracy: 0.6158 - val_loss: 1.7132 - val_accuracy: 0.4048\n",
      "Epoch 323/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0435 - accuracy: 0.6250 - val_loss: 1.7350 - val_accuracy: 0.4067\n",
      "Epoch 324/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0910 - accuracy: 0.6136 - val_loss: 1.7824 - val_accuracy: 0.4167\n",
      "Epoch 325/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0325 - accuracy: 0.6442 - val_loss: 1.7391 - val_accuracy: 0.4365\n",
      "Epoch 326/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0304 - accuracy: 0.6363 - val_loss: 1.7650 - val_accuracy: 0.4048\n",
      "Epoch 327/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0450 - accuracy: 0.6187 - val_loss: 1.7575 - val_accuracy: 0.4028\n",
      "Epoch 328/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0644 - accuracy: 0.6374 - val_loss: 1.7495 - val_accuracy: 0.4306\n",
      "Epoch 329/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0623 - accuracy: 0.6275 - val_loss: 1.7748 - val_accuracy: 0.4067\n",
      "Epoch 330/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0542 - accuracy: 0.6293 - val_loss: 1.7337 - val_accuracy: 0.4028\n",
      "Epoch 331/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0363 - accuracy: 0.6372 - val_loss: 1.7304 - val_accuracy: 0.4167\n",
      "Epoch 332/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0654 - accuracy: 0.6378 - val_loss: 1.7619 - val_accuracy: 0.4087\n",
      "Epoch 333/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0263 - accuracy: 0.6366 - val_loss: 1.7374 - val_accuracy: 0.4206\n",
      "Epoch 334/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0295 - accuracy: 0.6344 - val_loss: 1.7304 - val_accuracy: 0.4206\n",
      "Epoch 335/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0283 - accuracy: 0.6315 - val_loss: 1.8378 - val_accuracy: 0.3849\n",
      "Epoch 336/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0169 - accuracy: 0.6409 - val_loss: 1.7424 - val_accuracy: 0.4107\n",
      "Epoch 337/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0250 - accuracy: 0.6420 - val_loss: 1.7416 - val_accuracy: 0.4187\n",
      "Epoch 338/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0386 - accuracy: 0.6396 - val_loss: 1.7358 - val_accuracy: 0.3988\n",
      "Epoch 339/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0413 - accuracy: 0.6475 - val_loss: 1.7571 - val_accuracy: 0.4107\n",
      "Epoch 340/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0426 - accuracy: 0.6267 - val_loss: 1.7878 - val_accuracy: 0.4107\n",
      "Epoch 341/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0246 - accuracy: 0.6401 - val_loss: 1.7848 - val_accuracy: 0.4028\n",
      "Epoch 342/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0234 - accuracy: 0.6304 - val_loss: 1.7797 - val_accuracy: 0.4067\n",
      "Epoch 343/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0101 - accuracy: 0.6433 - val_loss: 1.7479 - val_accuracy: 0.4187\n",
      "Epoch 344/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0236 - accuracy: 0.6379 - val_loss: 1.7122 - val_accuracy: 0.4345\n",
      "Epoch 345/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0061 - accuracy: 0.6412 - val_loss: 1.7777 - val_accuracy: 0.4107\n",
      "Epoch 346/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0180 - accuracy: 0.6436 - val_loss: 1.7965 - val_accuracy: 0.4087\n",
      "Epoch 347/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0321 - accuracy: 0.6312 - val_loss: 1.7320 - val_accuracy: 0.4206\n",
      "Epoch 348/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0115 - accuracy: 0.6385 - val_loss: 1.7476 - val_accuracy: 0.4147\n",
      "Epoch 349/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0008 - accuracy: 0.6522 - val_loss: 1.7309 - val_accuracy: 0.4087\n",
      "Epoch 350/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0026 - accuracy: 0.6476 - val_loss: 1.7590 - val_accuracy: 0.4087\n",
      "Epoch 351/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0134 - accuracy: 0.6396 - val_loss: 1.7724 - val_accuracy: 0.4127\n",
      "Epoch 352/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0257 - accuracy: 0.6198 - val_loss: 1.7991 - val_accuracy: 0.4107\n",
      "Epoch 353/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9920 - accuracy: 0.6436 - val_loss: 1.7778 - val_accuracy: 0.4087\n",
      "Epoch 354/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0263 - accuracy: 0.6475 - val_loss: 1.7833 - val_accuracy: 0.4048\n",
      "Epoch 355/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0095 - accuracy: 0.6388 - val_loss: 1.7567 - val_accuracy: 0.4147\n",
      "Epoch 356/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0144 - accuracy: 0.6238 - val_loss: 1.7851 - val_accuracy: 0.4008\n",
      "Epoch 357/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0022 - accuracy: 0.6437 - val_loss: 1.7554 - val_accuracy: 0.4048\n",
      "Epoch 358/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.9986 - accuracy: 0.6364 - val_loss: 1.7782 - val_accuracy: 0.4048\n",
      "Epoch 359/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.0013 - accuracy: 0.6453 - val_loss: 1.7488 - val_accuracy: 0.4325\n",
      "Epoch 360/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9764 - accuracy: 0.6532 - val_loss: 1.8158 - val_accuracy: 0.4028\n",
      "Epoch 361/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0129 - accuracy: 0.6465 - val_loss: 1.7959 - val_accuracy: 0.4107\n",
      "Epoch 362/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9771 - accuracy: 0.6577 - val_loss: 1.7667 - val_accuracy: 0.4028\n",
      "Epoch 363/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9901 - accuracy: 0.6521 - val_loss: 1.7472 - val_accuracy: 0.4067\n",
      "Epoch 364/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9620 - accuracy: 0.6649 - val_loss: 1.7918 - val_accuracy: 0.4087\n",
      "Epoch 365/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9480 - accuracy: 0.6644 - val_loss: 1.7799 - val_accuracy: 0.4187\n",
      "Epoch 366/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9878 - accuracy: 0.6280 - val_loss: 1.7970 - val_accuracy: 0.4067\n",
      "Epoch 367/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9913 - accuracy: 0.6560 - val_loss: 1.7585 - val_accuracy: 0.4226\n",
      "Epoch 368/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0083 - accuracy: 0.6263 - val_loss: 1.7466 - val_accuracy: 0.4206\n",
      "Epoch 369/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9539 - accuracy: 0.6702 - val_loss: 1.7804 - val_accuracy: 0.3988\n",
      "Epoch 370/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0029 - accuracy: 0.6298 - val_loss: 1.7687 - val_accuracy: 0.4187\n",
      "Epoch 371/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9868 - accuracy: 0.6417 - val_loss: 1.7919 - val_accuracy: 0.3968\n",
      "Epoch 372/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9813 - accuracy: 0.6511 - val_loss: 1.7959 - val_accuracy: 0.3869\n",
      "Epoch 373/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9691 - accuracy: 0.6547 - val_loss: 1.7826 - val_accuracy: 0.4067\n",
      "Epoch 374/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9914 - accuracy: 0.6520 - val_loss: 1.7725 - val_accuracy: 0.4266\n",
      "Epoch 375/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9779 - accuracy: 0.6358 - val_loss: 1.8031 - val_accuracy: 0.3889\n",
      "Epoch 376/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9873 - accuracy: 0.6556 - val_loss: 1.8717 - val_accuracy: 0.3988\n",
      "Epoch 377/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9784 - accuracy: 0.6563 - val_loss: 1.7620 - val_accuracy: 0.4325\n",
      "Epoch 378/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.0033 - accuracy: 0.6400 - val_loss: 1.8028 - val_accuracy: 0.4127\n",
      "Epoch 379/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9376 - accuracy: 0.6673 - val_loss: 1.7656 - val_accuracy: 0.4167\n",
      "Epoch 380/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9138 - accuracy: 0.6587 - val_loss: 1.7487 - val_accuracy: 0.4306\n",
      "Epoch 381/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9580 - accuracy: 0.6564 - val_loss: 1.7778 - val_accuracy: 0.4385\n",
      "Epoch 382/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9547 - accuracy: 0.6502 - val_loss: 1.8215 - val_accuracy: 0.3829\n",
      "Epoch 383/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9531 - accuracy: 0.6547 - val_loss: 1.7941 - val_accuracy: 0.3948\n",
      "Epoch 384/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9699 - accuracy: 0.6526 - val_loss: 1.7950 - val_accuracy: 0.4206\n",
      "Epoch 385/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9302 - accuracy: 0.6771 - val_loss: 1.8340 - val_accuracy: 0.4147\n",
      "Epoch 386/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9451 - accuracy: 0.6563 - val_loss: 1.7788 - val_accuracy: 0.4167\n",
      "Epoch 387/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9528 - accuracy: 0.6495 - val_loss: 1.8287 - val_accuracy: 0.4187\n",
      "Epoch 388/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9220 - accuracy: 0.6664 - val_loss: 1.8320 - val_accuracy: 0.3929\n",
      "Epoch 389/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9138 - accuracy: 0.6721 - val_loss: 1.8021 - val_accuracy: 0.4008\n",
      "Epoch 390/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9384 - accuracy: 0.6648 - val_loss: 1.8343 - val_accuracy: 0.4028\n",
      "Epoch 391/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9450 - accuracy: 0.6556 - val_loss: 1.7940 - val_accuracy: 0.4206\n",
      "Epoch 392/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9396 - accuracy: 0.6675 - val_loss: 1.8123 - val_accuracy: 0.4187\n",
      "Epoch 393/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9293 - accuracy: 0.6589 - val_loss: 1.8073 - val_accuracy: 0.4187\n",
      "Epoch 394/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9590 - accuracy: 0.6620 - val_loss: 1.7797 - val_accuracy: 0.4187\n",
      "Epoch 395/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9394 - accuracy: 0.6591 - val_loss: 1.8287 - val_accuracy: 0.4167\n",
      "Epoch 396/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9322 - accuracy: 0.6623 - val_loss: 1.8380 - val_accuracy: 0.4107\n",
      "Epoch 397/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9380 - accuracy: 0.6596 - val_loss: 1.8091 - val_accuracy: 0.4107\n",
      "Epoch 398/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9421 - accuracy: 0.6542 - val_loss: 1.8293 - val_accuracy: 0.4187\n",
      "Epoch 399/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9211 - accuracy: 0.6748 - val_loss: 1.8374 - val_accuracy: 0.4206\n",
      "Epoch 400/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9054 - accuracy: 0.6698 - val_loss: 1.8071 - val_accuracy: 0.4226\n",
      "Epoch 401/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9485 - accuracy: 0.6545 - val_loss: 1.8080 - val_accuracy: 0.4187\n",
      "Epoch 402/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9663 - accuracy: 0.6563 - val_loss: 1.8302 - val_accuracy: 0.4187\n",
      "Epoch 403/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9447 - accuracy: 0.6588 - val_loss: 1.8227 - val_accuracy: 0.4048\n",
      "Epoch 404/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9105 - accuracy: 0.6840 - val_loss: 1.7791 - val_accuracy: 0.4306\n",
      "Epoch 405/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9340 - accuracy: 0.6704 - val_loss: 1.7940 - val_accuracy: 0.4167\n",
      "Epoch 406/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9244 - accuracy: 0.6673 - val_loss: 1.8068 - val_accuracy: 0.4087\n",
      "Epoch 407/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.9561 - accuracy: 0.6616 - val_loss: 1.7995 - val_accuracy: 0.4226\n",
      "Epoch 408/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9063 - accuracy: 0.6761 - val_loss: 1.8163 - val_accuracy: 0.4087\n",
      "Epoch 409/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9295 - accuracy: 0.6680 - val_loss: 1.7741 - val_accuracy: 0.4187\n",
      "Epoch 410/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8986 - accuracy: 0.6820 - val_loss: 1.8767 - val_accuracy: 0.4107\n",
      "Epoch 411/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8947 - accuracy: 0.6857 - val_loss: 1.8289 - val_accuracy: 0.4107\n",
      "Epoch 412/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9134 - accuracy: 0.6827 - val_loss: 1.8093 - val_accuracy: 0.4127\n",
      "Epoch 413/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9068 - accuracy: 0.6754 - val_loss: 1.8294 - val_accuracy: 0.4226\n",
      "Epoch 414/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9115 - accuracy: 0.6698 - val_loss: 1.7982 - val_accuracy: 0.4325\n",
      "Epoch 415/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9147 - accuracy: 0.6722 - val_loss: 1.8077 - val_accuracy: 0.4147\n",
      "Epoch 416/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8971 - accuracy: 0.6810 - val_loss: 1.8479 - val_accuracy: 0.3968\n",
      "Epoch 417/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8805 - accuracy: 0.6937 - val_loss: 1.8437 - val_accuracy: 0.3948\n",
      "Epoch 418/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8964 - accuracy: 0.6647 - val_loss: 1.8345 - val_accuracy: 0.4266\n",
      "Epoch 419/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8955 - accuracy: 0.6794 - val_loss: 1.8510 - val_accuracy: 0.4028\n",
      "Epoch 420/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8867 - accuracy: 0.6790 - val_loss: 1.8239 - val_accuracy: 0.4067\n",
      "Epoch 421/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8867 - accuracy: 0.6813 - val_loss: 1.8643 - val_accuracy: 0.3889\n",
      "Epoch 422/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9010 - accuracy: 0.6716 - val_loss: 1.7930 - val_accuracy: 0.4187\n",
      "Epoch 423/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9085 - accuracy: 0.6784 - val_loss: 1.8145 - val_accuracy: 0.4226\n",
      "Epoch 424/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9138 - accuracy: 0.6571 - val_loss: 1.8660 - val_accuracy: 0.3948\n",
      "Epoch 425/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8664 - accuracy: 0.7003 - val_loss: 1.8438 - val_accuracy: 0.4187\n",
      "Epoch 426/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9033 - accuracy: 0.6862 - val_loss: 1.9025 - val_accuracy: 0.4028\n",
      "Epoch 427/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8618 - accuracy: 0.6971 - val_loss: 1.8193 - val_accuracy: 0.4067\n",
      "Epoch 428/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8634 - accuracy: 0.6947 - val_loss: 1.8542 - val_accuracy: 0.4127\n",
      "Epoch 429/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8742 - accuracy: 0.6923 - val_loss: 1.8992 - val_accuracy: 0.3988\n",
      "Epoch 430/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.9074 - accuracy: 0.6815 - val_loss: 1.8095 - val_accuracy: 0.4246\n",
      "Epoch 431/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8984 - accuracy: 0.6882 - val_loss: 1.8199 - val_accuracy: 0.4127\n",
      "Epoch 432/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8610 - accuracy: 0.6941 - val_loss: 1.8018 - val_accuracy: 0.4127\n",
      "Epoch 433/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8829 - accuracy: 0.6833 - val_loss: 1.8306 - val_accuracy: 0.4226\n",
      "Epoch 434/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8586 - accuracy: 0.6829 - val_loss: 1.8575 - val_accuracy: 0.4127\n",
      "Epoch 435/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8795 - accuracy: 0.6924 - val_loss: 1.8323 - val_accuracy: 0.4107\n",
      "Epoch 436/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8880 - accuracy: 0.6656 - val_loss: 1.8660 - val_accuracy: 0.4167\n",
      "Epoch 437/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8524 - accuracy: 0.7077 - val_loss: 1.8260 - val_accuracy: 0.4087\n",
      "Epoch 438/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8544 - accuracy: 0.7023 - val_loss: 1.8758 - val_accuracy: 0.4127\n",
      "Epoch 439/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8868 - accuracy: 0.6771 - val_loss: 1.8984 - val_accuracy: 0.3988\n",
      "Epoch 440/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8831 - accuracy: 0.6854 - val_loss: 1.9467 - val_accuracy: 0.3810\n",
      "Epoch 441/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8493 - accuracy: 0.6914 - val_loss: 1.9188 - val_accuracy: 0.3909\n",
      "Epoch 442/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8630 - accuracy: 0.6871 - val_loss: 1.8329 - val_accuracy: 0.4306\n",
      "Epoch 443/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8856 - accuracy: 0.6789 - val_loss: 1.8458 - val_accuracy: 0.4187\n",
      "Epoch 444/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8596 - accuracy: 0.7035 - val_loss: 1.8893 - val_accuracy: 0.4107\n",
      "Epoch 445/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8529 - accuracy: 0.6950 - val_loss: 1.8556 - val_accuracy: 0.4107\n",
      "Epoch 446/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8550 - accuracy: 0.6923 - val_loss: 1.8550 - val_accuracy: 0.4246\n",
      "Epoch 447/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8539 - accuracy: 0.7000 - val_loss: 1.8363 - val_accuracy: 0.4127\n",
      "Epoch 448/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8554 - accuracy: 0.6904 - val_loss: 1.8886 - val_accuracy: 0.4067\n",
      "Epoch 449/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8827 - accuracy: 0.6760 - val_loss: 1.8916 - val_accuracy: 0.3968\n",
      "Epoch 450/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8781 - accuracy: 0.6833 - val_loss: 1.8626 - val_accuracy: 0.4127\n",
      "Epoch 451/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8373 - accuracy: 0.6929 - val_loss: 1.8174 - val_accuracy: 0.4286\n",
      "Epoch 452/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8576 - accuracy: 0.6999 - val_loss: 1.8835 - val_accuracy: 0.3988\n",
      "Epoch 453/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8610 - accuracy: 0.6802 - val_loss: 1.8416 - val_accuracy: 0.4226\n",
      "Epoch 454/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8519 - accuracy: 0.6959 - val_loss: 1.8361 - val_accuracy: 0.4167\n",
      "Epoch 455/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8081 - accuracy: 0.7045 - val_loss: 1.8558 - val_accuracy: 0.4167\n",
      "Epoch 456/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8603 - accuracy: 0.6965 - val_loss: 1.8561 - val_accuracy: 0.4187\n",
      "Epoch 457/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8379 - accuracy: 0.7028 - val_loss: 1.8732 - val_accuracy: 0.4147\n",
      "Epoch 458/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8530 - accuracy: 0.6943 - val_loss: 1.9161 - val_accuracy: 0.4107\n",
      "Epoch 459/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8342 - accuracy: 0.7007 - val_loss: 1.8585 - val_accuracy: 0.4266\n",
      "Epoch 460/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8281 - accuracy: 0.7060 - val_loss: 1.8653 - val_accuracy: 0.4028\n",
      "Epoch 461/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8537 - accuracy: 0.6870 - val_loss: 1.8674 - val_accuracy: 0.4147\n",
      "Epoch 462/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8469 - accuracy: 0.6869 - val_loss: 1.8660 - val_accuracy: 0.4226\n",
      "Epoch 463/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8240 - accuracy: 0.7193 - val_loss: 1.8859 - val_accuracy: 0.4206\n",
      "Epoch 464/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8275 - accuracy: 0.7158 - val_loss: 1.9430 - val_accuracy: 0.4008s - loss: 0.8270 \n",
      "Epoch 465/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8330 - accuracy: 0.6959 - val_loss: 1.8988 - val_accuracy: 0.4127\n",
      "Epoch 466/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8297 - accuracy: 0.6943 - val_loss: 1.9667 - val_accuracy: 0.3929\n",
      "Epoch 467/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7970 - accuracy: 0.7108 - val_loss: 1.8847 - val_accuracy: 0.4206\n",
      "Epoch 468/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8124 - accuracy: 0.6975 - val_loss: 1.9259 - val_accuracy: 0.4067\n",
      "Epoch 469/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8141 - accuracy: 0.7115 - val_loss: 1.8815 - val_accuracy: 0.4048\n",
      "Epoch 470/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8292 - accuracy: 0.6962 - val_loss: 1.8918 - val_accuracy: 0.4325\n",
      "Epoch 471/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8466 - accuracy: 0.6893 - val_loss: 1.9290 - val_accuracy: 0.4048\n",
      "Epoch 472/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8155 - accuracy: 0.7008 - val_loss: 1.8664 - val_accuracy: 0.4187\n",
      "Epoch 473/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8342 - accuracy: 0.7070 - val_loss: 1.8533 - val_accuracy: 0.4286\n",
      "Epoch 474/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8223 - accuracy: 0.7066 - val_loss: 1.8795 - val_accuracy: 0.4266\n",
      "Epoch 475/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8072 - accuracy: 0.7152 - val_loss: 1.9253 - val_accuracy: 0.4187\n",
      "Epoch 476/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7902 - accuracy: 0.7026 - val_loss: 1.8609 - val_accuracy: 0.4028\n",
      "Epoch 477/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8275 - accuracy: 0.6979 - val_loss: 1.9064 - val_accuracy: 0.4246\n",
      "Epoch 478/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8040 - accuracy: 0.7046 - val_loss: 1.9118 - val_accuracy: 0.4087\n",
      "Epoch 479/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7933 - accuracy: 0.7140 - val_loss: 1.8997 - val_accuracy: 0.4286\n",
      "Epoch 480/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8067 - accuracy: 0.7051 - val_loss: 1.9243 - val_accuracy: 0.4067\n",
      "Epoch 481/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8322 - accuracy: 0.6879 - val_loss: 1.8915 - val_accuracy: 0.4127\n",
      "Epoch 482/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8042 - accuracy: 0.7163 - val_loss: 1.9293 - val_accuracy: 0.4187\n",
      "Epoch 483/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8060 - accuracy: 0.7067 - val_loss: 1.9351 - val_accuracy: 0.4087\n",
      "Epoch 484/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7962 - accuracy: 0.7208 - val_loss: 1.8986 - val_accuracy: 0.4385\n",
      "Epoch 485/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8084 - accuracy: 0.7180 - val_loss: 1.9389 - val_accuracy: 0.4008\n",
      "Epoch 486/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7848 - accuracy: 0.7296 - val_loss: 1.9008 - val_accuracy: 0.4127\n",
      "Epoch 487/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8125 - accuracy: 0.7107 - val_loss: 1.9190 - val_accuracy: 0.3988\n",
      "Epoch 488/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7934 - accuracy: 0.7030 - val_loss: 1.9118 - val_accuracy: 0.4306\n",
      "Epoch 489/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.8239 - accuracy: 0.6923 - val_loss: 1.9006 - val_accuracy: 0.4306\n",
      "Epoch 490/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7764 - accuracy: 0.7084 - val_loss: 1.8524 - val_accuracy: 0.4226\n",
      "Epoch 491/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7597 - accuracy: 0.7345 - val_loss: 1.8992 - val_accuracy: 0.4226\n",
      "Epoch 492/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7892 - accuracy: 0.6951 - val_loss: 1.9463 - val_accuracy: 0.4187\n",
      "Epoch 493/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7839 - accuracy: 0.7132 - val_loss: 1.8954 - val_accuracy: 0.4246\n",
      "Epoch 494/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7767 - accuracy: 0.7161 - val_loss: 1.9590 - val_accuracy: 0.4147\n",
      "Epoch 495/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7844 - accuracy: 0.7138 - val_loss: 1.9468 - val_accuracy: 0.4028\n",
      "Epoch 496/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7830 - accuracy: 0.7230 - val_loss: 1.9192 - val_accuracy: 0.4028\n",
      "Epoch 497/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7895 - accuracy: 0.7155 - val_loss: 1.9639 - val_accuracy: 0.4048\n",
      "Epoch 498/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.8016 - accuracy: 0.7076 - val_loss: 1.9550 - val_accuracy: 0.4127\n",
      "Epoch 499/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7839 - accuracy: 0.7145 - val_loss: 1.9499 - val_accuracy: 0.4067\n",
      "Epoch 500/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7628 - accuracy: 0.7139 - val_loss: 1.9175 - val_accuracy: 0.4206\n",
      "Epoch 501/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7776 - accuracy: 0.7167 - val_loss: 1.9642 - val_accuracy: 0.4028\n",
      "Epoch 502/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7686 - accuracy: 0.7074 - val_loss: 1.9717 - val_accuracy: 0.3889\n",
      "Epoch 503/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7749 - accuracy: 0.7133 - val_loss: 1.9183 - val_accuracy: 0.4345\n",
      "Epoch 504/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7564 - accuracy: 0.7321 - val_loss: 1.9181 - val_accuracy: 0.4206\n",
      "Epoch 505/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7856 - accuracy: 0.7094 - val_loss: 1.9984 - val_accuracy: 0.3988\n",
      "Epoch 506/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7852 - accuracy: 0.7016 - val_loss: 1.9095 - val_accuracy: 0.4325\n",
      "Epoch 507/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7912 - accuracy: 0.7046 - val_loss: 2.0089 - val_accuracy: 0.4067\n",
      "Epoch 508/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7816 - accuracy: 0.7219 - val_loss: 1.8873 - val_accuracy: 0.4266\n",
      "Epoch 509/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7712 - accuracy: 0.7086 - val_loss: 1.9593 - val_accuracy: 0.4028\n",
      "Epoch 510/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7818 - accuracy: 0.7118 - val_loss: 1.9632 - val_accuracy: 0.4206\n",
      "Epoch 511/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7464 - accuracy: 0.7216 - val_loss: 1.9496 - val_accuracy: 0.4286\n",
      "Epoch 512/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7660 - accuracy: 0.7053 - val_loss: 1.9956 - val_accuracy: 0.4167\n",
      "Epoch 513/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7492 - accuracy: 0.7362 - val_loss: 1.9280 - val_accuracy: 0.4206\n",
      "Epoch 514/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7554 - accuracy: 0.7356 - val_loss: 1.9410 - val_accuracy: 0.4048\n",
      "Epoch 515/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7366 - accuracy: 0.7320 - val_loss: 1.9796 - val_accuracy: 0.3869\n",
      "Epoch 516/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7347 - accuracy: 0.7207 - val_loss: 1.9433 - val_accuracy: 0.4206\n",
      "Epoch 517/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7392 - accuracy: 0.7297 - val_loss: 1.9525 - val_accuracy: 0.4167\n",
      "Epoch 518/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7453 - accuracy: 0.7352 - val_loss: 1.9882 - val_accuracy: 0.3770\n",
      "Epoch 519/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7646 - accuracy: 0.7235 - val_loss: 1.9614 - val_accuracy: 0.4246\n",
      "Epoch 520/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7207 - accuracy: 0.7348 - val_loss: 1.9685 - val_accuracy: 0.4008\n",
      "Epoch 521/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7644 - accuracy: 0.7228 - val_loss: 2.0268 - val_accuracy: 0.3968\n",
      "Epoch 522/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7378 - accuracy: 0.7286 - val_loss: 1.9290 - val_accuracy: 0.4226\n",
      "Epoch 523/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7603 - accuracy: 0.7193 - val_loss: 2.0133 - val_accuracy: 0.3948\n",
      "Epoch 524/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7536 - accuracy: 0.7255 - val_loss: 1.9650 - val_accuracy: 0.4107\n",
      "Epoch 525/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7517 - accuracy: 0.7336 - val_loss: 1.9868 - val_accuracy: 0.4206\n",
      "Epoch 526/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7380 - accuracy: 0.7346 - val_loss: 1.9377 - val_accuracy: 0.4187\n",
      "Epoch 527/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7435 - accuracy: 0.7290 - val_loss: 1.9337 - val_accuracy: 0.4206\n",
      "Epoch 528/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7576 - accuracy: 0.7342 - val_loss: 1.9544 - val_accuracy: 0.4246\n",
      "Epoch 529/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7365 - accuracy: 0.7297 - val_loss: 2.0490 - val_accuracy: 0.3948\n",
      "Epoch 530/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7412 - accuracy: 0.7308 - val_loss: 2.0182 - val_accuracy: 0.4008\n",
      "Epoch 531/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7104 - accuracy: 0.7340 - val_loss: 2.0130 - val_accuracy: 0.4226\n",
      "Epoch 532/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7135 - accuracy: 0.7316 - val_loss: 1.9827 - val_accuracy: 0.4127\n",
      "Epoch 533/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7502 - accuracy: 0.7323 - val_loss: 1.9750 - val_accuracy: 0.4206\n",
      "Epoch 534/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7404 - accuracy: 0.7153 - val_loss: 1.9675 - val_accuracy: 0.4107\n",
      "Epoch 535/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7477 - accuracy: 0.7246 - val_loss: 1.9837 - val_accuracy: 0.4127\n",
      "Epoch 536/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7117 - accuracy: 0.7314 - val_loss: 2.0236 - val_accuracy: 0.4306\n",
      "Epoch 537/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7150 - accuracy: 0.7372 - val_loss: 2.0091 - val_accuracy: 0.4028\n",
      "Epoch 538/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7065 - accuracy: 0.7474 - val_loss: 1.9556 - val_accuracy: 0.4187\n",
      "Epoch 539/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7301 - accuracy: 0.7270 - val_loss: 1.9944 - val_accuracy: 0.4048\n",
      "Epoch 540/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7329 - accuracy: 0.7403 - val_loss: 1.9986 - val_accuracy: 0.4107\n",
      "Epoch 541/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7427 - accuracy: 0.7306 - val_loss: 2.0125 - val_accuracy: 0.4067\n",
      "Epoch 542/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7193 - accuracy: 0.7437 - val_loss: 2.0358 - val_accuracy: 0.4008\n",
      "Epoch 543/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7190 - accuracy: 0.7422 - val_loss: 2.0191 - val_accuracy: 0.4048\n",
      "Epoch 544/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7213 - accuracy: 0.7359 - val_loss: 2.0022 - val_accuracy: 0.4206\n",
      "Epoch 545/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7063 - accuracy: 0.7396 - val_loss: 2.0533 - val_accuracy: 0.3948\n",
      "Epoch 546/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6974 - accuracy: 0.7477 - val_loss: 1.9635 - val_accuracy: 0.4107\n",
      "Epoch 547/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7485 - accuracy: 0.7249 - val_loss: 1.9728 - val_accuracy: 0.4107\n",
      "Epoch 548/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7165 - accuracy: 0.7438 - val_loss: 2.0158 - val_accuracy: 0.4087\n",
      "Epoch 549/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7286 - accuracy: 0.7336 - val_loss: 2.0281 - val_accuracy: 0.4048\n",
      "Epoch 550/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7033 - accuracy: 0.7430 - val_loss: 2.0462 - val_accuracy: 0.4107\n",
      "Epoch 551/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7218 - accuracy: 0.7282 - val_loss: 1.9910 - val_accuracy: 0.4048\n",
      "Epoch 552/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7011 - accuracy: 0.7462 - val_loss: 2.0210 - val_accuracy: 0.4246\n",
      "Epoch 553/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7068 - accuracy: 0.7359 - val_loss: 1.9566 - val_accuracy: 0.4365\n",
      "Epoch 554/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6967 - accuracy: 0.7401 - val_loss: 2.0616 - val_accuracy: 0.3869\n",
      "Epoch 555/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6724 - accuracy: 0.7568 - val_loss: 2.0984 - val_accuracy: 0.3750\n",
      "Epoch 556/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7003 - accuracy: 0.7454 - val_loss: 1.9886 - val_accuracy: 0.3988\n",
      "Epoch 557/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6724 - accuracy: 0.7442 - val_loss: 2.0323 - val_accuracy: 0.4028\n",
      "Epoch 558/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7125 - accuracy: 0.7249 - val_loss: 1.9566 - val_accuracy: 0.4107\n",
      "Epoch 559/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7159 - accuracy: 0.7336 - val_loss: 2.0533 - val_accuracy: 0.4087\n",
      "Epoch 560/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6795 - accuracy: 0.7632 - val_loss: 1.9954 - val_accuracy: 0.4345\n",
      "Epoch 561/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.7005 - accuracy: 0.7482 - val_loss: 1.9788 - val_accuracy: 0.4206\n",
      "Epoch 562/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7065 - accuracy: 0.7294 - val_loss: 1.9982 - val_accuracy: 0.4167\n",
      "Epoch 563/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7127 - accuracy: 0.7335 - val_loss: 2.0700 - val_accuracy: 0.4147\n",
      "Epoch 564/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6904 - accuracy: 0.7428 - val_loss: 2.0169 - val_accuracy: 0.4167\n",
      "Epoch 565/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6874 - accuracy: 0.7300 - val_loss: 2.0082 - val_accuracy: 0.4127\n",
      "Epoch 566/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6776 - accuracy: 0.7600 - val_loss: 2.0061 - val_accuracy: 0.4385\n",
      "Epoch 567/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6732 - accuracy: 0.7495 - val_loss: 2.0167 - val_accuracy: 0.4107\n",
      "Epoch 568/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6646 - accuracy: 0.7552 - val_loss: 2.0241 - val_accuracy: 0.4107\n",
      "Epoch 569/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6949 - accuracy: 0.7447 - val_loss: 2.0261 - val_accuracy: 0.4067\n",
      "Epoch 570/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7060 - accuracy: 0.7435 - val_loss: 2.0285 - val_accuracy: 0.4206\n",
      "Epoch 571/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6914 - accuracy: 0.7347 - val_loss: 2.0485 - val_accuracy: 0.4286\n",
      "Epoch 572/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.7121 - accuracy: 0.7402 - val_loss: 2.1240 - val_accuracy: 0.3988\n",
      "Epoch 573/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6673 - accuracy: 0.7564 - val_loss: 2.0563 - val_accuracy: 0.4187\n",
      "Epoch 574/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6879 - accuracy: 0.7432 - val_loss: 2.0737 - val_accuracy: 0.3929\n",
      "Epoch 575/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6801 - accuracy: 0.7409 - val_loss: 2.0345 - val_accuracy: 0.3968\n",
      "Epoch 576/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6835 - accuracy: 0.7509 - val_loss: 2.0870 - val_accuracy: 0.4325\n",
      "Epoch 577/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6725 - accuracy: 0.7518 - val_loss: 2.0800 - val_accuracy: 0.4067\n",
      "Epoch 578/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6865 - accuracy: 0.7583 - val_loss: 2.0245 - val_accuracy: 0.4147\n",
      "Epoch 579/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6814 - accuracy: 0.7509 - val_loss: 2.0476 - val_accuracy: 0.4107\n",
      "Epoch 580/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6594 - accuracy: 0.7601 - val_loss: 2.0197 - val_accuracy: 0.4425\n",
      "Epoch 581/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6784 - accuracy: 0.7449 - val_loss: 1.9887 - val_accuracy: 0.4306\n",
      "Epoch 582/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6605 - accuracy: 0.7573 - val_loss: 2.0877 - val_accuracy: 0.4127\n",
      "Epoch 583/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6901 - accuracy: 0.7449 - val_loss: 2.0356 - val_accuracy: 0.4087\n",
      "Epoch 584/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6740 - accuracy: 0.7524 - val_loss: 1.9963 - val_accuracy: 0.4206\n",
      "Epoch 585/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6641 - accuracy: 0.7673 - val_loss: 2.0878 - val_accuracy: 0.4107\n",
      "Epoch 586/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6793 - accuracy: 0.7583 - val_loss: 2.0843 - val_accuracy: 0.4067\n",
      "Epoch 587/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6701 - accuracy: 0.7625 - val_loss: 2.0132 - val_accuracy: 0.4167\n",
      "Epoch 588/700\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6620 - accuracy: 0.7493 - val_loss: 2.0340 - val_accuracy: 0.4067\n",
      "Epoch 589/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6538 - accuracy: 0.7585 - val_loss: 2.1516 - val_accuracy: 0.4028\n",
      "Epoch 590/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6520 - accuracy: 0.7629 - val_loss: 2.0378 - val_accuracy: 0.4206\n",
      "Epoch 591/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6738 - accuracy: 0.7582 - val_loss: 2.0861 - val_accuracy: 0.3968\n",
      "Epoch 592/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6643 - accuracy: 0.7525 - val_loss: 2.0785 - val_accuracy: 0.4266\n",
      "Epoch 593/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6625 - accuracy: 0.7444 - val_loss: 2.0493 - val_accuracy: 0.4226\n",
      "Epoch 594/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6899 - accuracy: 0.7382 - val_loss: 2.0665 - val_accuracy: 0.4087\n",
      "Epoch 595/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6673 - accuracy: 0.7523 - val_loss: 2.1375 - val_accuracy: 0.4167\n",
      "Epoch 596/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6561 - accuracy: 0.7598 - val_loss: 2.0580 - val_accuracy: 0.4266\n",
      "Epoch 597/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6223 - accuracy: 0.7768 - val_loss: 2.0793 - val_accuracy: 0.4325\n",
      "Epoch 598/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6595 - accuracy: 0.7487 - val_loss: 2.1288 - val_accuracy: 0.3929\n",
      "Epoch 599/700\n",
      "200/200 [==============================] - 6s 29ms/step - loss: 0.6584 - accuracy: 0.7515 - val_loss: 2.0553 - val_accuracy: 0.4087\n",
      "Epoch 600/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6833 - accuracy: 0.7490 - val_loss: 2.0970 - val_accuracy: 0.4087\n",
      "Epoch 601/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6680 - accuracy: 0.7487 - val_loss: 2.0921 - val_accuracy: 0.4226\n",
      "Epoch 602/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6466 - accuracy: 0.7559 - val_loss: 2.0593 - val_accuracy: 0.4206\n",
      "Epoch 603/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6564 - accuracy: 0.7529 - val_loss: 2.0914 - val_accuracy: 0.4127\n",
      "Epoch 604/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6351 - accuracy: 0.7714 - val_loss: 2.1047 - val_accuracy: 0.4127\n",
      "Epoch 605/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6388 - accuracy: 0.7663 - val_loss: 2.1858 - val_accuracy: 0.4067\n",
      "Epoch 606/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6496 - accuracy: 0.7557 - val_loss: 2.0268 - val_accuracy: 0.4246\n",
      "Epoch 607/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6513 - accuracy: 0.7596 - val_loss: 2.0983 - val_accuracy: 0.4266\n",
      "Epoch 608/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6614 - accuracy: 0.7625 - val_loss: 2.0851 - val_accuracy: 0.4008\n",
      "Epoch 609/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6340 - accuracy: 0.7709 - val_loss: 2.0726 - val_accuracy: 0.4246\n",
      "Epoch 610/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6455 - accuracy: 0.7698 - val_loss: 2.1166 - val_accuracy: 0.4008\n",
      "Epoch 611/700\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6413 - accuracy: 0.7664 - val_loss: 2.0790 - val_accuracy: 0.4127\n",
      "Epoch 612/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6357 - accuracy: 0.7708 - val_loss: 2.0756 - val_accuracy: 0.4246\n",
      "Epoch 613/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6561 - accuracy: 0.7508 - val_loss: 2.1190 - val_accuracy: 0.4028\n",
      "Epoch 614/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6806 - accuracy: 0.7417 - val_loss: 2.0820 - val_accuracy: 0.4226\n",
      "Epoch 615/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6722 - accuracy: 0.7439 - val_loss: 2.0932 - val_accuracy: 0.4107\n",
      "Epoch 616/700\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6452 - accuracy: 0.7570 - val_loss: 2.1051 - val_accuracy: 0.4167\n",
      "Epoch 617/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6457 - accuracy: 0.7528 - val_loss: 2.1424 - val_accuracy: 0.4127\n",
      "Epoch 618/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6484 - accuracy: 0.7479 - val_loss: 2.0925 - val_accuracy: 0.4405\n",
      "Epoch 619/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6313 - accuracy: 0.7591 - val_loss: 2.1025 - val_accuracy: 0.4087\n",
      "Epoch 620/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6334 - accuracy: 0.7744 - val_loss: 2.1010 - val_accuracy: 0.4147\n",
      "Epoch 621/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6462 - accuracy: 0.7529 - val_loss: 2.1079 - val_accuracy: 0.4206\n",
      "Epoch 622/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6511 - accuracy: 0.7502 - val_loss: 2.0734 - val_accuracy: 0.4187\n",
      "Epoch 623/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6561 - accuracy: 0.7379 - val_loss: 2.1070 - val_accuracy: 0.4286\n",
      "Epoch 624/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6191 - accuracy: 0.7742 - val_loss: 2.1305 - val_accuracy: 0.4087\n",
      "Epoch 625/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6128 - accuracy: 0.7683 - val_loss: 2.1216 - val_accuracy: 0.4226\n",
      "Epoch 626/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6083 - accuracy: 0.7790 - val_loss: 2.1377 - val_accuracy: 0.4246\n",
      "Epoch 627/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6465 - accuracy: 0.7432 - val_loss: 2.1322 - val_accuracy: 0.4147\n",
      "Epoch 628/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6500 - accuracy: 0.7590 - val_loss: 2.1710 - val_accuracy: 0.4048\n",
      "Epoch 629/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6412 - accuracy: 0.7632 - val_loss: 2.1377 - val_accuracy: 0.4206\n",
      "Epoch 630/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6293 - accuracy: 0.7642 - val_loss: 2.0952 - val_accuracy: 0.4107\n",
      "Epoch 631/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6421 - accuracy: 0.7645 - val_loss: 2.1020 - val_accuracy: 0.4365\n",
      "Epoch 632/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6239 - accuracy: 0.7644 - val_loss: 2.1326 - val_accuracy: 0.4008\n",
      "Epoch 633/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6402 - accuracy: 0.7609 - val_loss: 2.1121 - val_accuracy: 0.4226\n",
      "Epoch 634/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6371 - accuracy: 0.7562 - val_loss: 2.1056 - val_accuracy: 0.4107\n",
      "Epoch 635/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6343 - accuracy: 0.7636 - val_loss: 2.1282 - val_accuracy: 0.4087\n",
      "Epoch 636/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6720 - accuracy: 0.7367 - val_loss: 2.2118 - val_accuracy: 0.4127\n",
      "Epoch 637/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6108 - accuracy: 0.7777 - val_loss: 2.1305 - val_accuracy: 0.4306\n",
      "Epoch 638/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6217 - accuracy: 0.7617 - val_loss: 2.0999 - val_accuracy: 0.4206\n",
      "Epoch 639/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6018 - accuracy: 0.7697 - val_loss: 2.1711 - val_accuracy: 0.4147\n",
      "Epoch 640/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6282 - accuracy: 0.7564 - val_loss: 2.1622 - val_accuracy: 0.4107\n",
      "Epoch 641/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6259 - accuracy: 0.7645 - val_loss: 2.1506 - val_accuracy: 0.4266\n",
      "Epoch 642/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5943 - accuracy: 0.7741 - val_loss: 2.1393 - val_accuracy: 0.4107\n",
      "Epoch 643/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6232 - accuracy: 0.7550 - val_loss: 2.1541 - val_accuracy: 0.4365\n",
      "Epoch 644/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6257 - accuracy: 0.7716 - val_loss: 2.1644 - val_accuracy: 0.4067\n",
      "Epoch 645/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5944 - accuracy: 0.7705 - val_loss: 2.1208 - val_accuracy: 0.4147\n",
      "Epoch 646/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6057 - accuracy: 0.7700 - val_loss: 2.1086 - val_accuracy: 0.4147\n",
      "Epoch 647/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5797 - accuracy: 0.7885 - val_loss: 2.1128 - val_accuracy: 0.4167\n",
      "Epoch 648/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6250 - accuracy: 0.7550 - val_loss: 2.1532 - val_accuracy: 0.4147\n",
      "Epoch 649/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6270 - accuracy: 0.7672 - val_loss: 2.1425 - val_accuracy: 0.4147\n",
      "Epoch 650/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5832 - accuracy: 0.7878 - val_loss: 2.1578 - val_accuracy: 0.4087\n",
      "Epoch 651/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6118 - accuracy: 0.7682 - val_loss: 2.1612 - val_accuracy: 0.4206\n",
      "Epoch 652/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5908 - accuracy: 0.7766 - val_loss: 2.1842 - val_accuracy: 0.4127\n",
      "Epoch 653/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6267 - accuracy: 0.7635 - val_loss: 2.1143 - val_accuracy: 0.4028\n",
      "Epoch 654/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5850 - accuracy: 0.7847 - val_loss: 2.1562 - val_accuracy: 0.4206\n",
      "Epoch 655/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5970 - accuracy: 0.7780 - val_loss: 2.1768 - val_accuracy: 0.4107\n",
      "Epoch 656/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6526 - accuracy: 0.7544 - val_loss: 2.1967 - val_accuracy: 0.4286\n",
      "Epoch 657/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6178 - accuracy: 0.7739 - val_loss: 2.1953 - val_accuracy: 0.4107\n",
      "Epoch 658/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5925 - accuracy: 0.7834 - val_loss: 2.1603 - val_accuracy: 0.4167\n",
      "Epoch 659/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6089 - accuracy: 0.7720 - val_loss: 2.2925 - val_accuracy: 0.3948\n",
      "Epoch 660/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6260 - accuracy: 0.7706 - val_loss: 2.2199 - val_accuracy: 0.4107\n",
      "Epoch 661/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6348 - accuracy: 0.7547 - val_loss: 2.2030 - val_accuracy: 0.4087\n",
      "Epoch 662/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5933 - accuracy: 0.7718 - val_loss: 2.1821 - val_accuracy: 0.4167\n",
      "Epoch 663/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5792 - accuracy: 0.7870 - val_loss: 2.1568 - val_accuracy: 0.4325\n",
      "Epoch 664/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5894 - accuracy: 0.7877 - val_loss: 2.1455 - val_accuracy: 0.4226\n",
      "Epoch 665/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5948 - accuracy: 0.7752 - val_loss: 2.3292 - val_accuracy: 0.3869\n",
      "Epoch 666/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5984 - accuracy: 0.7699 - val_loss: 2.1927 - val_accuracy: 0.4226\n",
      "Epoch 667/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6024 - accuracy: 0.7717 - val_loss: 2.2077 - val_accuracy: 0.4127\n",
      "Epoch 668/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5771 - accuracy: 0.7848 - val_loss: 2.1641 - val_accuracy: 0.4167\n",
      "Epoch 669/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6031 - accuracy: 0.7768 - val_loss: 2.2361 - val_accuracy: 0.4107\n",
      "Epoch 670/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6057 - accuracy: 0.7820 - val_loss: 2.2019 - val_accuracy: 0.4206\n",
      "Epoch 671/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5744 - accuracy: 0.7859 - val_loss: 2.2376 - val_accuracy: 0.4107\n",
      "Epoch 672/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5984 - accuracy: 0.7743 - val_loss: 2.1749 - val_accuracy: 0.4345\n",
      "Epoch 673/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5780 - accuracy: 0.7917 - val_loss: 2.2153 - val_accuracy: 0.4187\n",
      "Epoch 674/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5843 - accuracy: 0.7878 - val_loss: 2.2711 - val_accuracy: 0.4206\n",
      "Epoch 675/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6114 - accuracy: 0.7727 - val_loss: 2.2412 - val_accuracy: 0.4127\n",
      "Epoch 676/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5803 - accuracy: 0.7786 - val_loss: 2.1678 - val_accuracy: 0.4226\n",
      "Epoch 677/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5953 - accuracy: 0.7693 - val_loss: 2.2266 - val_accuracy: 0.4067\n",
      "Epoch 678/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5761 - accuracy: 0.7822 - val_loss: 2.2036 - val_accuracy: 0.4206\n",
      "Epoch 679/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5734 - accuracy: 0.7868 - val_loss: 2.1761 - val_accuracy: 0.4266\n",
      "Epoch 680/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5764 - accuracy: 0.7739 - val_loss: 2.2324 - val_accuracy: 0.4167\n",
      "Epoch 681/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6125 - accuracy: 0.7679 - val_loss: 2.2077 - val_accuracy: 0.4246\n",
      "Epoch 682/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6013 - accuracy: 0.7838 - val_loss: 2.1588 - val_accuracy: 0.4206\n",
      "Epoch 683/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5816 - accuracy: 0.7923 - val_loss: 2.2195 - val_accuracy: 0.4226\n",
      "Epoch 684/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5823 - accuracy: 0.7801 - val_loss: 2.1929 - val_accuracy: 0.4365\n",
      "Epoch 685/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5903 - accuracy: 0.7807 - val_loss: 2.2303 - val_accuracy: 0.4226\n",
      "Epoch 686/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5782 - accuracy: 0.7766 - val_loss: 2.1904 - val_accuracy: 0.4266\n",
      "Epoch 687/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6053 - accuracy: 0.7661 - val_loss: 2.2719 - val_accuracy: 0.4067\n",
      "Epoch 688/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5917 - accuracy: 0.7703 - val_loss: 2.2416 - val_accuracy: 0.4087\n",
      "Epoch 689/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5838 - accuracy: 0.7755 - val_loss: 2.2565 - val_accuracy: 0.4226\n",
      "Epoch 690/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5902 - accuracy: 0.7754 - val_loss: 2.2025 - val_accuracy: 0.4028\n",
      "Epoch 691/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5756 - accuracy: 0.7865 - val_loss: 2.1698 - val_accuracy: 0.4127\n",
      "Epoch 692/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5811 - accuracy: 0.7776 - val_loss: 2.2246 - val_accuracy: 0.4187\n",
      "Epoch 693/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5786 - accuracy: 0.7839 - val_loss: 2.2236 - val_accuracy: 0.4147\n",
      "Epoch 694/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5756 - accuracy: 0.7904 - val_loss: 2.3684 - val_accuracy: 0.3988\n",
      "Epoch 695/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5858 - accuracy: 0.7810 - val_loss: 2.1653 - val_accuracy: 0.4266\n",
      "Epoch 696/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5912 - accuracy: 0.7837 - val_loss: 2.1606 - val_accuracy: 0.3968\n",
      "Epoch 697/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5752 - accuracy: 0.7768 - val_loss: 2.2032 - val_accuracy: 0.4048\n",
      "Epoch 698/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5891 - accuracy: 0.7833 - val_loss: 2.2050 - val_accuracy: 0.4127\n",
      "Epoch 699/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6083 - accuracy: 0.7718 - val_loss: 2.2220 - val_accuracy: 0.4246\n",
      "Epoch 700/700\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5523 - accuracy: 0.8054 - val_loss: 2.2111 - val_accuracy: 0.4147\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(X_train, y_train, batch_size=16, epochs=700, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбираемся с проблемами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, '10dec_D41_1', 21.083000000000002, 24.517], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data_angry.values[3]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = AudioSegment.from_file(\"RAMAS(audio)/Audio/\" + example[1] + \"_mic.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = np.array(file[example[2] * 1000 : example[3] * 1000].get_array_of_samples()).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x293434fcaf0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31626"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151439,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(file[example[2] * 1000 : example[3] * 1000].get_array_of_samples()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c89dbf97a0c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmfccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_rate' is not defined"
     ]
    }
   ],
   "source": [
    "mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше выбирать другое значение `mfcc`, например 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load(\"RAMAS(audio)/Audio/\" + example[1] + \"_mic.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697344,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут какая-то потеря информации при использовании audio segment. Перепишем data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram_db(file_path, sr=22050, n_fft=2048, hop_length=512, n_mels=13, fmin=20, fmax=8300, top_db=80):\n",
    "    wav,sr = librosa.load(file_path,sr=sr)\n",
    "    if wav.shape[0]<5*sr:\n",
    "        wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
    "    else:\n",
    "        wav=wav[:5*sr]\n",
    "    spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,\n",
    "              hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "    spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "    return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader1:\n",
    "    \n",
    "    def __init__(self, category_filenames, audio_path, table_prefix, sample_rate):\n",
    "        self.table_prefix = table_prefix\n",
    "        self.category_filenames = category_filenames\n",
    "        self.audio_path = audio_path\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def make_dataset(self):\n",
    "        train_test_data = []\n",
    "        c = 0\n",
    "        d = 0\n",
    "        for category in self.category_filenames:\n",
    "            data = pd.read_csv(self.table_prefix + category)\n",
    "            values = data.values\n",
    "            for i in range(values.shape[0]):\n",
    "                ind, name, start, end = values[i]\n",
    "                if end - start > 3:\n",
    "                    try:\n",
    "                        file = AudioSegment.from_file(self.audio_path + name + '_mic.wav')\n",
    "                    except:\n",
    "                        c += 1\n",
    "                        continue\n",
    "                    new_file = file[start * 1000 : end * 1000]\n",
    "                    new_file.export('test.wav', format='wav')\n",
    "                    try:\n",
    "                        mfccs = get_melspectrogram_db('test.wav')\n",
    "                        train_test_data.append([category, mfccs])\n",
    "                    except:\n",
    "                        d += 1\n",
    "                        continue\n",
    "                if i % 100 == 0:\n",
    "                    print(\"Current: \", i)\n",
    "            print(category)\n",
    "    #                 print(mfccs.shape)\n",
    "        print(f'Lost: {c}, errors: {d}')\n",
    "        return train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader1(category_files, \"RAMAS(audio)/Audio/\", \"RAMAS(audio)/Annotations_by_emotions/\", 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "Current:  1100\n",
      "Current:  1200\n",
      "Current:  1300\n",
      "Current:  1400\n",
      "Current:  1500\n",
      "data_Angry.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "Current:  1100\n",
      "data_Disgusted.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1100\n",
      "Current:  1200\n",
      "Current:  1400\n",
      "Current:  1500\n",
      "Current:  1600\n",
      "Current:  1700\n",
      "Current:  1800\n",
      "Current:  1900\n",
      "Current:  2000\n",
      "Current:  2100\n",
      "Current:  2200\n",
      "Current:  2300\n",
      "data_Domination.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "Current:  1100\n",
      "Current:  1200\n",
      "Current:  1300\n",
      "Current:  1400\n",
      "Current:  1500\n",
      "Current:  1600\n",
      "Current:  1700\n",
      "Current:  1800\n",
      "Current:  1900\n",
      "Current:  2000\n",
      "Current:  2100\n",
      "Current:  2200\n",
      "Current:  2300\n",
      "Current:  2400\n",
      "Current:  2500\n",
      "Current:  2600\n",
      "data_Happy.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "Current:  1100\n",
      "Current:  1200\n",
      "data_Neutral.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "data_Sad.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "Current:  1100\n",
      "Current:  1200\n",
      "Current:  1300\n",
      "data_Scared.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "data_Shame.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "Current:  1100\n",
      "Current:  1200\n",
      "Current:  1300\n",
      "Current:  1400\n",
      "Current:  1500\n",
      "Current:  1600\n",
      "Current:  1700\n",
      "Current:  1800\n",
      "Current:  1900\n",
      "Current:  2000\n",
      "Current:  2100\n",
      "data_Submission.csv\n",
      "Current:  0\n",
      "Current:  100\n",
      "Current:  200\n",
      "Current:  300\n",
      "Current:  400\n",
      "Current:  500\n",
      "Current:  600\n",
      "Current:  700\n",
      "Current:  800\n",
      "Current:  900\n",
      "Current:  1000\n",
      "Current:  1100\n",
      "Current:  1200\n",
      "Current:  1300\n",
      "Current:  1400\n",
      "Current:  1500\n",
      "Current:  1600\n",
      "Current:  1700\n",
      "Current:  1800\n",
      "Current:  1900\n",
      "data_Surprised.csv\n",
      "Current:  0\n",
      "data_Tiredness.csv\n",
      "Lost: 474, errors: 9\n"
     ]
    }
   ],
   "source": [
    "ds = dl.make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12399"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 216)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdf = pd.DataFrame(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_Angry.csv</td>\n",
       "      <td>[[4.540872, 4.747926, 5.1777024, 6.526989, 6.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_Angry.csv</td>\n",
       "      <td>[[-7.098838, -6.5053678, -7.713932, -8.140531,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_Angry.csv</td>\n",
       "      <td>[[-11.991674, -13.944952, -18.29658, -18.32674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_Angry.csv</td>\n",
       "      <td>[[-13.065662, -13.430577, -10.778725, -5.56246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_Angry.csv</td>\n",
       "      <td>[[-8.406487, -1.1172584, 6.307428, 8.425748, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1\n",
       "0  data_Angry.csv  [[4.540872, 4.747926, 5.1777024, 6.526989, 6.5...\n",
       "1  data_Angry.csv  [[-7.098838, -6.5053678, -7.713932, -8.140531,...\n",
       "2  data_Angry.csv  [[-11.991674, -13.944952, -18.29658, -18.32674...\n",
       "3  data_Angry.csv  [[-13.065662, -13.430577, -10.778725, -5.56246...\n",
       "4  data_Angry.csv  [[-8.406487, -1.1172584, 6.307428, 8.425748, 6..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ramas_np = np.array(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 216)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ramas_np[0, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_ramas_numpy_13_216.npy', data_ramas_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_ramas_numpy_13_216.npy', 'rb') as f:\n",
    "    a = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_melspectrogram_db('test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 216)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data_Angry.csv',\n",
       "        array([[  4.540872 ,   4.747926 ,   5.1777024, ...,  13.815523 ,\n",
       "         10.333677 ,  13.135548 ],\n",
       "       [  8.823043 ,   8.296895 ,   9.382535 , ...,  20.119097 ,\n",
       "         17.015358 ,  17.99496  ],\n",
       "       [  9.111742 ,   8.407463 ,   6.838833 , ...,   0.239422 ,\n",
       "          1.8814344,   4.2713685],\n",
       "       ...,\n",
       "       [-34.916187 , -33.35733  , -29.940577 , ..., -14.748358 ,\n",
       "        -12.38315  , -13.810341 ],\n",
       "       [-39.58647  , -43.310165 , -45.446175 , ..., -18.303253 ,\n",
       "        -15.481214 , -16.304958 ],\n",
       "       [-38.180733 , -41.574516 , -45.316883 , ..., -22.12142  ,\n",
       "        -22.96006  , -22.276413 ]], dtype=float32)],\n",
       "       ['data_Angry.csv',\n",
       "        array([[ -7.098838 ,  -6.5053678,  -7.713932 , ...,   2.300391 ,\n",
       "          7.0834866,   7.7002907],\n",
       "       [ -7.903755 ,  -2.9978552,  -1.8150294, ...,  -0.743976 ,\n",
       "          2.2473986,   3.544095 ],\n",
       "       [-14.413696 , -15.585791 , -14.912251 , ...,  -6.546685 ,\n",
       "         -7.717809 ,  -7.4728165],\n",
       "       ...,\n",
       "       [-38.561115 , -34.02449  , -27.755508 , ..., -33.07881  ,\n",
       "        -33.305767 , -31.776636 ],\n",
       "       [-44.257538 , -37.58985  , -32.115562 , ..., -36.09195  ,\n",
       "        -37.477043 , -35.86966  ],\n",
       "       [-46.833153 , -40.691475 , -33.979256 , ..., -43.52714  ,\n",
       "        -40.929417 , -36.71314  ]], dtype=float32)],\n",
       "       ['data_Angry.csv',\n",
       "        array([[-11.991674, -13.944952, -18.29658 , ..., -26.47032 , -26.231285,\n",
       "        -26.859863],\n",
       "       [-16.095871, -17.80852 , -23.162973, ..., -26.868633, -28.218742,\n",
       "        -29.65668 ],\n",
       "       [-25.83379 , -28.784788, -33.517853, ..., -27.414097, -25.956362,\n",
       "        -24.844759],\n",
       "       ...,\n",
       "       [-51.03901 , -51.26013 , -51.167645, ..., -41.56046 , -41.698067,\n",
       "        -41.834877],\n",
       "       [-52.16668 , -52.56964 , -53.158844, ..., -47.708187, -46.80963 ,\n",
       "        -47.666832],\n",
       "       [-53.87532 , -53.10444 , -53.18679 , ..., -49.72045 , -48.808357,\n",
       "        -47.574005]], dtype=float32)],\n",
       "       ...,\n",
       "       ['data_Tiredness.csv',\n",
       "        array([[-24.842451 , -24.175463 , -17.619669 , ...,   1.5766404,\n",
       "          1.0015498,   0.197128 ],\n",
       "       [-23.753159 , -17.30144  , -14.458389 , ...,  10.080633 ,\n",
       "          9.092011 ,   7.0797324],\n",
       "       [-23.555878 , -17.586792 , -16.740034 , ...,  -0.6391612,\n",
       "         -1.5086259,  -2.9563606],\n",
       "       ...,\n",
       "       [-19.582445 , -20.675604 , -27.546122 , ..., -36.766743 ,\n",
       "        -37.36918  , -39.607742 ],\n",
       "       [-19.79521  , -21.751282 , -30.256721 , ..., -41.485943 ,\n",
       "        -42.12294  , -43.909843 ],\n",
       "       [-24.27541  , -26.26545  , -34.759125 , ..., -52.254757 ,\n",
       "        -52.461582 , -51.99444  ]], dtype=float32)],\n",
       "       ['data_Tiredness.csv',\n",
       "        array([[-27.507504  , -25.905209  , -24.629126  , ...,   6.9532514 ,\n",
       "          6.3927803 ,   0.08876447],\n",
       "       [-37.949947  , -37.26497   , -33.723976  , ...,   3.2629392 ,\n",
       "          0.40003788,  -7.476446  ],\n",
       "       [-45.718704  , -43.87279   , -38.472984  , ...,  -6.8262076 ,\n",
       "         -7.6019487 , -12.6327    ],\n",
       "       ...,\n",
       "       [-54.497     , -55.44393   , -54.416813  , ..., -39.843513  ,\n",
       "        -35.40594   , -41.329865  ],\n",
       "       [-55.67335   , -55.10151   , -54.85998   , ..., -46.25261   ,\n",
       "        -44.9753    , -48.844513  ],\n",
       "       [-56.370777  , -55.807438  , -55.34941   , ..., -46.242504  ,\n",
       "        -41.860966  , -47.575146  ]], dtype=float32)],\n",
       "       ['data_Tiredness.csv',\n",
       "        array([[-43.40979  , -41.42746  , -41.462803 , ...,   1.729629 ,\n",
       "          1.3737701,  -1.4867316],\n",
       "       [-53.147102 , -50.89685  , -47.62842  , ...,  -9.027922 ,\n",
       "        -10.5031185, -15.223893 ],\n",
       "       [-57.3987   , -58.586594 , -58.11521  , ..., -14.29484  ,\n",
       "        -15.644084 , -23.2495   ],\n",
       "       ...,\n",
       "       [-68.3172   , -69.44726  , -69.74719  , ..., -47.559982 ,\n",
       "        -49.292084 , -48.999664 ],\n",
       "       [-70.2242   , -69.70708  , -70.33591  , ..., -46.611675 ,\n",
       "        -49.460888 , -50.00017  ],\n",
       "       [-68.771065 , -69.61162  , -70.85917  , ..., -43.79558  ,\n",
       "        -46.413174 , -48.520313 ]], dtype=float32)]], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
