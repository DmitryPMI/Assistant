{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Speech emotion russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37   fa\n",
      "125   fc\n",
      "37   fh\n",
      "117   fs\n",
      "37   ma\n",
      "124   mc\n",
      "85   mh\n",
      "46   ms\n",
      "total 608\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for prefix in os.listdir('new_data'):\n",
    "    c += len(os.listdir('new_data/' + prefix))\n",
    "    print(len(os.listdir('new_data/' + prefix)), ' ', prefix)\n",
    "print('total', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собрали выборку из `608` аудио. Всего выделено по `4` признака для каждого пола. Признак, отвечающий за испуг, был отброшен. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формировние выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load('new_data/fc/1fc0.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive\n",
    "livedf2= pd.DataFrame(data=livedf2)\n",
    "livedf2 = livedf2.stack().to_frame().T\n",
    "# twodim= np.expand_dims(livedf2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twodim[0].reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2.columns = list(range(216))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-42.599155</td>\n",
       "      <td>-42.599155</td>\n",
       "      <td>-38.565506</td>\n",
       "      <td>-40.79958</td>\n",
       "      <td>-40.664909</td>\n",
       "      <td>-39.178364</td>\n",
       "      <td>-39.062923</td>\n",
       "      <td>-39.181309</td>\n",
       "      <td>-41.889675</td>\n",
       "      <td>-44.287861</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.585442</td>\n",
       "      <td>-31.385731</td>\n",
       "      <td>-32.928375</td>\n",
       "      <td>-32.946175</td>\n",
       "      <td>-31.390379</td>\n",
       "      <td>-31.363512</td>\n",
       "      <td>-31.420393</td>\n",
       "      <td>-33.336098</td>\n",
       "      <td>-31.142555</td>\n",
       "      <td>-28.53458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2         3          4          5          6    \\\n",
       "0 -42.599155 -42.599155 -38.565506 -40.79958 -40.664909 -39.178364 -39.062923   \n",
       "\n",
       "         7          8          9    ...        206        207        208  \\\n",
       "0 -39.181309 -41.889675 -44.287861  ... -29.585442 -31.385731 -32.928375   \n",
       "\n",
       "         209        210        211        212        213        214       215  \n",
       "0 -32.946175 -31.390379 -31.363512 -31.420393 -33.336098 -31.142555 -28.53458  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livedf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = dict(zip(os.listdir('new_data'), list(range(8))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fa': 0, 'fc': 1, 'fh': 2, 'fs': 3, 'ma': 4, 'mc': 5, 'mh': 6, 'ms': 7}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "i = 0\n",
    "for prefix in os.listdir('new_data'):\n",
    "    for filename in os.listdir('new_data/' + prefix):\n",
    "        X, sample_rate = librosa.load(f'new_data/{prefix}/{filename}', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "        featurelive = mfccs\n",
    "        livedf2 = featurelive\n",
    "        livedf2= pd.DataFrame(data=livedf2)\n",
    "        livedf2 = livedf2.stack().to_frame().T\n",
    "        X_data.append((i, livedf2.values[0]))\n",
    "        y_data.append((i, transformer[prefix]))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608, 608)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data), len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(map(lambda x: x[1], X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.326344</td>\n",
       "      <td>-17.296888</td>\n",
       "      <td>-20.150675</td>\n",
       "      <td>-18.294147</td>\n",
       "      <td>-17.103022</td>\n",
       "      <td>-16.043945</td>\n",
       "      <td>-16.167580</td>\n",
       "      <td>-15.591326</td>\n",
       "      <td>-15.285101</td>\n",
       "      <td>-16.635576</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.263520</td>\n",
       "      <td>-9.836855</td>\n",
       "      <td>-9.000297</td>\n",
       "      <td>-8.610595</td>\n",
       "      <td>-7.708127</td>\n",
       "      <td>-8.924120</td>\n",
       "      <td>-6.446887</td>\n",
       "      <td>-6.100635</td>\n",
       "      <td>-5.777068</td>\n",
       "      <td>-3.262930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.928268</td>\n",
       "      <td>-11.221898</td>\n",
       "      <td>-11.610126</td>\n",
       "      <td>-12.015554</td>\n",
       "      <td>-11.764825</td>\n",
       "      <td>-12.941557</td>\n",
       "      <td>-14.813755</td>\n",
       "      <td>-12.584860</td>\n",
       "      <td>-11.560820</td>\n",
       "      <td>-13.341023</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.369427</td>\n",
       "      <td>-11.286713</td>\n",
       "      <td>-12.561003</td>\n",
       "      <td>-13.209839</td>\n",
       "      <td>-14.229598</td>\n",
       "      <td>-14.887380</td>\n",
       "      <td>-13.279887</td>\n",
       "      <td>-10.424804</td>\n",
       "      <td>-9.198820</td>\n",
       "      <td>-9.799427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.682770</td>\n",
       "      <td>-8.139627</td>\n",
       "      <td>-9.780738</td>\n",
       "      <td>-9.021040</td>\n",
       "      <td>-7.429825</td>\n",
       "      <td>-8.016786</td>\n",
       "      <td>-11.229615</td>\n",
       "      <td>-13.115143</td>\n",
       "      <td>-12.387643</td>\n",
       "      <td>-13.688749</td>\n",
       "      <td>...</td>\n",
       "      <td>2.791893</td>\n",
       "      <td>-1.644092</td>\n",
       "      <td>-7.576475</td>\n",
       "      <td>-8.142863</td>\n",
       "      <td>-3.416764</td>\n",
       "      <td>-0.235614</td>\n",
       "      <td>-0.058597</td>\n",
       "      <td>0.158079</td>\n",
       "      <td>0.453212</td>\n",
       "      <td>-1.787468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.745885</td>\n",
       "      <td>-4.851453</td>\n",
       "      <td>-2.372185</td>\n",
       "      <td>-2.677375</td>\n",
       "      <td>-1.294483</td>\n",
       "      <td>-1.588351</td>\n",
       "      <td>-3.193917</td>\n",
       "      <td>-2.840873</td>\n",
       "      <td>-1.473870</td>\n",
       "      <td>-1.941777</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.527279</td>\n",
       "      <td>-8.047975</td>\n",
       "      <td>-8.805882</td>\n",
       "      <td>-10.848269</td>\n",
       "      <td>-14.466572</td>\n",
       "      <td>-14.186361</td>\n",
       "      <td>-12.370974</td>\n",
       "      <td>-11.046177</td>\n",
       "      <td>-9.836673</td>\n",
       "      <td>-6.553540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.175696</td>\n",
       "      <td>-9.916759</td>\n",
       "      <td>-10.240388</td>\n",
       "      <td>-9.676003</td>\n",
       "      <td>-9.011184</td>\n",
       "      <td>-8.094333</td>\n",
       "      <td>-8.224344</td>\n",
       "      <td>-6.904289</td>\n",
       "      <td>-6.189703</td>\n",
       "      <td>-6.950838</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.104716</td>\n",
       "      <td>-6.638175</td>\n",
       "      <td>-5.050791</td>\n",
       "      <td>-5.673285</td>\n",
       "      <td>-6.665066</td>\n",
       "      <td>-7.014104</td>\n",
       "      <td>-7.494484</td>\n",
       "      <td>-9.089967</td>\n",
       "      <td>-6.788941</td>\n",
       "      <td>0.912188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0 -16.326344 -17.296888 -20.150675 -18.294147 -17.103022 -16.043945   \n",
       "1 -10.928268 -11.221898 -11.610126 -12.015554 -11.764825 -12.941557   \n",
       "2  -6.682770  -8.139627  -9.780738  -9.021040  -7.429825  -8.016786   \n",
       "3  -5.745885  -4.851453  -2.372185  -2.677375  -1.294483  -1.588351   \n",
       "4 -11.175696  -9.916759 -10.240388  -9.676003  -9.011184  -8.094333   \n",
       "\n",
       "         6          7          8          9    ...        206        207  \\\n",
       "0 -16.167580 -15.591326 -15.285101 -16.635576  ...  -9.263520  -9.836855   \n",
       "1 -14.813755 -12.584860 -11.560820 -13.341023  ... -12.369427 -11.286713   \n",
       "2 -11.229615 -13.115143 -12.387643 -13.688749  ...   2.791893  -1.644092   \n",
       "3  -3.193917  -2.840873  -1.473870  -1.941777  ...  -7.527279  -8.047975   \n",
       "4  -8.224344  -6.904289  -6.189703  -6.950838  ...  -8.104716  -6.638175   \n",
       "\n",
       "         208        209        210        211        212        213       214  \\\n",
       "0  -9.000297  -8.610595  -7.708127  -8.924120  -6.446887  -6.100635 -5.777068   \n",
       "1 -12.561003 -13.209839 -14.229598 -14.887380 -13.279887 -10.424804 -9.198820   \n",
       "2  -7.576475  -8.142863  -3.416764  -0.235614  -0.058597   0.158079  0.453212   \n",
       "3  -8.805882 -10.848269 -14.466572 -14.186361 -12.370974 -11.046177 -9.836673   \n",
       "4  -5.050791  -5.673285  -6.665066  -7.014104  -7.494484  -9.089967 -6.788941   \n",
       "\n",
       "        215  \n",
       "0 -3.262930  \n",
       "1 -9.799427  \n",
       "2 -1.787468  \n",
       "3 -6.553540  \n",
       "4  0.912188  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(map(lambda x: x[1], y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_one_hot = pd.get_dummies(y_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_one_hot.columns = ['y' + str(i) for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y0  y1  y2  y3  y4  y5  y6  y7\n",
       "0   1   0   0   0   0   0   0   0\n",
       "1   1   0   0   0   0   0   0   0\n",
       "2   1   0   0   0   0   0   0   0\n",
       "3   1   0   0   0   0   0   0   0\n",
       "4   1   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df_one_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.326344</td>\n",
       "      <td>-17.296888</td>\n",
       "      <td>-20.150675</td>\n",
       "      <td>-18.294147</td>\n",
       "      <td>-17.103022</td>\n",
       "      <td>-16.043945</td>\n",
       "      <td>-16.167580</td>\n",
       "      <td>-15.591326</td>\n",
       "      <td>-15.285101</td>\n",
       "      <td>-16.635576</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.777068</td>\n",
       "      <td>-3.262930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.928268</td>\n",
       "      <td>-11.221898</td>\n",
       "      <td>-11.610126</td>\n",
       "      <td>-12.015554</td>\n",
       "      <td>-11.764825</td>\n",
       "      <td>-12.941557</td>\n",
       "      <td>-14.813755</td>\n",
       "      <td>-12.584860</td>\n",
       "      <td>-11.560820</td>\n",
       "      <td>-13.341023</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.198820</td>\n",
       "      <td>-9.799427</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.682770</td>\n",
       "      <td>-8.139627</td>\n",
       "      <td>-9.780738</td>\n",
       "      <td>-9.021040</td>\n",
       "      <td>-7.429825</td>\n",
       "      <td>-8.016786</td>\n",
       "      <td>-11.229615</td>\n",
       "      <td>-13.115143</td>\n",
       "      <td>-12.387643</td>\n",
       "      <td>-13.688749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453212</td>\n",
       "      <td>-1.787468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.745885</td>\n",
       "      <td>-4.851453</td>\n",
       "      <td>-2.372185</td>\n",
       "      <td>-2.677375</td>\n",
       "      <td>-1.294483</td>\n",
       "      <td>-1.588351</td>\n",
       "      <td>-3.193917</td>\n",
       "      <td>-2.840873</td>\n",
       "      <td>-1.473870</td>\n",
       "      <td>-1.941777</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.836673</td>\n",
       "      <td>-6.553540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.175696</td>\n",
       "      <td>-9.916759</td>\n",
       "      <td>-10.240388</td>\n",
       "      <td>-9.676003</td>\n",
       "      <td>-9.011184</td>\n",
       "      <td>-8.094333</td>\n",
       "      <td>-8.224344</td>\n",
       "      <td>-6.904289</td>\n",
       "      <td>-6.189703</td>\n",
       "      <td>-6.950838</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.788941</td>\n",
       "      <td>0.912188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5  \\\n",
       "0 -16.326344 -17.296888 -20.150675 -18.294147 -17.103022 -16.043945   \n",
       "1 -10.928268 -11.221898 -11.610126 -12.015554 -11.764825 -12.941557   \n",
       "2  -6.682770  -8.139627  -9.780738  -9.021040  -7.429825  -8.016786   \n",
       "3  -5.745885  -4.851453  -2.372185  -2.677375  -1.294483  -1.588351   \n",
       "4 -11.175696  -9.916759 -10.240388  -9.676003  -9.011184  -8.094333   \n",
       "\n",
       "           6          7          8          9  ...       214       215  y0  \\\n",
       "0 -16.167580 -15.591326 -15.285101 -16.635576  ... -5.777068 -3.262930   1   \n",
       "1 -14.813755 -12.584860 -11.560820 -13.341023  ... -9.198820 -9.799427   1   \n",
       "2 -11.229615 -13.115143 -12.387643 -13.688749  ...  0.453212 -1.787468   1   \n",
       "3  -3.193917  -2.840873  -1.473870  -1.941777  ... -9.836673 -6.553540   1   \n",
       "4  -8.224344  -6.904289  -6.189703  -6.950838  ... -6.788941  0.912188   1   \n",
       "\n",
       "   y1  y2  y3  y4  y5  y6  y7  \n",
       "0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([X_df, y_df_one_hot], axis=1, join=\"inner\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перемешиваем строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-14.336365</td>\n",
       "      <td>-18.434166</td>\n",
       "      <td>-36.444893</td>\n",
       "      <td>-38.979946</td>\n",
       "      <td>-40.082039</td>\n",
       "      <td>-40.134129</td>\n",
       "      <td>-39.824482</td>\n",
       "      <td>-39.696331</td>\n",
       "      <td>-39.672905</td>\n",
       "      <td>-39.855225</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.288723</td>\n",
       "      <td>-32.329247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-26.844685</td>\n",
       "      <td>-26.372921</td>\n",
       "      <td>-25.670422</td>\n",
       "      <td>-26.496016</td>\n",
       "      <td>-28.097734</td>\n",
       "      <td>-28.804609</td>\n",
       "      <td>-30.319942</td>\n",
       "      <td>-28.326519</td>\n",
       "      <td>-27.521799</td>\n",
       "      <td>-27.171021</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.452099</td>\n",
       "      <td>-23.930685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-21.369804</td>\n",
       "      <td>-24.315451</td>\n",
       "      <td>-31.552065</td>\n",
       "      <td>-33.512909</td>\n",
       "      <td>-34.008701</td>\n",
       "      <td>-34.261051</td>\n",
       "      <td>-34.469383</td>\n",
       "      <td>-37.682602</td>\n",
       "      <td>-38.426376</td>\n",
       "      <td>-40.362045</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.003563</td>\n",
       "      <td>-40.224724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2.831125</td>\n",
       "      <td>-0.877010</td>\n",
       "      <td>-12.888726</td>\n",
       "      <td>-12.064869</td>\n",
       "      <td>-8.980460</td>\n",
       "      <td>-10.204863</td>\n",
       "      <td>-8.665296</td>\n",
       "      <td>-7.667361</td>\n",
       "      <td>-9.432409</td>\n",
       "      <td>-11.393543</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.723922</td>\n",
       "      <td>3.454707</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-22.577364</td>\n",
       "      <td>-20.864346</td>\n",
       "      <td>-18.304888</td>\n",
       "      <td>-18.314985</td>\n",
       "      <td>-18.753752</td>\n",
       "      <td>-15.360708</td>\n",
       "      <td>-11.249742</td>\n",
       "      <td>-10.554243</td>\n",
       "      <td>-10.458380</td>\n",
       "      <td>-9.313645</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.980644</td>\n",
       "      <td>-25.071024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5  \\\n",
       "212 -14.336365 -18.434166 -36.444893 -38.979946 -40.082039 -40.134129   \n",
       "435 -26.844685 -26.372921 -25.670422 -26.496016 -28.097734 -28.804609   \n",
       "87  -21.369804 -24.315451 -31.552065 -33.512909 -34.008701 -34.261051   \n",
       "186   2.831125  -0.877010 -12.888726 -12.064869  -8.980460 -10.204863   \n",
       "494 -22.577364 -20.864346 -18.304888 -18.314985 -18.753752 -15.360708   \n",
       "\n",
       "             6          7          8          9  ...        214        215  \\\n",
       "212 -39.824482 -39.696331 -39.672905 -39.855225  ... -34.288723 -32.329247   \n",
       "435 -30.319942 -28.326519 -27.521799 -27.171021  ... -25.452099 -23.930685   \n",
       "87  -34.469383 -37.682602 -38.426376 -40.362045  ... -34.003563 -40.224724   \n",
       "186  -8.665296  -7.667361  -9.432409 -11.393543  ...  -2.723922   3.454707   \n",
       "494 -11.249742 -10.554243 -10.458380  -9.313645  ... -20.980644 -25.071024   \n",
       "\n",
       "     y0  y1  y2  y3  y4  y5  y6  y7  \n",
       "212   0   0   0   1   0   0   0   0  \n",
       "435   0   0   0   0   0   1   0   0  \n",
       "87    0   1   0   0   0   0   0   0  \n",
       "186   0   0   1   0   0   0   0   0  \n",
       "494   0   0   0   0   0   0   1   0  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = data[:500]\n",
    "Test_data = data[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 216), (108, 216))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = Train_data[list(range(216))]\n",
    "X_test = Test_data[list(range(216))]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 216, 1), (108, 216, 1))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(500, 216, 1)\n",
    "X_test = X_test.values.reshape(108, 216, 1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Train_data[y_df_one_hot.columns]\n",
    "y_test = Test_data[y_df_one_hot.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 27656     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 521,352\n",
      "Trainable params: 521,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "32/32 [==============================] - 4s 66ms/step - loss: 2.1104 - accuracy: 0.1353 - val_loss: 1.8318 - val_accuracy: 0.1389\n",
      "Epoch 2/700\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 1.7799 - accuracy: 0.2112 - val_loss: 1.7638 - val_accuracy: 0.1389\n",
      "Epoch 3/700\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 1.7474 - accuracy: 0.1965 - val_loss: 1.7341 - val_accuracy: 0.1667\n",
      "Epoch 4/700\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 1.6838 - accuracy: 0.2355 - val_loss: 1.7378 - val_accuracy: 0.1389\n",
      "Epoch 5/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.6803 - accuracy: 0.2197 - val_loss: 1.7039 - val_accuracy: 0.2037\n",
      "Epoch 6/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.7123 - accuracy: 0.1918 - val_loss: 1.6894 - val_accuracy: 0.2685\n",
      "Epoch 7/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.6956 - accuracy: 0.1851 - val_loss: 1.6959 - val_accuracy: 0.1574\n",
      "Epoch 8/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.5854 - accuracy: 0.2390 - val_loss: 1.6574 - val_accuracy: 0.2870\n",
      "Epoch 9/700\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 1.6091 - accuracy: 0.2485 - val_loss: 1.6553 - val_accuracy: 0.1852\n",
      "Epoch 10/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.5876 - accuracy: 0.3050 - val_loss: 1.6286 - val_accuracy: 0.3148\n",
      "Epoch 11/700\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 1.5795 - accuracy: 0.2898 - val_loss: 1.6074 - val_accuracy: 0.3148\n",
      "Epoch 12/700\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 1.5629 - accuracy: 0.2863 - val_loss: 1.6087 - val_accuracy: 0.2500\n",
      "Epoch 13/700\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 1.5854 - accuracy: 0.3239 - val_loss: 1.5940 - val_accuracy: 0.2222\n",
      "Epoch 14/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.5376 - accuracy: 0.2926 - val_loss: 1.5498 - val_accuracy: 0.3056\n",
      "Epoch 15/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.5329 - accuracy: 0.2826 - val_loss: 1.5406 - val_accuracy: 0.2685\n",
      "Epoch 16/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.5361 - accuracy: 0.2944 - val_loss: 1.5869 - val_accuracy: 0.3333\n",
      "Epoch 17/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.4710 - accuracy: 0.3597 - val_loss: 1.4781 - val_accuracy: 0.3519\n",
      "Epoch 18/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.4036 - accuracy: 0.3775 - val_loss: 1.4722 - val_accuracy: 0.3519\n",
      "Epoch 19/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.4316 - accuracy: 0.3513 - val_loss: 1.4693 - val_accuracy: 0.3889\n",
      "Epoch 20/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.4034 - accuracy: 0.3769 - val_loss: 1.4451 - val_accuracy: 0.3611\n",
      "Epoch 21/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.3332 - accuracy: 0.4220 - val_loss: 1.4264 - val_accuracy: 0.2685\n",
      "Epoch 22/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.3488 - accuracy: 0.3945 - val_loss: 1.4079 - val_accuracy: 0.4537\n",
      "Epoch 23/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.2847 - accuracy: 0.4928 - val_loss: 1.4050 - val_accuracy: 0.3056\n",
      "Epoch 24/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.2767 - accuracy: 0.4352 - val_loss: 1.3445 - val_accuracy: 0.4167\n",
      "Epoch 25/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.2892 - accuracy: 0.4478 - val_loss: 1.3073 - val_accuracy: 0.4259\n",
      "Epoch 26/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.2543 - accuracy: 0.4676 - val_loss: 1.2837 - val_accuracy: 0.5463\n",
      "Epoch 27/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.2411 - accuracy: 0.5130 - val_loss: 1.2571 - val_accuracy: 0.4907\n",
      "Epoch 28/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.2435 - accuracy: 0.4607 - val_loss: 1.2341 - val_accuracy: 0.4722\n",
      "Epoch 29/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.2176 - accuracy: 0.5080 - val_loss: 1.2053 - val_accuracy: 0.5000\n",
      "Epoch 30/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.1917 - accuracy: 0.4904 - val_loss: 1.1889 - val_accuracy: 0.5185\n",
      "Epoch 31/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.1478 - accuracy: 0.5453 - val_loss: 1.2377 - val_accuracy: 0.4815\n",
      "Epoch 32/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.1393 - accuracy: 0.4985 - val_loss: 1.1563 - val_accuracy: 0.5093\n",
      "Epoch 33/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.0842 - accuracy: 0.5622 - val_loss: 1.3320 - val_accuracy: 0.3889\n",
      "Epoch 34/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.1138 - accuracy: 0.5391 - val_loss: 1.3345 - val_accuracy: 0.3148\n",
      "Epoch 35/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 1.1291 - accuracy: 0.4891 - val_loss: 1.1089 - val_accuracy: 0.5278\n",
      "Epoch 36/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.0395 - accuracy: 0.5365 - val_loss: 1.1029 - val_accuracy: 0.5648\n",
      "Epoch 37/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.0646 - accuracy: 0.5444 - val_loss: 1.2004 - val_accuracy: 0.4630\n",
      "Epoch 38/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.0645 - accuracy: 0.5646 - val_loss: 1.0952 - val_accuracy: 0.4722\n",
      "Epoch 39/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.0154 - accuracy: 0.5583 - val_loss: 1.0295 - val_accuracy: 0.6111\n",
      "Epoch 40/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.0565 - accuracy: 0.5644 - val_loss: 1.0776 - val_accuracy: 0.4722\n",
      "Epoch 41/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.0057 - accuracy: 0.5506 - val_loss: 1.0445 - val_accuracy: 0.5556\n",
      "Epoch 42/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.0100 - accuracy: 0.5938 - val_loss: 1.0620 - val_accuracy: 0.5278\n",
      "Epoch 43/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.9707 - accuracy: 0.6016 - val_loss: 1.2075 - val_accuracy: 0.4537\n",
      "Epoch 44/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.9603 - accuracy: 0.6246 - val_loss: 1.0904 - val_accuracy: 0.5093\n",
      "Epoch 45/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.9604 - accuracy: 0.6318 - val_loss: 1.0156 - val_accuracy: 0.5185\n",
      "Epoch 46/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.9084 - accuracy: 0.6033 - val_loss: 0.9907 - val_accuracy: 0.5833\n",
      "Epoch 47/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.9649 - accuracy: 0.6047 - val_loss: 0.9495 - val_accuracy: 0.6481\n",
      "Epoch 48/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.9772 - accuracy: 0.5963 - val_loss: 1.1628 - val_accuracy: 0.4722\n",
      "Epoch 49/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.9212 - accuracy: 0.6197 - val_loss: 1.1215 - val_accuracy: 0.4815\n",
      "Epoch 50/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.9325 - accuracy: 0.6459 - val_loss: 1.0544 - val_accuracy: 0.5000\n",
      "Epoch 51/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.9262 - accuracy: 0.6372 - val_loss: 1.0837 - val_accuracy: 0.4722\n",
      "Epoch 52/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.9089 - accuracy: 0.6470 - val_loss: 0.9507 - val_accuracy: 0.6296\n",
      "Epoch 53/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.8797 - accuracy: 0.6223 - val_loss: 0.9245 - val_accuracy: 0.6389\n",
      "Epoch 54/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.8901 - accuracy: 0.6625 - val_loss: 0.9667 - val_accuracy: 0.5278\n",
      "Epoch 55/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.8967 - accuracy: 0.6074 - val_loss: 0.9046 - val_accuracy: 0.6389\n",
      "Epoch 56/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.9062 - accuracy: 0.6570 - val_loss: 0.9240 - val_accuracy: 0.6204\n",
      "Epoch 57/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.8534 - accuracy: 0.6565 - val_loss: 0.9606 - val_accuracy: 0.5833\n",
      "Epoch 58/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 43ms/step - loss: 0.8514 - accuracy: 0.6415 - val_loss: 0.9298 - val_accuracy: 0.5833\n",
      "Epoch 59/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8881 - accuracy: 0.6458 - val_loss: 0.9657 - val_accuracy: 0.5370\n",
      "Epoch 60/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.9047 - accuracy: 0.6299 - val_loss: 0.8924 - val_accuracy: 0.6111\n",
      "Epoch 61/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.8384 - accuracy: 0.6699 - val_loss: 0.9287 - val_accuracy: 0.6019\n",
      "Epoch 62/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8096 - accuracy: 0.6764 - val_loss: 0.8986 - val_accuracy: 0.6204\n",
      "Epoch 63/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8064 - accuracy: 0.7106 - val_loss: 0.8551 - val_accuracy: 0.6852\n",
      "Epoch 64/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.8429 - accuracy: 0.6691 - val_loss: 0.9031 - val_accuracy: 0.5926\n",
      "Epoch 65/700\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.8362 - accuracy: 0.6611 - val_loss: 0.8559 - val_accuracy: 0.6852\n",
      "Epoch 66/700\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.8342 - accuracy: 0.6345 - val_loss: 0.8860 - val_accuracy: 0.6574\n",
      "Epoch 67/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7768 - accuracy: 0.6688 - val_loss: 1.4097 - val_accuracy: 0.3519\n",
      "Epoch 68/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.8609 - accuracy: 0.6527 - val_loss: 0.8333 - val_accuracy: 0.6389\n",
      "Epoch 69/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8540 - accuracy: 0.6406 - val_loss: 0.9510 - val_accuracy: 0.5741\n",
      "Epoch 70/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.7827 - accuracy: 0.7006 - val_loss: 1.4035 - val_accuracy: 0.3611\n",
      "Epoch 71/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.7904 - accuracy: 0.6859 - val_loss: 0.8459 - val_accuracy: 0.6574\n",
      "Epoch 72/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.8345 - accuracy: 0.6254 - val_loss: 0.9490 - val_accuracy: 0.5741\n",
      "Epoch 73/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.7869 - accuracy: 0.6776 - val_loss: 1.0553 - val_accuracy: 0.5463\n",
      "Epoch 74/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.8241 - accuracy: 0.6745 - val_loss: 0.8380 - val_accuracy: 0.6574\n",
      "Epoch 75/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.7962 - accuracy: 0.6796 - val_loss: 0.8333 - val_accuracy: 0.6481\n",
      "Epoch 76/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.7989 - accuracy: 0.6848 - val_loss: 0.8320 - val_accuracy: 0.6481\n",
      "Epoch 77/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.7592 - accuracy: 0.6956 - val_loss: 0.8508 - val_accuracy: 0.6759\n",
      "Epoch 78/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.7537 - accuracy: 0.6921 - val_loss: 0.8376 - val_accuracy: 0.6852\n",
      "Epoch 79/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.7859 - accuracy: 0.6866 - val_loss: 0.8684 - val_accuracy: 0.6574\n",
      "Epoch 80/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7216 - accuracy: 0.6954 - val_loss: 0.8630 - val_accuracy: 0.6019\n",
      "Epoch 81/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.6521 - accuracy: 0.7621 - val_loss: 0.8936 - val_accuracy: 0.6296\n",
      "Epoch 82/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7621 - accuracy: 0.6926 - val_loss: 0.8263 - val_accuracy: 0.6204\n",
      "Epoch 83/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.6995 - accuracy: 0.7323 - val_loss: 0.8065 - val_accuracy: 0.6574\n",
      "Epoch 84/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.6909 - accuracy: 0.7445 - val_loss: 0.9282 - val_accuracy: 0.5648\n",
      "Epoch 85/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6860 - accuracy: 0.7458 - val_loss: 0.8145 - val_accuracy: 0.6111\n",
      "Epoch 86/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.7056 - accuracy: 0.6974 - val_loss: 0.8555 - val_accuracy: 0.6111\n",
      "Epoch 87/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7224 - accuracy: 0.6821 - val_loss: 0.8059 - val_accuracy: 0.6204\n",
      "Epoch 88/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.7110 - accuracy: 0.7074 - val_loss: 0.8049 - val_accuracy: 0.6759\n",
      "Epoch 89/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.7473 - accuracy: 0.7408 - val_loss: 0.8614 - val_accuracy: 0.6019\n",
      "Epoch 90/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6798 - accuracy: 0.7284 - val_loss: 0.7965 - val_accuracy: 0.6667\n",
      "Epoch 91/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6879 - accuracy: 0.7316 - val_loss: 0.9695 - val_accuracy: 0.5556\n",
      "Epoch 92/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6911 - accuracy: 0.7113 - val_loss: 1.0620 - val_accuracy: 0.4907\n",
      "Epoch 93/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6733 - accuracy: 0.7164 - val_loss: 0.9689 - val_accuracy: 0.5741\n",
      "Epoch 94/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.6873 - accuracy: 0.7242 - val_loss: 0.7900 - val_accuracy: 0.6296\n",
      "Epoch 95/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6392 - accuracy: 0.7534 - val_loss: 0.8565 - val_accuracy: 0.6481\n",
      "Epoch 96/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6499 - accuracy: 0.7436 - val_loss: 1.0572 - val_accuracy: 0.5093\n",
      "Epoch 97/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.7095 - accuracy: 0.7378 - val_loss: 1.1453 - val_accuracy: 0.5000\n",
      "Epoch 98/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6820 - accuracy: 0.7156 - val_loss: 0.8069 - val_accuracy: 0.6019\n",
      "Epoch 99/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6373 - accuracy: 0.7721 - val_loss: 0.8154 - val_accuracy: 0.6481\n",
      "Epoch 100/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6582 - accuracy: 0.7639 - val_loss: 0.7749 - val_accuracy: 0.6481\n",
      "Epoch 101/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6779 - accuracy: 0.7397 - val_loss: 0.7709 - val_accuracy: 0.6296\n",
      "Epoch 102/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6073 - accuracy: 0.7733 - val_loss: 0.7793 - val_accuracy: 0.6296\n",
      "Epoch 103/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6875 - accuracy: 0.7002 - val_loss: 0.8895 - val_accuracy: 0.6204\n",
      "Epoch 104/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6392 - accuracy: 0.7160 - val_loss: 1.1064 - val_accuracy: 0.5370\n",
      "Epoch 105/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5900 - accuracy: 0.7833 - val_loss: 0.7888 - val_accuracy: 0.6204\n",
      "Epoch 106/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6390 - accuracy: 0.7360 - val_loss: 0.7403 - val_accuracy: 0.6759\n",
      "Epoch 107/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6668 - accuracy: 0.7244 - val_loss: 0.7692 - val_accuracy: 0.6852\n",
      "Epoch 108/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6360 - accuracy: 0.7489 - val_loss: 0.8184 - val_accuracy: 0.6296\n",
      "Epoch 109/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5831 - accuracy: 0.7821 - val_loss: 1.2062 - val_accuracy: 0.4444\n",
      "Epoch 110/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6376 - accuracy: 0.7564 - val_loss: 0.7392 - val_accuracy: 0.6852\n",
      "Epoch 111/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5715 - accuracy: 0.7774 - val_loss: 1.0344 - val_accuracy: 0.5833\n",
      "Epoch 112/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5631 - accuracy: 0.7720 - val_loss: 0.7900 - val_accuracy: 0.6204\n",
      "Epoch 113/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5552 - accuracy: 0.8088 - val_loss: 0.7422 - val_accuracy: 0.6852\n",
      "Epoch 114/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5612 - accuracy: 0.7856 - val_loss: 0.7744 - val_accuracy: 0.6296\n",
      "Epoch 115/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 41ms/step - loss: 0.6069 - accuracy: 0.7674 - val_loss: 0.7602 - val_accuracy: 0.6944\n",
      "Epoch 116/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.6022 - accuracy: 0.7530 - val_loss: 0.9289 - val_accuracy: 0.5741\n",
      "Epoch 117/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5646 - accuracy: 0.8024 - val_loss: 0.9453 - val_accuracy: 0.5833\n",
      "Epoch 118/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.6028 - accuracy: 0.7550 - val_loss: 0.7380 - val_accuracy: 0.6759\n",
      "Epoch 119/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.5684 - accuracy: 0.7773 - val_loss: 0.7419 - val_accuracy: 0.6759\n",
      "Epoch 120/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5940 - accuracy: 0.7918 - val_loss: 0.7516 - val_accuracy: 0.7037\n",
      "Epoch 121/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5690 - accuracy: 0.7943 - val_loss: 0.8491 - val_accuracy: 0.6296\n",
      "Epoch 122/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5761 - accuracy: 0.7737 - val_loss: 1.0553 - val_accuracy: 0.5093\n",
      "Epoch 123/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5497 - accuracy: 0.7761 - val_loss: 0.7445 - val_accuracy: 0.6296\n",
      "Epoch 124/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5493 - accuracy: 0.7671 - val_loss: 0.7328 - val_accuracy: 0.6852\n",
      "Epoch 125/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5320 - accuracy: 0.8041 - val_loss: 0.7258 - val_accuracy: 0.7037\n",
      "Epoch 126/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5757 - accuracy: 0.7715 - val_loss: 0.7041 - val_accuracy: 0.7222\n",
      "Epoch 127/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5222 - accuracy: 0.8086 - val_loss: 0.7960 - val_accuracy: 0.6667\n",
      "Epoch 128/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5447 - accuracy: 0.7826 - val_loss: 0.7767 - val_accuracy: 0.6574\n",
      "Epoch 129/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5394 - accuracy: 0.7980 - val_loss: 0.9286 - val_accuracy: 0.5833\n",
      "Epoch 130/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5999 - accuracy: 0.7644 - val_loss: 0.8009 - val_accuracy: 0.6389\n",
      "Epoch 131/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5289 - accuracy: 0.8328 - val_loss: 0.7489 - val_accuracy: 0.7037\n",
      "Epoch 132/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5135 - accuracy: 0.7998 - val_loss: 0.7143 - val_accuracy: 0.7222\n",
      "Epoch 133/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.5491 - accuracy: 0.7922 - val_loss: 0.7966 - val_accuracy: 0.6204\n",
      "Epoch 134/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5111 - accuracy: 0.8205 - val_loss: 0.7712 - val_accuracy: 0.6852\n",
      "Epoch 135/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5508 - accuracy: 0.7854 - val_loss: 0.7001 - val_accuracy: 0.7222\n",
      "Epoch 136/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4698 - accuracy: 0.8354 - val_loss: 0.6990 - val_accuracy: 0.6944\n",
      "Epoch 137/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5235 - accuracy: 0.7978 - val_loss: 0.7330 - val_accuracy: 0.6852\n",
      "Epoch 138/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.4721 - accuracy: 0.8229 - val_loss: 0.6801 - val_accuracy: 0.6852\n",
      "Epoch 139/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4910 - accuracy: 0.8198 - val_loss: 0.8274 - val_accuracy: 0.6574\n",
      "Epoch 140/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4934 - accuracy: 0.8130 - val_loss: 0.6918 - val_accuracy: 0.7222\n",
      "Epoch 141/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5335 - accuracy: 0.8082 - val_loss: 0.8031 - val_accuracy: 0.6481\n",
      "Epoch 142/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.4888 - accuracy: 0.8149 - val_loss: 0.8190 - val_accuracy: 0.6389\n",
      "Epoch 143/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5139 - accuracy: 0.7814 - val_loss: 0.8490 - val_accuracy: 0.6481\n",
      "Epoch 144/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5193 - accuracy: 0.8320 - val_loss: 0.6861 - val_accuracy: 0.7130\n",
      "Epoch 145/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4895 - accuracy: 0.8187 - val_loss: 0.8494 - val_accuracy: 0.6296\n",
      "Epoch 146/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5111 - accuracy: 0.7910 - val_loss: 0.7064 - val_accuracy: 0.6852\n",
      "Epoch 147/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4852 - accuracy: 0.8402 - val_loss: 0.7293 - val_accuracy: 0.6944\n",
      "Epoch 148/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4358 - accuracy: 0.8688 - val_loss: 0.7090 - val_accuracy: 0.6944\n",
      "Epoch 149/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4801 - accuracy: 0.8394 - val_loss: 1.0473 - val_accuracy: 0.5926\n",
      "Epoch 150/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5796 - accuracy: 0.7801 - val_loss: 0.8358 - val_accuracy: 0.6574\n",
      "Epoch 151/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4989 - accuracy: 0.8004 - val_loss: 0.7039 - val_accuracy: 0.7130\n",
      "Epoch 152/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4645 - accuracy: 0.8323 - val_loss: 0.7089 - val_accuracy: 0.6852\n",
      "Epoch 153/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.4351 - accuracy: 0.8388 - val_loss: 0.7821 - val_accuracy: 0.6852\n",
      "Epoch 154/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.4887 - accuracy: 0.8421 - val_loss: 0.7692 - val_accuracy: 0.6759\n",
      "Epoch 155/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5016 - accuracy: 0.7896 - val_loss: 0.7819 - val_accuracy: 0.6852\n",
      "Epoch 156/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.4452 - accuracy: 0.8397 - val_loss: 0.9282 - val_accuracy: 0.6389\n",
      "Epoch 157/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4218 - accuracy: 0.8655 - val_loss: 0.8333 - val_accuracy: 0.6759\n",
      "Epoch 158/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.4626 - accuracy: 0.8283 - val_loss: 0.6834 - val_accuracy: 0.7315\n",
      "Epoch 159/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4455 - accuracy: 0.8419 - val_loss: 0.6858 - val_accuracy: 0.7407\n",
      "Epoch 160/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4855 - accuracy: 0.8263 - val_loss: 0.7160 - val_accuracy: 0.6944\n",
      "Epoch 161/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4692 - accuracy: 0.8255 - val_loss: 1.3104 - val_accuracy: 0.5185\n",
      "Epoch 162/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5326 - accuracy: 0.7619 - val_loss: 0.7790 - val_accuracy: 0.6944\n",
      "Epoch 163/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4474 - accuracy: 0.8327 - val_loss: 0.6504 - val_accuracy: 0.7315\n",
      "Epoch 164/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4414 - accuracy: 0.8514 - val_loss: 0.7217 - val_accuracy: 0.6944\n",
      "Epoch 165/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4079 - accuracy: 0.8665 - val_loss: 0.7052 - val_accuracy: 0.7500\n",
      "Epoch 166/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4405 - accuracy: 0.8416 - val_loss: 0.7084 - val_accuracy: 0.7037\n",
      "Epoch 167/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.4563 - accuracy: 0.8069 - val_loss: 0.8397 - val_accuracy: 0.6759\n",
      "Epoch 168/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.3962 - accuracy: 0.8803 - val_loss: 0.7489 - val_accuracy: 0.7130\n",
      "Epoch 169/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4404 - accuracy: 0.8406 - val_loss: 0.6931 - val_accuracy: 0.7222\n",
      "Epoch 170/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4317 - accuracy: 0.8470 - val_loss: 0.6687 - val_accuracy: 0.7407\n",
      "Epoch 171/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.4514 - accuracy: 0.8334 - val_loss: 0.7542 - val_accuracy: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4125 - accuracy: 0.8436 - val_loss: 0.6747 - val_accuracy: 0.7407\n",
      "Epoch 173/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4082 - accuracy: 0.8699 - val_loss: 0.6772 - val_accuracy: 0.7315\n",
      "Epoch 174/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4341 - accuracy: 0.8380 - val_loss: 0.7222 - val_accuracy: 0.7130\n",
      "Epoch 175/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4368 - accuracy: 0.8271 - val_loss: 0.8316 - val_accuracy: 0.6852\n",
      "Epoch 176/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4352 - accuracy: 0.8553 - val_loss: 0.7619 - val_accuracy: 0.7037\n",
      "Epoch 177/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.3637 - accuracy: 0.9038 - val_loss: 0.8285 - val_accuracy: 0.6944\n",
      "Epoch 178/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.3977 - accuracy: 0.8674 - val_loss: 0.7236 - val_accuracy: 0.7315\n",
      "Epoch 179/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4154 - accuracy: 0.8388 - val_loss: 0.7476 - val_accuracy: 0.6944\n",
      "Epoch 180/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4103 - accuracy: 0.8623 - val_loss: 0.7643 - val_accuracy: 0.7130\n",
      "Epoch 181/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3814 - accuracy: 0.8923 - val_loss: 0.6830 - val_accuracy: 0.7130\n",
      "Epoch 182/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3584 - accuracy: 0.9014 - val_loss: 0.6880 - val_accuracy: 0.7407\n",
      "Epoch 183/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4923 - accuracy: 0.8315 - val_loss: 0.6988 - val_accuracy: 0.7500\n",
      "Epoch 184/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3878 - accuracy: 0.8497 - val_loss: 0.6762 - val_accuracy: 0.7500\n",
      "Epoch 185/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3947 - accuracy: 0.8426 - val_loss: 0.8383 - val_accuracy: 0.6944\n",
      "Epoch 186/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3599 - accuracy: 0.8861 - val_loss: 0.6727 - val_accuracy: 0.7222\n",
      "Epoch 187/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4022 - accuracy: 0.8658 - val_loss: 0.6867 - val_accuracy: 0.7315\n",
      "Epoch 188/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.3959 - accuracy: 0.8440 - val_loss: 0.6526 - val_accuracy: 0.7407\n",
      "Epoch 189/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4181 - accuracy: 0.8341 - val_loss: 0.8434 - val_accuracy: 0.6759\n",
      "Epoch 190/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.4295 - accuracy: 0.8436 - val_loss: 0.7343 - val_accuracy: 0.7407\n",
      "Epoch 191/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3931 - accuracy: 0.8381 - val_loss: 0.6932 - val_accuracy: 0.7222\n",
      "Epoch 192/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3502 - accuracy: 0.9060 - val_loss: 0.6609 - val_accuracy: 0.7407\n",
      "Epoch 193/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3486 - accuracy: 0.8793 - val_loss: 0.6637 - val_accuracy: 0.7407\n",
      "Epoch 194/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.4090 - accuracy: 0.8675 - val_loss: 0.7293 - val_accuracy: 0.7500\n",
      "Epoch 195/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.3991 - accuracy: 0.8879 - val_loss: 0.7962 - val_accuracy: 0.6852\n",
      "Epoch 196/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.3832 - accuracy: 0.8582 - val_loss: 0.6813 - val_accuracy: 0.7222\n",
      "Epoch 197/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3425 - accuracy: 0.8950 - val_loss: 0.6353 - val_accuracy: 0.7593\n",
      "Epoch 198/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3699 - accuracy: 0.8733 - val_loss: 1.7473 - val_accuracy: 0.4352\n",
      "Epoch 199/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5037 - accuracy: 0.8510 - val_loss: 0.6596 - val_accuracy: 0.7685\n",
      "Epoch 200/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.3497 - accuracy: 0.8640 - val_loss: 0.7624 - val_accuracy: 0.7407\n",
      "Epoch 201/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4229 - accuracy: 0.8551 - val_loss: 0.6672 - val_accuracy: 0.7500\n",
      "Epoch 202/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.3261 - accuracy: 0.9025 - val_loss: 0.7253 - val_accuracy: 0.7315\n",
      "Epoch 203/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3465 - accuracy: 0.8736 - val_loss: 0.7205 - val_accuracy: 0.7593\n",
      "Epoch 204/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.3526 - accuracy: 0.8456 - val_loss: 0.6566 - val_accuracy: 0.7500\n",
      "Epoch 205/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.3534 - accuracy: 0.8831 - val_loss: 0.7962 - val_accuracy: 0.7315\n",
      "Epoch 206/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.3368 - accuracy: 0.8823 - val_loss: 0.6531 - val_accuracy: 0.7778\n",
      "Epoch 207/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.3499 - accuracy: 0.8855 - val_loss: 0.6965 - val_accuracy: 0.7685\n",
      "Epoch 208/700\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.89 - 1s 41ms/step - loss: 0.3225 - accuracy: 0.8948 - val_loss: 0.6603 - val_accuracy: 0.7222\n",
      "Epoch 209/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3695 - accuracy: 0.8703 - val_loss: 0.8595 - val_accuracy: 0.7037\n",
      "Epoch 210/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2797 - accuracy: 0.9302 - val_loss: 0.6629 - val_accuracy: 0.7500\n",
      "Epoch 211/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3432 - accuracy: 0.8919 - val_loss: 0.7191 - val_accuracy: 0.7222\n",
      "Epoch 212/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3502 - accuracy: 0.8700 - val_loss: 0.6643 - val_accuracy: 0.7778\n",
      "Epoch 213/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3199 - accuracy: 0.8880 - val_loss: 1.3090 - val_accuracy: 0.5926\n",
      "Epoch 214/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3962 - accuracy: 0.8627 - val_loss: 0.7230 - val_accuracy: 0.7500\n",
      "Epoch 215/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3352 - accuracy: 0.8984 - val_loss: 0.6802 - val_accuracy: 0.7315\n",
      "Epoch 216/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.3381 - accuracy: 0.8909 - val_loss: 0.7113 - val_accuracy: 0.7500\n",
      "Epoch 217/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2825 - accuracy: 0.9274 - val_loss: 0.8649 - val_accuracy: 0.6667\n",
      "Epoch 218/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.3418 - accuracy: 0.8892 - val_loss: 0.6631 - val_accuracy: 0.7593\n",
      "Epoch 219/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.3427 - accuracy: 0.8813 - val_loss: 0.7052 - val_accuracy: 0.7593\n",
      "Epoch 220/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3176 - accuracy: 0.9023 - val_loss: 0.6334 - val_accuracy: 0.7593\n",
      "Epoch 221/700\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.3168 - accuracy: 0.8696 - val_loss: 0.6725 - val_accuracy: 0.7500\n",
      "Epoch 222/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2979 - accuracy: 0.9274 - val_loss: 0.7726 - val_accuracy: 0.7130\n",
      "Epoch 223/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3012 - accuracy: 0.9024 - val_loss: 0.6768 - val_accuracy: 0.7407\n",
      "Epoch 224/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3162 - accuracy: 0.8803 - val_loss: 0.6511 - val_accuracy: 0.7407\n",
      "Epoch 225/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.3187 - accuracy: 0.8875 - val_loss: 0.6106 - val_accuracy: 0.7963\n",
      "Epoch 226/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2612 - accuracy: 0.9330 - val_loss: 0.6588 - val_accuracy: 0.7870\n",
      "Epoch 227/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2882 - accuracy: 0.9180 - val_loss: 0.6077 - val_accuracy: 0.7778\n",
      "Epoch 228/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 44ms/step - loss: 0.3028 - accuracy: 0.9176 - val_loss: 0.6762 - val_accuracy: 0.7407\n",
      "Epoch 229/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.3091 - accuracy: 0.8924 - val_loss: 0.8131 - val_accuracy: 0.7315\n",
      "Epoch 230/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2777 - accuracy: 0.9184 - val_loss: 0.7447 - val_accuracy: 0.7500\n",
      "Epoch 231/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3128 - accuracy: 0.8963 - val_loss: 0.8681 - val_accuracy: 0.6944\n",
      "Epoch 232/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.3196 - accuracy: 0.8762 - val_loss: 0.6909 - val_accuracy: 0.7593\n",
      "Epoch 233/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2822 - accuracy: 0.9164 - val_loss: 0.6335 - val_accuracy: 0.7685\n",
      "Epoch 234/700\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.2898 - accuracy: 0.9051 - val_loss: 0.6158 - val_accuracy: 0.7870\n",
      "Epoch 235/700\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.2855 - accuracy: 0.9012 - val_loss: 0.7357 - val_accuracy: 0.7500\n",
      "Epoch 236/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2958 - accuracy: 0.9040 - val_loss: 0.7052 - val_accuracy: 0.7593\n",
      "Epoch 237/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.3179 - accuracy: 0.9072 - val_loss: 0.7929 - val_accuracy: 0.7315\n",
      "Epoch 238/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2799 - accuracy: 0.9010 - val_loss: 0.8034 - val_accuracy: 0.7222\n",
      "Epoch 239/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2989 - accuracy: 0.8893 - val_loss: 0.9870 - val_accuracy: 0.6481\n",
      "Epoch 240/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3219 - accuracy: 0.9210 - val_loss: 0.6505 - val_accuracy: 0.7778\n",
      "Epoch 241/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2954 - accuracy: 0.9027 - val_loss: 0.6209 - val_accuracy: 0.7963\n",
      "Epoch 242/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2838 - accuracy: 0.9213 - val_loss: 0.6376 - val_accuracy: 0.7685\n",
      "Epoch 243/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2752 - accuracy: 0.9112 - val_loss: 0.6668 - val_accuracy: 0.7778\n",
      "Epoch 244/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2605 - accuracy: 0.9364 - val_loss: 0.6410 - val_accuracy: 0.7407\n",
      "Epoch 245/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2516 - accuracy: 0.9238 - val_loss: 0.7551 - val_accuracy: 0.7407\n",
      "Epoch 246/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3121 - accuracy: 0.8915 - val_loss: 0.6304 - val_accuracy: 0.7870\n",
      "Epoch 247/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3081 - accuracy: 0.8908 - val_loss: 1.1470 - val_accuracy: 0.6204\n",
      "Epoch 248/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2907 - accuracy: 0.9105 - val_loss: 0.6633 - val_accuracy: 0.7593\n",
      "Epoch 249/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2476 - accuracy: 0.9318 - val_loss: 0.6803 - val_accuracy: 0.7500\n",
      "Epoch 250/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2718 - accuracy: 0.9038 - val_loss: 0.8546 - val_accuracy: 0.7037\n",
      "Epoch 251/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2928 - accuracy: 0.8938 - val_loss: 0.7088 - val_accuracy: 0.7500\n",
      "Epoch 252/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2930 - accuracy: 0.9169 - val_loss: 0.7029 - val_accuracy: 0.7500\n",
      "Epoch 253/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2493 - accuracy: 0.9279 - val_loss: 0.6417 - val_accuracy: 0.7500\n",
      "Epoch 254/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2828 - accuracy: 0.9166 - val_loss: 0.6095 - val_accuracy: 0.7963\n",
      "Epoch 255/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2684 - accuracy: 0.9424 - val_loss: 0.6454 - val_accuracy: 0.7500\n",
      "Epoch 256/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2584 - accuracy: 0.8986 - val_loss: 0.6379 - val_accuracy: 0.7685\n",
      "Epoch 257/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2323 - accuracy: 0.9360 - val_loss: 0.6186 - val_accuracy: 0.7963\n",
      "Epoch 258/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2677 - accuracy: 0.9153 - val_loss: 0.6224 - val_accuracy: 0.7593\n",
      "Epoch 259/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2466 - accuracy: 0.9224 - val_loss: 0.7550 - val_accuracy: 0.7315\n",
      "Epoch 260/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2429 - accuracy: 0.9154 - val_loss: 0.6368 - val_accuracy: 0.7500\n",
      "Epoch 261/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2692 - accuracy: 0.9097 - val_loss: 0.6380 - val_accuracy: 0.7963\n",
      "Epoch 262/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2519 - accuracy: 0.9329 - val_loss: 0.6718 - val_accuracy: 0.7593\n",
      "Epoch 263/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2588 - accuracy: 0.9140 - val_loss: 0.6361 - val_accuracy: 0.7407\n",
      "Epoch 264/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2621 - accuracy: 0.9157 - val_loss: 0.9267 - val_accuracy: 0.7037\n",
      "Epoch 265/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2394 - accuracy: 0.9207 - val_loss: 0.6422 - val_accuracy: 0.7593\n",
      "Epoch 266/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2205 - accuracy: 0.9522 - val_loss: 1.2998 - val_accuracy: 0.6111\n",
      "Epoch 267/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2539 - accuracy: 0.9207 - val_loss: 1.1307 - val_accuracy: 0.6389\n",
      "Epoch 268/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2925 - accuracy: 0.9029 - val_loss: 0.6107 - val_accuracy: 0.7870\n",
      "Epoch 269/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2547 - accuracy: 0.9317 - val_loss: 0.6858 - val_accuracy: 0.7778\n",
      "Epoch 270/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2258 - accuracy: 0.9281 - val_loss: 0.6531 - val_accuracy: 0.7963\n",
      "Epoch 271/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2169 - accuracy: 0.9439 - val_loss: 0.7912 - val_accuracy: 0.7685\n",
      "Epoch 272/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2448 - accuracy: 0.9494 - val_loss: 0.9914 - val_accuracy: 0.6574\n",
      "Epoch 273/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2612 - accuracy: 0.9129 - val_loss: 0.6422 - val_accuracy: 0.7500\n",
      "Epoch 274/700\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.2201 - accuracy: 0.9455 - val_loss: 1.0834 - val_accuracy: 0.6204\n",
      "Epoch 275/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2131 - accuracy: 0.9181 - val_loss: 0.6392 - val_accuracy: 0.7778\n",
      "Epoch 276/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2174 - accuracy: 0.9318 - val_loss: 0.6308 - val_accuracy: 0.7685\n",
      "Epoch 277/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2726 - accuracy: 0.9118 - val_loss: 0.6716 - val_accuracy: 0.7778\n",
      "Epoch 278/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1988 - accuracy: 0.9508 - val_loss: 0.6590 - val_accuracy: 0.7593\n",
      "Epoch 279/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2384 - accuracy: 0.9285 - val_loss: 0.7187 - val_accuracy: 0.7407\n",
      "Epoch 280/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2213 - accuracy: 0.9383 - val_loss: 0.6109 - val_accuracy: 0.7963\n",
      "Epoch 281/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2269 - accuracy: 0.9193 - val_loss: 0.6795 - val_accuracy: 0.7870\n",
      "Epoch 282/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.1993 - accuracy: 0.9475 - val_loss: 0.7214 - val_accuracy: 0.7593\n",
      "Epoch 283/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2349 - accuracy: 0.9178 - val_loss: 0.6599 - val_accuracy: 0.7778\n",
      "Epoch 284/700\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.1701 - accuracy: 0.9469 - val_loss: 0.6952 - val_accuracy: 0.7315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/700\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.2106 - accuracy: 0.9264 - val_loss: 0.7164 - val_accuracy: 0.7685\n",
      "Epoch 286/700\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.2024 - accuracy: 0.9301 - val_loss: 0.6344 - val_accuracy: 0.7963\n",
      "Epoch 287/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2401 - accuracy: 0.9203 - val_loss: 0.7103 - val_accuracy: 0.7870\n",
      "Epoch 288/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2107 - accuracy: 0.9374 - val_loss: 0.7315 - val_accuracy: 0.7778\n",
      "Epoch 289/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2380 - accuracy: 0.9185 - val_loss: 0.8487 - val_accuracy: 0.7222\n",
      "Epoch 290/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2061 - accuracy: 0.9247 - val_loss: 0.6450 - val_accuracy: 0.7685\n",
      "Epoch 291/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2089 - accuracy: 0.9230 - val_loss: 0.6535 - val_accuracy: 0.7500\n",
      "Epoch 292/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1983 - accuracy: 0.9457 - val_loss: 0.6910 - val_accuracy: 0.7778\n",
      "Epoch 293/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1970 - accuracy: 0.9419 - val_loss: 0.6610 - val_accuracy: 0.7685\n",
      "Epoch 294/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1923 - accuracy: 0.9521 - val_loss: 0.6601 - val_accuracy: 0.7778\n",
      "Epoch 295/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1849 - accuracy: 0.9443 - val_loss: 0.6309 - val_accuracy: 0.7963\n",
      "Epoch 296/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.1953 - accuracy: 0.9325 - val_loss: 0.8003 - val_accuracy: 0.7315\n",
      "Epoch 297/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2097 - accuracy: 0.9436 - val_loss: 0.6591 - val_accuracy: 0.8148\n",
      "Epoch 298/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1760 - accuracy: 0.9410 - val_loss: 0.6934 - val_accuracy: 0.7870\n",
      "Epoch 299/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2024 - accuracy: 0.9308 - val_loss: 0.6635 - val_accuracy: 0.7870\n",
      "Epoch 300/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2000 - accuracy: 0.9312 - val_loss: 0.9549 - val_accuracy: 0.6944\n",
      "Epoch 301/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.1909 - accuracy: 0.9334 - val_loss: 0.6695 - val_accuracy: 0.7963\n",
      "Epoch 302/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1717 - accuracy: 0.9544 - val_loss: 0.6276 - val_accuracy: 0.7778\n",
      "Epoch 303/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2031 - accuracy: 0.9387 - val_loss: 0.6670 - val_accuracy: 0.7593\n",
      "Epoch 304/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1738 - accuracy: 0.9445 - val_loss: 0.6383 - val_accuracy: 0.7593\n",
      "Epoch 305/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1571 - accuracy: 0.9642 - val_loss: 0.6141 - val_accuracy: 0.8056\n",
      "Epoch 306/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1962 - accuracy: 0.9546 - val_loss: 0.6768 - val_accuracy: 0.7685\n",
      "Epoch 307/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1728 - accuracy: 0.9511 - val_loss: 0.6121 - val_accuracy: 0.8241\n",
      "Epoch 308/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2431 - accuracy: 0.9137 - val_loss: 0.6318 - val_accuracy: 0.7685\n",
      "Epoch 309/700\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.96 - 1s 42ms/step - loss: 0.1891 - accuracy: 0.9678 - val_loss: 0.6125 - val_accuracy: 0.8148\n",
      "Epoch 310/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1829 - accuracy: 0.9464 - val_loss: 0.7916 - val_accuracy: 0.7685\n",
      "Epoch 311/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1824 - accuracy: 0.9259 - val_loss: 0.6953 - val_accuracy: 0.7778\n",
      "Epoch 312/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1611 - accuracy: 0.9647 - val_loss: 0.8423 - val_accuracy: 0.7593\n",
      "Epoch 313/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2018 - accuracy: 0.9183 - val_loss: 0.6261 - val_accuracy: 0.7778\n",
      "Epoch 314/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1700 - accuracy: 0.9399 - val_loss: 0.6800 - val_accuracy: 0.7870\n",
      "Epoch 315/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1733 - accuracy: 0.9561 - val_loss: 0.7652 - val_accuracy: 0.7778\n",
      "Epoch 316/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2130 - accuracy: 0.9170 - val_loss: 0.6427 - val_accuracy: 0.7593\n",
      "Epoch 317/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1566 - accuracy: 0.9650 - val_loss: 0.7570 - val_accuracy: 0.7407\n",
      "Epoch 318/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1908 - accuracy: 0.9408 - val_loss: 0.6676 - val_accuracy: 0.7870\n",
      "Epoch 319/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1609 - accuracy: 0.9512 - val_loss: 0.6161 - val_accuracy: 0.8056\n",
      "Epoch 320/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1695 - accuracy: 0.9438 - val_loss: 0.8358 - val_accuracy: 0.7500\n",
      "Epoch 321/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1626 - accuracy: 0.9584 - val_loss: 0.9537 - val_accuracy: 0.6944\n",
      "Epoch 322/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1847 - accuracy: 0.9447 - val_loss: 0.7244 - val_accuracy: 0.7870\n",
      "Epoch 323/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2165 - accuracy: 0.9381 - val_loss: 0.6160 - val_accuracy: 0.8148\n",
      "Epoch 324/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1558 - accuracy: 0.9533 - val_loss: 0.6897 - val_accuracy: 0.7685\n",
      "Epoch 325/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1345 - accuracy: 0.9694 - val_loss: 0.6784 - val_accuracy: 0.8056\n",
      "Epoch 326/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.1466 - accuracy: 0.9587 - val_loss: 0.6127 - val_accuracy: 0.8241\n",
      "Epoch 327/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1463 - accuracy: 0.9594 - val_loss: 0.6779 - val_accuracy: 0.7963\n",
      "Epoch 328/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1672 - accuracy: 0.9504 - val_loss: 0.6568 - val_accuracy: 0.7870\n",
      "Epoch 329/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1227 - accuracy: 0.9736 - val_loss: 0.8480 - val_accuracy: 0.7500\n",
      "Epoch 330/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1998 - accuracy: 0.9290 - val_loss: 0.6522 - val_accuracy: 0.7963\n",
      "Epoch 331/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1593 - accuracy: 0.9579 - val_loss: 0.6351 - val_accuracy: 0.8148\n",
      "Epoch 332/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1822 - accuracy: 0.9519 - val_loss: 0.6578 - val_accuracy: 0.7870\n",
      "Epoch 333/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1473 - accuracy: 0.9524 - val_loss: 0.6362 - val_accuracy: 0.8333\n",
      "Epoch 334/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1743 - accuracy: 0.9464 - val_loss: 0.7522 - val_accuracy: 0.7778\n",
      "Epoch 335/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1559 - accuracy: 0.9584 - val_loss: 0.6478 - val_accuracy: 0.8333\n",
      "Epoch 336/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1324 - accuracy: 0.9631 - val_loss: 0.6548 - val_accuracy: 0.7870\n",
      "Epoch 337/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1755 - accuracy: 0.9426 - val_loss: 0.6341 - val_accuracy: 0.8241\n",
      "Epoch 338/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1715 - accuracy: 0.9554 - val_loss: 0.6833 - val_accuracy: 0.8056\n",
      "Epoch 339/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1155 - accuracy: 0.9755 - val_loss: 0.7946 - val_accuracy: 0.7685\n",
      "Epoch 340/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1285 - accuracy: 0.9674 - val_loss: 0.6441 - val_accuracy: 0.8241\n",
      "Epoch 341/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1474 - accuracy: 0.9687 - val_loss: 0.6496 - val_accuracy: 0.7963\n",
      "Epoch 342/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1310 - accuracy: 0.9629 - val_loss: 0.6479 - val_accuracy: 0.8333\n",
      "Epoch 343/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1763 - accuracy: 0.9527 - val_loss: 0.6393 - val_accuracy: 0.8241\n",
      "Epoch 344/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1261 - accuracy: 0.9759 - val_loss: 0.6156 - val_accuracy: 0.8241\n",
      "Epoch 345/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1624 - accuracy: 0.9511 - val_loss: 0.6396 - val_accuracy: 0.8241\n",
      "Epoch 346/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1161 - accuracy: 0.9733 - val_loss: 0.6364 - val_accuracy: 0.7963\n",
      "Epoch 347/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1622 - accuracy: 0.9683 - val_loss: 0.7986 - val_accuracy: 0.7778\n",
      "Epoch 348/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1654 - accuracy: 0.9490 - val_loss: 0.6565 - val_accuracy: 0.7963\n",
      "Epoch 349/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1270 - accuracy: 0.9675 - val_loss: 0.6574 - val_accuracy: 0.8241\n",
      "Epoch 350/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1568 - accuracy: 0.9633 - val_loss: 0.6328 - val_accuracy: 0.8241\n",
      "Epoch 351/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1197 - accuracy: 0.9585 - val_loss: 0.6523 - val_accuracy: 0.8056\n",
      "Epoch 352/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1416 - accuracy: 0.9612 - val_loss: 0.6969 - val_accuracy: 0.8148\n",
      "Epoch 353/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1724 - accuracy: 0.9517 - val_loss: 0.7260 - val_accuracy: 0.7963\n",
      "Epoch 354/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1237 - accuracy: 0.9639 - val_loss: 0.7179 - val_accuracy: 0.8056\n",
      "Epoch 355/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1360 - accuracy: 0.9564 - val_loss: 0.8018 - val_accuracy: 0.7870\n",
      "Epoch 356/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1237 - accuracy: 0.9679 - val_loss: 0.6579 - val_accuracy: 0.8333\n",
      "Epoch 357/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1174 - accuracy: 0.9688 - val_loss: 0.6801 - val_accuracy: 0.7963\n",
      "Epoch 358/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1111 - accuracy: 0.9745 - val_loss: 0.6957 - val_accuracy: 0.8056\n",
      "Epoch 359/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1436 - accuracy: 0.9459 - val_loss: 0.7536 - val_accuracy: 0.7963\n",
      "Epoch 360/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1601 - accuracy: 0.9488 - val_loss: 0.6868 - val_accuracy: 0.7963\n",
      "Epoch 361/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1103 - accuracy: 0.9671 - val_loss: 0.6724 - val_accuracy: 0.7870\n",
      "Epoch 362/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1611 - accuracy: 0.9518 - val_loss: 0.6622 - val_accuracy: 0.8056\n",
      "Epoch 363/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1227 - accuracy: 0.9652 - val_loss: 0.6682 - val_accuracy: 0.7963\n",
      "Epoch 364/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1228 - accuracy: 0.9783 - val_loss: 0.7365 - val_accuracy: 0.7685\n",
      "Epoch 365/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0999 - accuracy: 0.9754 - val_loss: 0.7330 - val_accuracy: 0.7870\n",
      "Epoch 366/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1199 - accuracy: 0.9726 - val_loss: 0.7677 - val_accuracy: 0.7685\n",
      "Epoch 367/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1208 - accuracy: 0.9623 - val_loss: 0.7430 - val_accuracy: 0.7963\n",
      "Epoch 368/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1229 - accuracy: 0.9666 - val_loss: 0.7120 - val_accuracy: 0.7685\n",
      "Epoch 369/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1369 - accuracy: 0.9594 - val_loss: 0.7777 - val_accuracy: 0.7870\n",
      "Epoch 370/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1017 - accuracy: 0.9839 - val_loss: 0.8509 - val_accuracy: 0.7870\n",
      "Epoch 371/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1283 - accuracy: 0.9674 - val_loss: 0.8537 - val_accuracy: 0.7500\n",
      "Epoch 372/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1552 - accuracy: 0.9629 - val_loss: 0.6459 - val_accuracy: 0.8333\n",
      "Epoch 373/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1429 - accuracy: 0.9516 - val_loss: 0.7195 - val_accuracy: 0.8056\n",
      "Epoch 374/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1162 - accuracy: 0.9653 - val_loss: 0.6722 - val_accuracy: 0.8241\n",
      "Epoch 375/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1529 - accuracy: 0.9446 - val_loss: 0.6714 - val_accuracy: 0.7963\n",
      "Epoch 376/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1096 - accuracy: 0.9756 - val_loss: 0.6913 - val_accuracy: 0.7963\n",
      "Epoch 377/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0927 - accuracy: 0.9785 - val_loss: 0.7447 - val_accuracy: 0.7778\n",
      "Epoch 378/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0998 - accuracy: 0.9718 - val_loss: 0.6687 - val_accuracy: 0.8519\n",
      "Epoch 379/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0998 - accuracy: 0.9713 - val_loss: 0.6831 - val_accuracy: 0.8056\n",
      "Epoch 380/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1166 - accuracy: 0.9651 - val_loss: 0.7013 - val_accuracy: 0.8056\n",
      "Epoch 381/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1140 - accuracy: 0.9749 - val_loss: 0.6371 - val_accuracy: 0.8241\n",
      "Epoch 382/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1067 - accuracy: 0.9733 - val_loss: 0.6858 - val_accuracy: 0.8333\n",
      "Epoch 383/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1104 - accuracy: 0.9685 - val_loss: 0.8596 - val_accuracy: 0.7315\n",
      "Epoch 384/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2233 - accuracy: 0.9393 - val_loss: 0.7118 - val_accuracy: 0.8333\n",
      "Epoch 385/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1141 - accuracy: 0.9695 - val_loss: 0.7448 - val_accuracy: 0.8056\n",
      "Epoch 386/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0998 - accuracy: 0.9695 - val_loss: 0.7397 - val_accuracy: 0.8148\n",
      "Epoch 387/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1032 - accuracy: 0.9837 - val_loss: 0.6605 - val_accuracy: 0.8056\n",
      "Epoch 388/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1099 - accuracy: 0.9779 - val_loss: 0.6863 - val_accuracy: 0.8148\n",
      "Epoch 389/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1251 - accuracy: 0.9696 - val_loss: 0.6604 - val_accuracy: 0.8333\n",
      "Epoch 390/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1143 - accuracy: 0.9597 - val_loss: 0.6735 - val_accuracy: 0.8241\n",
      "Epoch 391/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1074 - accuracy: 0.9633 - val_loss: 0.7050 - val_accuracy: 0.8056\n",
      "Epoch 392/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0851 - accuracy: 0.9776 - val_loss: 0.7136 - val_accuracy: 0.8148\n",
      "Epoch 393/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0879 - accuracy: 0.9837 - val_loss: 0.7351 - val_accuracy: 0.7963\n",
      "Epoch 394/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1082 - accuracy: 0.9737 - val_loss: 0.7109 - val_accuracy: 0.8148\n",
      "Epoch 395/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0952 - accuracy: 0.9842 - val_loss: 0.7136 - val_accuracy: 0.8333\n",
      "Epoch 396/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1003 - accuracy: 0.9725 - val_loss: 0.6497 - val_accuracy: 0.8241\n",
      "Epoch 397/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0932 - accuracy: 0.9767 - val_loss: 0.8978 - val_accuracy: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1113 - accuracy: 0.9749 - val_loss: 0.7008 - val_accuracy: 0.8333\n",
      "Epoch 399/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1012 - accuracy: 0.9646 - val_loss: 0.6561 - val_accuracy: 0.8333\n",
      "Epoch 400/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0944 - accuracy: 0.9739 - val_loss: 0.6868 - val_accuracy: 0.8426\n",
      "Epoch 401/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1021 - accuracy: 0.9739 - val_loss: 0.7612 - val_accuracy: 0.8056\n",
      "Epoch 402/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0930 - accuracy: 0.9730 - val_loss: 0.7074 - val_accuracy: 0.8056\n",
      "Epoch 403/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1060 - accuracy: 0.9740 - val_loss: 0.6990 - val_accuracy: 0.7963\n",
      "Epoch 404/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0729 - accuracy: 0.9854 - val_loss: 0.7007 - val_accuracy: 0.8056\n",
      "Epoch 405/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0790 - accuracy: 0.9883 - val_loss: 0.7011 - val_accuracy: 0.8241\n",
      "Epoch 406/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1273 - accuracy: 0.9680 - val_loss: 0.6836 - val_accuracy: 0.8148\n",
      "Epoch 407/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 0.8102 - val_accuracy: 0.7870\n",
      "Epoch 408/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1684 - accuracy: 0.9393 - val_loss: 0.6690 - val_accuracy: 0.8241\n",
      "Epoch 409/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0779 - accuracy: 0.9840 - val_loss: 0.7594 - val_accuracy: 0.8056\n",
      "Epoch 410/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0856 - accuracy: 0.9848 - val_loss: 0.7067 - val_accuracy: 0.8056\n",
      "Epoch 411/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0738 - accuracy: 0.9868 - val_loss: 0.7077 - val_accuracy: 0.8056\n",
      "Epoch 412/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0748 - accuracy: 0.9772 - val_loss: 0.8553 - val_accuracy: 0.7685\n",
      "Epoch 413/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1187 - accuracy: 0.9674 - val_loss: 0.7107 - val_accuracy: 0.8056\n",
      "Epoch 414/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0840 - accuracy: 0.9770 - val_loss: 0.6907 - val_accuracy: 0.8148\n",
      "Epoch 415/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0673 - accuracy: 0.9921 - val_loss: 0.6992 - val_accuracy: 0.8241\n",
      "Epoch 416/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0784 - accuracy: 0.9728 - val_loss: 0.7589 - val_accuracy: 0.8056\n",
      "Epoch 417/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0903 - accuracy: 0.9799 - val_loss: 0.9157 - val_accuracy: 0.7407\n",
      "Epoch 418/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1047 - accuracy: 0.9689 - val_loss: 1.9881 - val_accuracy: 0.5833\n",
      "Epoch 419/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2079 - accuracy: 0.9624 - val_loss: 0.7467 - val_accuracy: 0.8333\n",
      "Epoch 420/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0934 - accuracy: 0.9675 - val_loss: 0.7526 - val_accuracy: 0.8241\n",
      "Epoch 421/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0778 - accuracy: 0.9702 - val_loss: 0.7516 - val_accuracy: 0.8241\n",
      "Epoch 422/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1549 - accuracy: 0.9502 - val_loss: 0.7374 - val_accuracy: 0.8056\n",
      "Epoch 423/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0742 - accuracy: 0.9894 - val_loss: 1.0543 - val_accuracy: 0.7130\n",
      "Epoch 424/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0936 - accuracy: 0.9720 - val_loss: 0.6947 - val_accuracy: 0.8426\n",
      "Epoch 425/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0735 - accuracy: 0.9803 - val_loss: 0.7386 - val_accuracy: 0.7963\n",
      "Epoch 426/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0938 - accuracy: 0.9795 - val_loss: 0.7134 - val_accuracy: 0.8241\n",
      "Epoch 427/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1277 - accuracy: 0.9611 - val_loss: 0.7245 - val_accuracy: 0.8056\n",
      "Epoch 428/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0873 - accuracy: 0.9704 - val_loss: 0.7364 - val_accuracy: 0.8056\n",
      "Epoch 429/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0931 - accuracy: 0.9834 - val_loss: 0.7445 - val_accuracy: 0.8056\n",
      "Epoch 430/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0751 - accuracy: 0.9820 - val_loss: 0.7172 - val_accuracy: 0.8333\n",
      "Epoch 431/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0739 - accuracy: 0.9902 - val_loss: 0.7648 - val_accuracy: 0.8056\n",
      "Epoch 432/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0767 - accuracy: 0.9824 - val_loss: 0.6832 - val_accuracy: 0.8148\n",
      "Epoch 433/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1012 - accuracy: 0.9777 - val_loss: 0.7143 - val_accuracy: 0.8426\n",
      "Epoch 434/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0672 - accuracy: 0.9862 - val_loss: 0.7222 - val_accuracy: 0.8056\n",
      "Epoch 435/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0858 - accuracy: 0.9795 - val_loss: 1.7871 - val_accuracy: 0.6296\n",
      "Epoch 436/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1642 - accuracy: 0.9354 - val_loss: 0.7683 - val_accuracy: 0.8056\n",
      "Epoch 437/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0743 - accuracy: 0.9881 - val_loss: 0.7166 - val_accuracy: 0.8519\n",
      "Epoch 438/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0729 - accuracy: 0.9885 - val_loss: 0.7479 - val_accuracy: 0.8241\n",
      "Epoch 439/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0867 - accuracy: 0.9743 - val_loss: 0.7709 - val_accuracy: 0.7963\n",
      "Epoch 440/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0757 - accuracy: 0.9830 - val_loss: 0.7456 - val_accuracy: 0.8056\n",
      "Epoch 441/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0888 - accuracy: 0.9817 - val_loss: 0.8299 - val_accuracy: 0.7778\n",
      "Epoch 442/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0766 - accuracy: 0.9758 - val_loss: 0.7296 - val_accuracy: 0.8241\n",
      "Epoch 443/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0604 - accuracy: 0.9931 - val_loss: 0.7584 - val_accuracy: 0.8056\n",
      "Epoch 444/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0668 - accuracy: 0.9852 - val_loss: 0.7320 - val_accuracy: 0.8056\n",
      "Epoch 445/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0745 - accuracy: 0.9873 - val_loss: 0.6853 - val_accuracy: 0.8333\n",
      "Epoch 446/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0633 - accuracy: 0.9829 - val_loss: 0.7351 - val_accuracy: 0.8426\n",
      "Epoch 447/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0685 - accuracy: 0.9894 - val_loss: 0.7383 - val_accuracy: 0.8056\n",
      "Epoch 448/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0636 - accuracy: 0.9843 - val_loss: 1.3642 - val_accuracy: 0.6667\n",
      "Epoch 449/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0847 - accuracy: 0.9717 - val_loss: 0.7310 - val_accuracy: 0.8333\n",
      "Epoch 450/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0679 - accuracy: 0.9785 - val_loss: 1.0318 - val_accuracy: 0.7593\n",
      "Epoch 451/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0881 - accuracy: 0.9736 - val_loss: 0.7191 - val_accuracy: 0.8333\n",
      "Epoch 452/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.7837 - val_accuracy: 0.8241\n",
      "Epoch 453/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0622 - accuracy: 0.9859 - val_loss: 0.7850 - val_accuracy: 0.8241\n",
      "Epoch 454/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.7196 - val_accuracy: 0.8241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0724 - accuracy: 0.9854 - val_loss: 0.7159 - val_accuracy: 0.8333\n",
      "Epoch 456/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0657 - accuracy: 0.9814 - val_loss: 0.7974 - val_accuracy: 0.8056\n",
      "Epoch 457/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0646 - accuracy: 0.9848 - val_loss: 0.8950 - val_accuracy: 0.7685\n",
      "Epoch 458/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0609 - accuracy: 0.9920 - val_loss: 0.8605 - val_accuracy: 0.7593\n",
      "Epoch 459/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0789 - accuracy: 0.9827 - val_loss: 0.7681 - val_accuracy: 0.8056\n",
      "Epoch 460/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0882 - accuracy: 0.9763 - val_loss: 0.8530 - val_accuracy: 0.8056\n",
      "Epoch 461/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0550 - accuracy: 0.9865 - val_loss: 0.8308 - val_accuracy: 0.8241\n",
      "Epoch 462/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0783 - accuracy: 0.9803 - val_loss: 1.1755 - val_accuracy: 0.6944\n",
      "Epoch 463/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0656 - accuracy: 0.9865 - val_loss: 0.7433 - val_accuracy: 0.8333\n",
      "Epoch 464/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0716 - accuracy: 0.9825 - val_loss: 0.7230 - val_accuracy: 0.8519\n",
      "Epoch 465/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0693 - accuracy: 0.9883 - val_loss: 0.7943 - val_accuracy: 0.8056\n",
      "Epoch 466/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1181 - accuracy: 0.9623 - val_loss: 0.7378 - val_accuracy: 0.8241\n",
      "Epoch 467/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0489 - accuracy: 0.9947 - val_loss: 0.8487 - val_accuracy: 0.7963\n",
      "Epoch 468/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.7509 - val_accuracy: 0.8333\n",
      "Epoch 469/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0676 - accuracy: 0.9920 - val_loss: 0.7743 - val_accuracy: 0.7963\n",
      "Epoch 470/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0472 - accuracy: 0.9902 - val_loss: 0.7657 - val_accuracy: 0.8333\n",
      "Epoch 471/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0757 - accuracy: 0.9649 - val_loss: 0.7841 - val_accuracy: 0.8426\n",
      "Epoch 472/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0656 - accuracy: 0.9858 - val_loss: 0.8108 - val_accuracy: 0.8056\n",
      "Epoch 473/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0583 - accuracy: 0.9881 - val_loss: 0.7416 - val_accuracy: 0.8426\n",
      "Epoch 474/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0597 - accuracy: 0.9770 - val_loss: 0.7670 - val_accuracy: 0.8519\n",
      "Epoch 475/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0611 - accuracy: 0.9881 - val_loss: 0.7463 - val_accuracy: 0.8426\n",
      "Epoch 476/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0338 - accuracy: 0.9996 - val_loss: 0.7416 - val_accuracy: 0.8519\n",
      "Epoch 477/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0683 - accuracy: 0.9772 - val_loss: 0.7815 - val_accuracy: 0.8241\n",
      "Epoch 478/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0506 - accuracy: 0.9896 - val_loss: 0.8241 - val_accuracy: 0.8148\n",
      "Epoch 479/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0516 - accuracy: 0.9775 - val_loss: 0.8482 - val_accuracy: 0.8056\n",
      "Epoch 480/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0739 - accuracy: 0.9779 - val_loss: 0.7666 - val_accuracy: 0.8426\n",
      "Epoch 481/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0383 - accuracy: 0.9897 - val_loss: 0.7987 - val_accuracy: 0.8148\n",
      "Epoch 482/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0592 - accuracy: 0.9890 - val_loss: 0.7571 - val_accuracy: 0.8426\n",
      "Epoch 483/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0387 - accuracy: 0.9954 - val_loss: 0.8437 - val_accuracy: 0.8056\n",
      "Epoch 484/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0636 - accuracy: 0.9723 - val_loss: 0.7739 - val_accuracy: 0.8333\n",
      "Epoch 485/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0564 - accuracy: 0.9943 - val_loss: 0.8033 - val_accuracy: 0.8148\n",
      "Epoch 486/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0470 - accuracy: 0.9885 - val_loss: 0.8864 - val_accuracy: 0.7963\n",
      "Epoch 487/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1029 - accuracy: 0.9826 - val_loss: 0.7469 - val_accuracy: 0.8333\n",
      "Epoch 488/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0484 - accuracy: 0.9880 - val_loss: 0.7566 - val_accuracy: 0.8241\n",
      "Epoch 489/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.7904 - val_accuracy: 0.8241\n",
      "Epoch 490/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0896 - accuracy: 0.9765 - val_loss: 0.7985 - val_accuracy: 0.7963\n",
      "Epoch 491/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0636 - accuracy: 0.9859 - val_loss: 0.7720 - val_accuracy: 0.8333\n",
      "Epoch 492/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0499 - accuracy: 0.9911 - val_loss: 0.8909 - val_accuracy: 0.8148\n",
      "Epoch 493/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1029 - accuracy: 0.9630 - val_loss: 0.8446 - val_accuracy: 0.8241\n",
      "Epoch 494/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 0.7749 - val_accuracy: 0.8333\n",
      "Epoch 495/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.0449 - accuracy: 0.9849 - val_loss: 0.8201 - val_accuracy: 0.8333\n",
      "Epoch 496/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0575 - accuracy: 0.9879 - val_loss: 0.7698 - val_accuracy: 0.8426\n",
      "Epoch 497/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0381 - accuracy: 0.9954 - val_loss: 0.7866 - val_accuracy: 0.8333\n",
      "Epoch 498/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0427 - accuracy: 0.9914 - val_loss: 0.7601 - val_accuracy: 0.8333\n",
      "Epoch 499/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0651 - accuracy: 0.9790 - val_loss: 0.7696 - val_accuracy: 0.8426\n",
      "Epoch 500/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0875 - accuracy: 0.9684 - val_loss: 0.8549 - val_accuracy: 0.8241\n",
      "Epoch 501/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0560 - accuracy: 0.9887 - val_loss: 0.7830 - val_accuracy: 0.8241\n",
      "Epoch 502/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0453 - accuracy: 0.9916 - val_loss: 0.8520 - val_accuracy: 0.8241\n",
      "Epoch 503/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0424 - accuracy: 0.9893 - val_loss: 0.8277 - val_accuracy: 0.8241\n",
      "Epoch 504/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0646 - accuracy: 0.9819 - val_loss: 0.8811 - val_accuracy: 0.7963\n",
      "Epoch 505/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0511 - accuracy: 0.9905 - val_loss: 0.8218 - val_accuracy: 0.8241\n",
      "Epoch 506/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0321 - accuracy: 0.9929 - val_loss: 1.0106 - val_accuracy: 0.7778\n",
      "Epoch 507/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 0.8776 - val_accuracy: 0.7963\n",
      "Epoch 508/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0572 - accuracy: 0.9878 - val_loss: 0.7966 - val_accuracy: 0.8426\n",
      "Epoch 509/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.8142 - val_accuracy: 0.8426\n",
      "Epoch 510/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0583 - accuracy: 0.9847 - val_loss: 0.8608 - val_accuracy: 0.7870\n",
      "Epoch 511/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0631 - accuracy: 0.9702 - val_loss: 0.8997 - val_accuracy: 0.7870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0626 - accuracy: 0.9877 - val_loss: 0.9998 - val_accuracy: 0.7685\n",
      "Epoch 513/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0384 - accuracy: 0.9970 - val_loss: 0.8389 - val_accuracy: 0.7870\n",
      "Epoch 514/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0488 - accuracy: 0.9861 - val_loss: 0.8798 - val_accuracy: 0.8056\n",
      "Epoch 515/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0744 - accuracy: 0.9802 - val_loss: 0.8391 - val_accuracy: 0.8333\n",
      "Epoch 516/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0355 - accuracy: 0.9917 - val_loss: 0.7737 - val_accuracy: 0.8333\n",
      "Epoch 517/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0436 - accuracy: 0.9909 - val_loss: 0.8469 - val_accuracy: 0.8333\n",
      "Epoch 518/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0464 - accuracy: 0.9905 - val_loss: 0.8357 - val_accuracy: 0.7870\n",
      "Epoch 519/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 1.0504 - val_accuracy: 0.7685\n",
      "Epoch 520/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0446 - accuracy: 0.9916 - val_loss: 0.7920 - val_accuracy: 0.8426\n",
      "Epoch 521/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0407 - accuracy: 0.9967 - val_loss: 0.8351 - val_accuracy: 0.8426\n",
      "Epoch 522/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0448 - accuracy: 0.9869 - val_loss: 0.8278 - val_accuracy: 0.8333\n",
      "Epoch 523/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.0369 - accuracy: 0.9917 - val_loss: 0.8791 - val_accuracy: 0.8056\n",
      "Epoch 524/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0394 - accuracy: 0.9888 - val_loss: 0.8460 - val_accuracy: 0.8241\n",
      "Epoch 525/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0411 - accuracy: 0.9936 - val_loss: 0.8759 - val_accuracy: 0.8056\n",
      "Epoch 526/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0520 - accuracy: 0.9867 - val_loss: 0.8536 - val_accuracy: 0.8241\n",
      "Epoch 527/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0356 - accuracy: 0.9899 - val_loss: 0.8773 - val_accuracy: 0.8241\n",
      "Epoch 528/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0529 - accuracy: 0.9892 - val_loss: 0.9095 - val_accuracy: 0.7963\n",
      "Epoch 529/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0366 - accuracy: 0.9936 - val_loss: 2.1587 - val_accuracy: 0.6019\n",
      "Epoch 530/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.4448 - accuracy: 0.9456 - val_loss: 0.8662 - val_accuracy: 0.8333\n",
      "Epoch 531/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0305 - accuracy: 0.9972 - val_loss: 0.8486 - val_accuracy: 0.8056\n",
      "Epoch 532/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0416 - accuracy: 0.9883 - val_loss: 0.9358 - val_accuracy: 0.7870\n",
      "Epoch 533/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0506 - accuracy: 0.9863 - val_loss: 0.8831 - val_accuracy: 0.8333\n",
      "Epoch 534/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0839 - accuracy: 0.9643 - val_loss: 0.8248 - val_accuracy: 0.8056\n",
      "Epoch 535/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0330 - accuracy: 0.9920 - val_loss: 0.8294 - val_accuracy: 0.8148\n",
      "Epoch 536/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0867 - accuracy: 0.9791 - val_loss: 0.8484 - val_accuracy: 0.8148\n",
      "Epoch 537/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.8172 - val_accuracy: 0.8333\n",
      "Epoch 538/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0502 - accuracy: 0.9908 - val_loss: 0.8671 - val_accuracy: 0.8333\n",
      "Epoch 539/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0284 - accuracy: 0.9953 - val_loss: 0.9433 - val_accuracy: 0.7963\n",
      "Epoch 540/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0307 - accuracy: 0.9983 - val_loss: 0.8504 - val_accuracy: 0.8241\n",
      "Epoch 541/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.8333\n",
      "Epoch 542/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0504 - accuracy: 0.9884 - val_loss: 0.8895 - val_accuracy: 0.8148\n",
      "Epoch 543/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0348 - accuracy: 0.9959 - val_loss: 0.8532 - val_accuracy: 0.8241\n",
      "Epoch 544/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0338 - accuracy: 0.9949 - val_loss: 0.8634 - val_accuracy: 0.8056\n",
      "Epoch 545/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1093 - accuracy: 0.9743 - val_loss: 0.8482 - val_accuracy: 0.8241\n",
      "Epoch 546/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0257 - accuracy: 0.9998 - val_loss: 0.8104 - val_accuracy: 0.8241\n",
      "Epoch 547/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0344 - accuracy: 0.9901 - val_loss: 0.8915 - val_accuracy: 0.8241\n",
      "Epoch 548/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0374 - accuracy: 0.9981 - val_loss: 0.8713 - val_accuracy: 0.7963\n",
      "Epoch 549/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.8586 - val_accuracy: 0.8241\n",
      "Epoch 550/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0364 - accuracy: 0.9937 - val_loss: 0.8436 - val_accuracy: 0.8333\n",
      "Epoch 551/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0373 - accuracy: 0.9942 - val_loss: 0.9967 - val_accuracy: 0.7963\n",
      "Epoch 552/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0433 - accuracy: 0.9824 - val_loss: 0.8989 - val_accuracy: 0.8148\n",
      "Epoch 553/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.0259 - accuracy: 0.9962 - val_loss: 0.8494 - val_accuracy: 0.8519\n",
      "Epoch 554/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.0659 - accuracy: 0.9781 - val_loss: 0.8927 - val_accuracy: 0.8426\n",
      "Epoch 555/700\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.0509 - accuracy: 0.9878 - val_loss: 0.8699 - val_accuracy: 0.8333\n",
      "Epoch 556/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.0442 - accuracy: 0.9875 - val_loss: 0.9409 - val_accuracy: 0.8519\n",
      "Epoch 557/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0330 - accuracy: 0.9932 - val_loss: 0.9130 - val_accuracy: 0.8056\n",
      "Epoch 558/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0199 - accuracy: 0.9995 - val_loss: 1.0692 - val_accuracy: 0.7315\n",
      "Epoch 559/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0412 - accuracy: 0.9844 - val_loss: 1.0095 - val_accuracy: 0.7870\n",
      "Epoch 560/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0518 - accuracy: 0.9868 - val_loss: 0.9280 - val_accuracy: 0.8333\n",
      "Epoch 561/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0453 - accuracy: 0.9891 - val_loss: 0.9215 - val_accuracy: 0.8148\n",
      "Epoch 562/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0289 - accuracy: 0.9925 - val_loss: 0.8596 - val_accuracy: 0.8148\n",
      "Epoch 563/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0451 - accuracy: 0.9826 - val_loss: 0.8533 - val_accuracy: 0.8241\n",
      "Epoch 564/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0275 - accuracy: 0.9976 - val_loss: 0.9726 - val_accuracy: 0.8056\n",
      "Epoch 565/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0726 - accuracy: 0.9945 - val_loss: 0.8608 - val_accuracy: 0.8426\n",
      "Epoch 566/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.8874 - val_accuracy: 0.8148\n",
      "Epoch 567/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.8991 - val_accuracy: 0.8333\n",
      "Epoch 568/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 0.8489 - val_accuracy: 0.8241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0299 - accuracy: 0.9975 - val_loss: 1.0557 - val_accuracy: 0.7870\n",
      "Epoch 570/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0413 - accuracy: 0.9845 - val_loss: 0.9159 - val_accuracy: 0.8056\n",
      "Epoch 571/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0441 - accuracy: 0.9944 - val_loss: 0.9649 - val_accuracy: 0.8148\n",
      "Epoch 572/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0259 - accuracy: 0.9973 - val_loss: 0.8570 - val_accuracy: 0.8333\n",
      "Epoch 573/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0318 - accuracy: 0.9976 - val_loss: 0.9276 - val_accuracy: 0.8056\n",
      "Epoch 574/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.8937 - val_accuracy: 0.8333\n",
      "Epoch 575/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0217 - accuracy: 0.9996 - val_loss: 1.0219 - val_accuracy: 0.8056\n",
      "Epoch 576/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0346 - accuracy: 0.9954 - val_loss: 0.8917 - val_accuracy: 0.8148\n",
      "Epoch 577/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0186 - accuracy: 0.9985 - val_loss: 0.8699 - val_accuracy: 0.8148\n",
      "Epoch 578/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0570 - accuracy: 0.9817 - val_loss: 0.9858 - val_accuracy: 0.8426\n",
      "Epoch 579/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 1.6869 - val_accuracy: 0.6667\n",
      "Epoch 580/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0990 - accuracy: 0.9645 - val_loss: 0.8464 - val_accuracy: 0.8241\n",
      "Epoch 581/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0293 - accuracy: 0.9960 - val_loss: 0.9406 - val_accuracy: 0.8333\n",
      "Epoch 582/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0209 - accuracy: 0.9967 - val_loss: 0.8973 - val_accuracy: 0.8148\n",
      "Epoch 583/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0206 - accuracy: 0.9988 - val_loss: 0.9341 - val_accuracy: 0.8333\n",
      "Epoch 584/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0285 - accuracy: 0.9942 - val_loss: 0.9041 - val_accuracy: 0.8333\n",
      "Epoch 585/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0292 - accuracy: 0.9960 - val_loss: 0.9348 - val_accuracy: 0.8056\n",
      "Epoch 586/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0365 - accuracy: 0.9932 - val_loss: 0.8781 - val_accuracy: 0.8241\n",
      "Epoch 587/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0160 - accuracy: 0.9986 - val_loss: 0.9940 - val_accuracy: 0.7778\n",
      "Epoch 588/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0216 - accuracy: 0.9965 - val_loss: 0.8856 - val_accuracy: 0.8426\n",
      "Epoch 589/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0558 - accuracy: 0.9766 - val_loss: 0.8615 - val_accuracy: 0.8333\n",
      "Epoch 590/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0210 - accuracy: 0.9955 - val_loss: 0.8729 - val_accuracy: 0.8333\n",
      "Epoch 591/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0250 - accuracy: 0.9987 - val_loss: 0.9126 - val_accuracy: 0.8426\n",
      "Epoch 592/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0228 - accuracy: 0.9985 - val_loss: 1.0137 - val_accuracy: 0.8333\n",
      "Epoch 593/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0603 - accuracy: 0.9824 - val_loss: 1.2784 - val_accuracy: 0.7685\n",
      "Epoch 594/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.9400 - val_accuracy: 0.8333\n",
      "Epoch 595/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 1.0248 - val_accuracy: 0.7963\n",
      "Epoch 596/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.9037 - val_accuracy: 0.8241\n",
      "Epoch 597/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0237 - accuracy: 0.9967 - val_loss: 0.8783 - val_accuracy: 0.8241\n",
      "Epoch 598/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.9282 - val_accuracy: 0.8241\n",
      "Epoch 599/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0202 - accuracy: 0.9985 - val_loss: 0.9565 - val_accuracy: 0.8148\n",
      "Epoch 600/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0258 - accuracy: 0.9951 - val_loss: 0.9460 - val_accuracy: 0.8148\n",
      "Epoch 601/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0384 - accuracy: 0.9906 - val_loss: 0.9711 - val_accuracy: 0.8241\n",
      "Epoch 602/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.9129 - val_accuracy: 0.8148\n",
      "Epoch 603/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0225 - accuracy: 0.9979 - val_loss: 0.9633 - val_accuracy: 0.8241\n",
      "Epoch 604/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0125 - accuracy: 0.9990 - val_loss: 0.9329 - val_accuracy: 0.8241\n",
      "Epoch 605/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0407 - accuracy: 0.9851 - val_loss: 0.9061 - val_accuracy: 0.8426\n",
      "Epoch 606/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0203 - accuracy: 0.9995 - val_loss: 0.9893 - val_accuracy: 0.8148\n",
      "Epoch 607/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0447 - accuracy: 0.9879 - val_loss: 0.9653 - val_accuracy: 0.8241\n",
      "Epoch 608/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0369 - accuracy: 0.9913 - val_loss: 0.9362 - val_accuracy: 0.8333\n",
      "Epoch 609/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0227 - accuracy: 0.9990 - val_loss: 0.9095 - val_accuracy: 0.8241\n",
      "Epoch 610/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0209 - accuracy: 0.9985 - val_loss: 0.9508 - val_accuracy: 0.8241\n",
      "Epoch 611/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0219 - accuracy: 0.9908 - val_loss: 0.9058 - val_accuracy: 0.8241\n",
      "Epoch 612/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0478 - accuracy: 0.9874 - val_loss: 0.9332 - val_accuracy: 0.8148\n",
      "Epoch 613/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 1.0269 - val_accuracy: 0.7963\n",
      "Epoch 614/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.9117 - val_accuracy: 0.8241\n",
      "Epoch 615/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0232 - accuracy: 0.9967 - val_loss: 0.9026 - val_accuracy: 0.8426\n",
      "Epoch 616/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0159 - accuracy: 0.9975 - val_loss: 0.9660 - val_accuracy: 0.8241\n",
      "Epoch 617/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0328 - accuracy: 0.9913 - val_loss: 1.0571 - val_accuracy: 0.8148\n",
      "Epoch 618/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0197 - accuracy: 0.9955 - val_loss: 0.9858 - val_accuracy: 0.8241\n",
      "Epoch 619/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.9196 - val_accuracy: 0.8241\n",
      "Epoch 620/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 1.0041 - val_accuracy: 0.8056\n",
      "Epoch 621/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0144 - accuracy: 0.9985 - val_loss: 1.0087 - val_accuracy: 0.7963\n",
      "Epoch 622/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 0.9077 - val_accuracy: 0.8333\n",
      "Epoch 623/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0386 - accuracy: 0.9876 - val_loss: 0.9474 - val_accuracy: 0.8241\n",
      "Epoch 624/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0332 - accuracy: 0.9926 - val_loss: 0.9380 - val_accuracy: 0.8241\n",
      "Epoch 625/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0190 - accuracy: 0.9983 - val_loss: 0.9048 - val_accuracy: 0.8241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.9626 - val_accuracy: 0.8241\n",
      "Epoch 627/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.0038 - val_accuracy: 0.7870\n",
      "Epoch 628/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0493 - accuracy: 0.9907 - val_loss: 0.9294 - val_accuracy: 0.8333\n",
      "Epoch 629/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.9544 - val_accuracy: 0.8241\n",
      "Epoch 630/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.9268 - val_accuracy: 0.8056\n",
      "Epoch 631/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0179 - accuracy: 0.9974 - val_loss: 1.1940 - val_accuracy: 0.8056\n",
      "Epoch 632/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0560 - accuracy: 0.9899 - val_loss: 0.9509 - val_accuracy: 0.8333\n",
      "Epoch 633/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.9277 - val_accuracy: 0.8241\n",
      "Epoch 634/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0410 - accuracy: 0.9842 - val_loss: 0.9459 - val_accuracy: 0.8241\n",
      "Epoch 635/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 1.2621 - val_accuracy: 0.6852\n",
      "Epoch 636/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0359 - accuracy: 0.9895 - val_loss: 0.9850 - val_accuracy: 0.8148\n",
      "Epoch 637/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.9958 - val_accuracy: 0.8056\n",
      "Epoch 638/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0250 - accuracy: 0.9935 - val_loss: 0.9560 - val_accuracy: 0.8241\n",
      "Epoch 639/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.9732 - val_accuracy: 0.8333\n",
      "Epoch 640/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0266 - accuracy: 0.9964 - val_loss: 1.0133 - val_accuracy: 0.8333\n",
      "Epoch 641/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0163 - accuracy: 0.9998 - val_loss: 1.0080 - val_accuracy: 0.8056\n",
      "Epoch 642/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 0.9896 - val_accuracy: 0.8426\n",
      "Epoch 643/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0233 - accuracy: 0.9989 - val_loss: 0.9504 - val_accuracy: 0.8241\n",
      "Epoch 644/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 1.0185 - val_accuracy: 0.8241\n",
      "Epoch 645/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.9709 - val_accuracy: 0.8241\n",
      "Epoch 646/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0218 - accuracy: 0.9972 - val_loss: 1.0273 - val_accuracy: 0.7870\n",
      "Epoch 647/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0298 - accuracy: 0.9958 - val_loss: 0.9313 - val_accuracy: 0.8148\n",
      "Epoch 648/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0243 - accuracy: 0.9966 - val_loss: 1.2376 - val_accuracy: 0.7685\n",
      "Epoch 649/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.9715 - val_accuracy: 0.8333\n",
      "Epoch 650/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0273 - accuracy: 0.9965 - val_loss: 0.9921 - val_accuracy: 0.8148\n",
      "Epoch 651/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 0.9710 - val_accuracy: 0.8241\n",
      "Epoch 652/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0139 - accuracy: 0.9980 - val_loss: 1.0814 - val_accuracy: 0.8241\n",
      "Epoch 653/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0191 - accuracy: 0.9981 - val_loss: 1.0843 - val_accuracy: 0.7870\n",
      "Epoch 654/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 1.0472 - val_accuracy: 0.8056\n",
      "Epoch 655/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0835 - accuracy: 0.9846 - val_loss: 1.0063 - val_accuracy: 0.8241\n",
      "Epoch 656/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.0354 - val_accuracy: 0.8333\n",
      "Epoch 657/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 1.0071 - val_accuracy: 0.8333\n",
      "Epoch 658/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0316 - accuracy: 0.9928 - val_loss: 0.9687 - val_accuracy: 0.8148\n",
      "Epoch 659/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 1.0361 - val_accuracy: 0.8241\n",
      "Epoch 660/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0147 - accuracy: 0.9990 - val_loss: 1.1213 - val_accuracy: 0.8241\n",
      "Epoch 661/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 1.0796 - val_accuracy: 0.8241\n",
      "Epoch 662/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0259 - accuracy: 0.9969 - val_loss: 0.9958 - val_accuracy: 0.8148\n",
      "Epoch 663/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9817 - val_accuracy: 0.8241\n",
      "Epoch 664/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 1.1527 - val_accuracy: 0.7963\n",
      "Epoch 665/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0173 - accuracy: 0.9973 - val_loss: 1.0308 - val_accuracy: 0.8333\n",
      "Epoch 666/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.0869 - val_accuracy: 0.7870\n",
      "Epoch 667/700\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0329 - accuracy: 0.9966 - val_loss: 1.1161 - val_accuracy: 0.8056\n",
      "Epoch 668/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 1.0325 - val_accuracy: 0.8241\n",
      "Epoch 669/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 1.0981 - val_accuracy: 0.8148\n",
      "Epoch 670/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0248 - accuracy: 0.9951 - val_loss: 1.0009 - val_accuracy: 0.8241\n",
      "Epoch 671/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 1.0335 - val_accuracy: 0.8426\n",
      "Epoch 672/700\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0116 - accuracy: 0.9988 - val_loss: 1.2721 - val_accuracy: 0.7130\n",
      "Epoch 673/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0346 - accuracy: 0.9896 - val_loss: 1.0240 - val_accuracy: 0.8333\n",
      "Epoch 674/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.0302 - val_accuracy: 0.8148\n",
      "Epoch 675/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0191 - val_accuracy: 0.8333\n",
      "Epoch 676/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0308 - accuracy: 0.9924 - val_loss: 0.9678 - val_accuracy: 0.8333\n",
      "Epoch 677/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0208 - accuracy: 0.9908 - val_loss: 1.0520 - val_accuracy: 0.8241\n",
      "Epoch 678/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0102 - accuracy: 0.9996 - val_loss: 1.0520 - val_accuracy: 0.8333\n",
      "Epoch 679/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 1.0557 - val_accuracy: 0.8241\n",
      "Epoch 680/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1184 - val_accuracy: 0.7963\n",
      "Epoch 681/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0228 - accuracy: 0.9983 - val_loss: 1.0405 - val_accuracy: 0.8148\n",
      "Epoch 682/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0173 - accuracy: 0.9981 - val_loss: 1.2488 - val_accuracy: 0.7870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 0.9978 - val_accuracy: 0.8148\n",
      "Epoch 684/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0845 - val_accuracy: 0.8056\n",
      "Epoch 685/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 1.0603 - val_accuracy: 0.8241\n",
      "Epoch 686/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0130 - accuracy: 0.9988 - val_loss: 1.1127 - val_accuracy: 0.8241\n",
      "Epoch 687/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.9948 - val_accuracy: 0.8426\n",
      "Epoch 688/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 1.0002 - val_accuracy: 0.8333\n",
      "Epoch 689/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 0.8333\n",
      "Epoch 690/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 1.0498 - val_accuracy: 0.8241\n",
      "Epoch 691/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 1.0984 - val_accuracy: 0.7870\n",
      "Epoch 692/700\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.0395 - accuracy: 0.9892 - val_loss: 0.9940 - val_accuracy: 0.8333\n",
      "Epoch 693/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 1.1182 - val_accuracy: 0.8148\n",
      "Epoch 694/700\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 1.0567 - val_accuracy: 0.8056\n",
      "Epoch 695/700\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.0082 - accuracy: 0.9998 - val_loss: 1.0649 - val_accuracy: 0.8333\n",
      "Epoch 696/700\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 1.0080 - val_accuracy: 0.8241\n",
      "Epoch 697/700\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 1.0562 - val_accuracy: 0.8241\n",
      "Epoch 698/700\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 1.1089 - val_accuracy: 0.8056\n",
      "Epoch 699/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 1.0541 - val_accuracy: 0.8241\n",
      "Epoch 700/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 1.0092 - val_accuracy: 0.8241\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(X_train, y_train, batch_size=16, epochs=700, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим повторение картины, которая наблюдается в статье. Качество модели на тестовой выборке около `70-80%`. Это хороший результат, но скорее всего некорректный. \n",
    "\n",
    "В данной работе, как и в статье, качество на валидации оценивалось на голосах спикеров, которые присутствуют в обучающей выборке. Следует проверить качество модели на новых голосах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка на новых голосах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\79217\\Documents\\Personal_assistent\\speech_emotion\\Speech-Emotion-Analyzer\\saved_models\\Emotion_Voice_Detection_Model_Russian.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model_Russian.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model_russian.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model_russian.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model_Russian.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load('my_data/from_public/2_ms.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "livedf2= pd.DataFrame(data=livedf2)\n",
    "livedf2 = livedf2.stack().to_frame().T\n",
    "twodim= np.expand_dims(livedf2, axis=2)\n",
    "livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)\n",
    "livepreds1=livepreds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepreds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fa': 0, 'fc': 1, 'fh': 2, 'fs': 3, 'ma': 4, 'mc': 5, 'mh': 6, 'ms': 7}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На новых голосах модель работает просто ужасно. В качестве новых голосов были выбраны живые голосовые сообщения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Использовать другие голоса на валидации.\n",
    "\n",
    "2. Возможно, поменять модель. \n",
    "\n",
    "Эту модель пока нельзя использовать для разметки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
